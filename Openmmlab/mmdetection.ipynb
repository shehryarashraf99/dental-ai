{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4cd0tLsdZvo",
        "outputId": "9594964b-e21a-4e3d-92e7-2d10525edad7"
      },
      "outputs": [
        {
          "ename": "MessageError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    130\u001b[0m   )\n\u001b[1;32m    131\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3XiKxmsPd-E-",
        "outputId": "3d21d05d-c2f0-41ba-e802-c934fa3eeaea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting openmim\n",
            "  Downloading openmim-0.3.9-py2.py3-none-any.whl (52 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/52.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click in /usr/local/lib/python3.10/dist-packages (from openmim) (8.1.7)\n",
            "Collecting colorama (from openmim)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting model-index (from openmim)\n",
            "  Downloading model_index-0.1.11-py3-none-any.whl (34 kB)\n",
            "Collecting opendatalab (from openmim)\n",
            "  Downloading opendatalab-0.0.10-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from openmim) (1.5.3)\n",
            "Requirement already satisfied: pip>=19.3 in /usr/local/lib/python3.10/dist-packages (from openmim) (23.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from openmim) (2.31.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from openmim) (13.5.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from openmim) (0.9.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from model-index->openmim) (6.0.1)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from model-index->openmim) (3.4.4)\n",
            "Collecting ordered-set (from model-index->openmim)\n",
            "  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
            "Collecting pycryptodome (from opendatalab->openmim)\n",
            "  Downloading pycryptodome-3.19.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from opendatalab->openmim) (4.66.1)\n",
            "Collecting openxlab (from opendatalab->openmim)\n",
            "  Downloading openxlab-0.0.25-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.1/295.1 kB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->openmim) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->openmim) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->openmim) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->openmim) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->openmim) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->openmim) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas->openmim) (1.23.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->openmim) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->openmim) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->openmim) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->openmim) (1.16.0)\n",
            "Collecting oss2~=2.17.0 (from openxlab->opendatalab->openmim)\n",
            "  Downloading oss2-2.17.0.tar.gz (259 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.5/259.5 kB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting requests (from openmim)\n",
            "  Downloading requests-2.28.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rich (from openmim)\n",
            "  Downloading rich-13.4.2-py3-none-any.whl (239 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.4/239.4 kB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting setuptools~=60.2.0 (from openxlab->opendatalab->openmim)\n",
            "  Downloading setuptools-60.2.0-py3-none-any.whl (953 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.1/953.1 kB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tqdm (from opendatalab->openmim)\n",
            "  Downloading tqdm-4.65.2-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting urllib3<1.27,>=1.21.1 (from requests->openmim)\n",
            "  Downloading urllib3-1.26.16-py2.py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.1/143.1 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting crcmod>=1.7 (from oss2~=2.17.0->openxlab->opendatalab->openmim)\n",
            "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting aliyun-python-sdk-kms>=2.4.1 (from oss2~=2.17.0->openxlab->opendatalab->openmim)\n",
            "  Downloading aliyun_python_sdk_kms-2.16.2-py2.py3-none-any.whl (94 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.0/94.0 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aliyun-python-sdk-core>=2.13.12 (from oss2~=2.17.0->openxlab->opendatalab->openmim)\n",
            "  Downloading aliyun-python-sdk-core-2.14.0.tar.gz (443 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.0/443.0 kB\u001b[0m \u001b[31m50.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jmespath<1.0.0,>=0.9.3 (from aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim)\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: cryptography>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim) (41.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=2.6.0->aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=2.6.0->aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim) (2.21)\n",
            "Building wheels for collected packages: oss2, aliyun-python-sdk-core, crcmod\n",
            "  Building wheel for oss2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for oss2: filename=oss2-2.17.0-py3-none-any.whl size=112371 sha256=b95773c69ebd924b8247be3c342b32271a367fbedc39e49ecf8246bf541a733b\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/04/7b/7e61b8157fdf211c5131375240d0d86ca82e2a88ead9672c88\n",
            "  Building wheel for aliyun-python-sdk-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for aliyun-python-sdk-core: filename=aliyun_python_sdk_core-2.14.0-py3-none-any.whl size=535290 sha256=f8e600570afcaa4071134f98bb5b769b700cc7a0450792eef8ca602ef3a44c3e\n",
            "  Stored in directory: /root/.cache/pip/wheels/16/3c/68/b7eab618d9f1d5e7d386296f1e07e2cf36aaa1eb5161885038\n",
            "  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for crcmod: filename=crcmod-1.7-cp310-cp310-linux_x86_64.whl size=31410 sha256=214ba1958ac490a5f4ce929d5f2a3ba1253fc4b2ae28c0c43c0bcaf3df5af570\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/4c/07/72215c529bd59d67e3dac29711d7aba1b692f543c808ba9e86\n",
            "Successfully built oss2 aliyun-python-sdk-core crcmod\n",
            "Installing collected packages: crcmod, urllib3, tqdm, setuptools, pycryptodome, ordered-set, jmespath, colorama, rich, requests, model-index, aliyun-python-sdk-core, aliyun-python-sdk-kms, oss2, openxlab, opendatalab, openmim\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.0.4\n",
            "    Uninstalling urllib3-2.0.4:\n",
            "      Successfully uninstalled urllib3-2.0.4\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.66.1\n",
            "    Uninstalling tqdm-4.66.1:\n",
            "      Successfully uninstalled tqdm-4.66.1\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 67.7.2\n",
            "    Uninstalling setuptools-67.7.2:\n",
            "      Successfully uninstalled setuptools-67.7.2\n",
            "  Attempting uninstall: rich\n",
            "    Found existing installation: rich 13.5.2\n",
            "    Uninstalling rich-13.5.2:\n",
            "      Successfully uninstalled rich-13.5.2\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.31.0\n",
            "    Uninstalling requests-2.31.0:\n",
            "      Successfully uninstalled requests-2.31.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "cvxpy 1.3.2 requires setuptools>65.5.1, but you have setuptools 60.2.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.28.2 which is incompatible.\n",
            "yfinance 0.2.28 requires requests>=2.31, but you have requests 2.28.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aliyun-python-sdk-core-2.14.0 aliyun-python-sdk-kms-2.16.2 colorama-0.4.6 crcmod-1.7 jmespath-0.10.0 model-index-0.1.11 opendatalab-0.0.10 openmim-0.3.9 openxlab-0.0.25 ordered-set-4.1.0 oss2-2.17.0 pycryptodome-3.19.0 requests-2.28.2 rich-13.4.2 setuptools-60.2.0 tqdm-4.65.2 urllib3-1.26.16\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack",
                  "pkg_resources",
                  "setuptools"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.openmmlab.com/mmcv/dist/cu118/torch2.0.0/index.html\n",
            "Collecting mmengine>=0.7.0\n",
            "  Downloading mmengine-0.8.5-py3-none-any.whl (437 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m437.5/437.5 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting addict (from mmengine>=0.7.0)\n",
            "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.7.0) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.7.0) (1.23.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.7.0) (6.0.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.7.0) (13.4.2)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.7.0) (2.3.0)\n",
            "Collecting yapf (from mmengine>=0.7.0)\n",
            "  Downloading yapf-0.40.2-py3-none-any.whl (254 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.7/254.7 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.7.0) (4.8.0.76)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.7.0) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.7.0) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.7.0) (4.42.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.7.0) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.7.0) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.7.0) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.7.0) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.7.0) (2.8.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmengine>=0.7.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmengine>=0.7.0) (2.16.1)\n",
            "Requirement already satisfied: importlib-metadata>=6.6.0 in /usr/local/lib/python3.10/dist-packages (from yapf->mmengine>=0.7.0) (6.8.0)\n",
            "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmengine>=0.7.0) (3.10.0)\n",
            "Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmengine>=0.7.0) (2.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.6.0->yapf->mmengine>=0.7.0) (3.16.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->mmengine>=0.7.0) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mmengine>=0.7.0) (1.16.0)\n",
            "Installing collected packages: addict, yapf, mmengine\n",
            "Successfully installed addict-2.4.0 mmengine-0.8.5 yapf-0.40.2\n",
            "Looking in links: https://download.openmmlab.com/mmcv/dist/cu118/torch2.0.0/index.html\n",
            "Collecting mmcv>=2.0.0rc4\n",
            "  Downloading https://download.openmmlab.com/mmcv/dist/cu118/torch2.0.0/mmcv-2.0.1-cp310-cp310-manylinux1_x86_64.whl (74.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.4/74.4 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: addict in /usr/local/lib/python3.10/dist-packages (from mmcv>=2.0.0rc4) (2.4.0)\n",
            "Requirement already satisfied: mmengine>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from mmcv>=2.0.0rc4) (0.8.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mmcv>=2.0.0rc4) (1.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mmcv>=2.0.0rc4) (23.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from mmcv>=2.0.0rc4) (9.4.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from mmcv>=2.0.0rc4) (6.0.1)\n",
            "Requirement already satisfied: yapf in /usr/local/lib/python3.10/dist-packages (from mmcv>=2.0.0rc4) (0.40.2)\n",
            "Requirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.10/dist-packages (from mmcv>=2.0.0rc4) (4.8.0.76)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.3.0->mmcv>=2.0.0rc4) (3.7.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.3.0->mmcv>=2.0.0rc4) (13.4.2)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.3.0->mmcv>=2.0.0rc4) (2.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=6.6.0 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv>=2.0.0rc4) (6.8.0)\n",
            "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv>=2.0.0rc4) (3.10.0)\n",
            "Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv>=2.0.0rc4) (2.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.6.0->yapf->mmcv>=2.0.0rc4) (3.16.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv>=2.0.0rc4) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv>=2.0.0rc4) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv>=2.0.0rc4) (4.42.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv>=2.0.0rc4) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv>=2.0.0rc4) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv>=2.0.0rc4) (2.8.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmengine>=0.3.0->mmcv>=2.0.0rc4) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmengine>=0.3.0->mmcv>=2.0.0rc4) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->mmengine>=0.3.0->mmcv>=2.0.0rc4) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mmengine>=0.3.0->mmcv>=2.0.0rc4) (1.16.0)\n",
            "Installing collected packages: mmcv\n",
            "Successfully installed mmcv-2.0.1\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Cloning into 'mmdetection'...\n",
            "remote: Enumerating objects: 37367, done.\u001b[K\n",
            "remote: Total 37367 (delta 0), reused 0 (delta 0), pack-reused 37367\u001b[K\n",
            "Receiving objects: 100% (37367/37367), 62.74 MiB | 28.93 MiB/s, done.\n",
            "Resolving deltas: 100% (25827/25827), done.\n",
            "/content/mmdetection\n",
            "Obtaining file:///content/mmdetection\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mmdet==3.1.0) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mmdet==3.1.0) (1.23.5)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from mmdet==3.1.0) (2.0.7)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from mmdet==3.1.0) (1.11.2)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.10/dist-packages (from mmdet==3.1.0) (2.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from mmdet==3.1.0) (1.16.0)\n",
            "Collecting terminaltables (from mmdet==3.1.0)\n",
            "  Downloading terminaltables-3.1.10-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet==3.1.0) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet==3.1.0) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet==3.1.0) (4.42.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet==3.1.0) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet==3.1.0) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet==3.1.0) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet==3.1.0) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet==3.1.0) (2.8.2)\n",
            "Installing collected packages: terminaltables, mmdet\n",
            "  Running setup.py develop for mmdet\n",
            "Successfully installed mmdet-3.1.0 terminaltables-3.1.10\n",
            "3.1.0\n",
            "11.8\n",
            "GCC 9.3\n"
          ]
        }
      ],
      "source": [
        "%pip install -U openmim\n",
        "!mim install \"mmengine>=0.7.0\"\n",
        "!mim install \"mmcv>=2.0.0rc4\"\n",
        "!pip install  torch\n",
        "# Install mmdetection\n",
        "\n",
        "!rm -rf mmdetection\n",
        "!git clone https://github.com/open-mmlab/mmdetection.git\n",
        "%cd mmdetection\n",
        "\n",
        "%pip install -e .\n",
        "\n",
        "import mmdet\n",
        "print(mmdet.__version__)\n",
        "\n",
        "# Check mmcv installation\n",
        "from mmcv.ops import get_compiling_cuda_version, get_compiler_version\n",
        "print(get_compiling_cuda_version())\n",
        "print(get_compiler_version())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "5oJX5zwrgdnM",
        "outputId": "2909d5cb-0135-43e4-a0f0-bc569f3446b0"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-742586200037>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmmengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/mmdetection/configs/detectors/customconfig.py'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Config:\\n{cfg.pretty_text}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mmengine/config/config.py\u001b[0m in \u001b[0;36mfromfile\u001b[0;34m(filename, use_predefined_variables, import_custom_modules, use_environment_variables, lazy_import, format_python_code)\u001b[0m\n\u001b[1;32m    453\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlazy_import\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m            \u001b[0mlazy_import\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_lazy_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m             cfg_dict, cfg_text, env_variables = Config._file2dict(\n\u001b[1;32m    457\u001b[0m                 \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_predefined_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_environment_variables\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mmengine/config/config.py\u001b[0m in \u001b[0;36m_is_lazy_import\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m   1649\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.py'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1650\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1651\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1652\u001b[0m             \u001b[0mcodes_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1653\u001b[0m             \u001b[0mparsed_codes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcodes_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/mmdetection/configs/detectors/customconfig.py'"
          ]
        }
      ],
      "source": [
        "from mmengine import Config\n",
        "cfg = Config.fromfile('/content/mmdetection/configs/detectors/customconfig.py')\n",
        "print(f'Config:\\n{cfg.pretty_text}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hivwMBCVhOmj"
      },
      "outputs": [],
      "source": [
        "data_root='/content/drive/MyDrive/data/diagnosis'\n",
        "cfg['load_from']=r'/content/drive/MyDrive/models/detectors_htc_r101_20e_coco_20210419_203638-348d533b.pth'\n",
        "cfg.model.backbone.frozen_stages=4\n",
        "cfg.work_dir=r'C:\\Users\\HP\\mmdetection\\demo\\work_dir'\n",
        "cfg.val_evaluator.ann_file='/content/drive/MyDrive/data/diagnosis/ann/val.json'\n",
        "cfg.test_evaluator=cfg.val_evaluator\n",
        "cfg.train_cfg.max_epochs=10\n",
        "cfg.train_dataloader={'batch_size': 1,\n",
        " 'num_workers': 8,\n",
        " 'persistent_workers': True,\n",
        " 'sampler': {'type': 'DefaultSampler', 'shuffle': True},\n",
        " 'batch_sampler': {'type': 'AspectRatioBatchSampler'},\n",
        " 'dataset': {'type': 'DiagnosisDataset',\n",
        "  'data_root':data_root,\n",
        "  'ann_file': 'ann/train.json',\n",
        "  'data_prefix': {'img': 'train/'},\n",
        "  'filter_cfg': {'filter_empty_gt': False, 'min_size': 16},\n",
        "  'pipeline': [{'type': 'LoadImageFromFile', 'backend_args': None},\n",
        "   {'type': 'LoadAnnotations', 'with_bbox': True, 'with_mask': True},\n",
        "   {'type': 'Resize', 'scale': (1333, 800), 'keep_ratio': True},\n",
        "   {'type': 'RandomFlip', 'prob': 0.0},\n",
        "   {'type': 'PackDetInputs'}],\n",
        "  'backend_args': None,\n",
        "  'metainfo': {'classes': ('Bdr',\n",
        "    'Bone Loss',\n",
        "    'Bridge',\n",
        "    'Caries',\n",
        "    'Crown',\n",
        "    'Filling',\n",
        "    'Impaction',\n",
        "    'Implant',\n",
        "    'Periapical Abscess',\n",
        "    'Rct',\n",
        "    'Rct +Post',\n",
        "    'Retentive Pin',\n",
        "    'Shadow',\n",
        "    'Splinted Crowns',\n",
        "    'Unerupted')}}}\n",
        "cfg.optim_wrapper={'type': 'OptimWrapper',\n",
        " 'optimizer': {'type': 'SGD',\n",
        "  'lr': 0.005,\n",
        "  'momentum': 0.9,\n",
        "  'weight_decay': 0.0001}}\n",
        "cfg.log_processor.window_size=1774\n",
        "cfg.default_hooks.logger={'type': 'LoggerHook', 'interval': 1774}\n",
        "\n",
        "cfg.param_scheduler=[{'type': 'LinearLR',\n",
        "  'start_factor': 0.001,\n",
        "  'by_epoch': False,\n",
        "  'begin': 0,\n",
        "  'end': 500},\n",
        " {'type': 'MultiStepLR',\n",
        "  'begin': 0,\n",
        "  'end': 12,\n",
        "  'by_epoch': True,\n",
        "  'milestones': [21, 22],\n",
        "  'gamma': 0.1}]\n",
        "cfg['lr_config']={'step': [25, 30]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NWiyfYuvhh0T",
        "outputId": "aff565e7-ad83-4518-e43b-6e6a31068438"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive\n",
            "09/19 08:19:52 - mmengine - INFO - \n",
            "------------------------------------------------------------\n",
            "System environment:\n",
            "    sys.platform: linux\n",
            "    Python: 3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0]\n",
            "    CUDA available: True\n",
            "    numpy_random_seed: 1669051659\n",
            "    GPU 0: Tesla T4\n",
            "    CUDA_HOME: /usr/local/cuda\n",
            "    NVCC: Cuda compilation tools, release 11.8, V11.8.89\n",
            "    GCC: x86_64-linux-gnu-gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
            "    PyTorch: 2.0.1+cu118\n",
            "    PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 9.3\n",
            "  - C++ Version: 201703\n",
            "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 11.8\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
            "  - CuDNN 8.7\n",
            "  - Magma 2.6.1\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "    TorchVision: 0.15.2+cu118\n",
            "    OpenCV: 4.8.0\n",
            "    MMEngine: 0.8.4\n",
            "\n",
            "Runtime environment:\n",
            "    cudnn_benchmark: False\n",
            "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
            "    dist_cfg: {'backend': 'nccl'}\n",
            "    seed: 1669051659\n",
            "    Distributed launcher: none\n",
            "    Distributed training: False\n",
            "    GPU number: 1\n",
            "------------------------------------------------------------\n",
            "\n",
            "09/19 08:19:53 - mmengine - INFO - Config:\n",
            "auto_scale_lr = dict(base_batch_size=16, enable=False)\n",
            "backend_args = None\n",
            "classes = (\n",
            "    'Bdr',\n",
            "    'Bone Loss',\n",
            "    'Bridge',\n",
            "    'Caries',\n",
            "    'Crown',\n",
            "    'Filling',\n",
            "    'Impaction',\n",
            "    'Implant',\n",
            "    'Periapical Abscess',\n",
            "    'Rct',\n",
            "    'Rct +Post',\n",
            "    'Retentive Pin',\n",
            "    'Shadow',\n",
            "    'Splinted Crowns',\n",
            "    'Unerupted',\n",
            ")\n",
            "data_root = 'data/diagnosis'\n",
            "dataset_type = 'DiagnosisDataset'\n",
            "default_hooks = dict(\n",
            "    checkpoint=dict(interval=1, type='CheckpointHook'),\n",
            "    logger=dict(interval=1774, type='LoggerHook'),\n",
            "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    timer=dict(type='IterTimerHook'),\n",
            "    visualization=dict(type='DetVisualizationHook'))\n",
            "default_scope = 'mmdet'\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=False,\n",
            "    dist_cfg=dict(backend='nccl'),\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
            "load_from = '/content/drive/MyDrive/models/detectors_htc_r101_20e_coco_20210419_203638-348d533b.pth'\n",
            "log_level = 'INFO'\n",
            "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=1774)\n",
            "lr_config = dict(step=[\n",
            "    25,\n",
            "    30,\n",
            "])\n",
            "max_epochs = 20\n",
            "model = dict(\n",
            "    backbone=dict(\n",
            "        conv_cfg=dict(type='ConvAWS'),\n",
            "        depth=101,\n",
            "        frozen_stages=4,\n",
            "        init_cfg=dict(checkpoint='torchvision://resnet101', type='Pretrained'),\n",
            "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "        norm_eval=True,\n",
            "        num_stages=4,\n",
            "        out_indices=(\n",
            "            0,\n",
            "            1,\n",
            "            2,\n",
            "            3,\n",
            "        ),\n",
            "        output_img=True,\n",
            "        sac=dict(type='SAC', use_deform=True),\n",
            "        stage_with_sac=(\n",
            "            False,\n",
            "            True,\n",
            "            True,\n",
            "            True,\n",
            "        ),\n",
            "        style='pytorch',\n",
            "        type='DetectoRS_ResNet'),\n",
            "    data_preprocessor=dict(\n",
            "        bgr_to_rgb=True,\n",
            "        mean=[\n",
            "            123.675,\n",
            "            116.28,\n",
            "            103.53,\n",
            "        ],\n",
            "        pad_seg=True,\n",
            "        pad_size_divisor=32,\n",
            "        std=[\n",
            "            58.395,\n",
            "            57.12,\n",
            "            57.375,\n",
            "        ],\n",
            "        type='DetDataPreprocessor'),\n",
            "    neck=dict(\n",
            "        aspp_dilations=(\n",
            "            1,\n",
            "            3,\n",
            "            6,\n",
            "            1,\n",
            "        ),\n",
            "        aspp_out_channels=64,\n",
            "        in_channels=[\n",
            "            256,\n",
            "            512,\n",
            "            1024,\n",
            "            2048,\n",
            "        ],\n",
            "        num_outs=5,\n",
            "        out_channels=256,\n",
            "        rfp_backbone=dict(\n",
            "            conv_cfg=dict(type='ConvAWS'),\n",
            "            depth=101,\n",
            "            frozen_stages=1,\n",
            "            norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "            norm_eval=True,\n",
            "            num_stages=4,\n",
            "            out_indices=(\n",
            "                0,\n",
            "                1,\n",
            "                2,\n",
            "                3,\n",
            "            ),\n",
            "            pretrained='torchvision://resnet101',\n",
            "            rfp_inplanes=256,\n",
            "            sac=dict(type='SAC', use_deform=True),\n",
            "            stage_with_sac=(\n",
            "                False,\n",
            "                True,\n",
            "                True,\n",
            "                True,\n",
            "            ),\n",
            "            style='pytorch',\n",
            "            type='DetectoRS_ResNet'),\n",
            "        rfp_steps=2,\n",
            "        type='RFP'),\n",
            "    roi_head=dict(\n",
            "        bbox_head=[\n",
            "            dict(\n",
            "                bbox_coder=dict(\n",
            "                    target_means=[\n",
            "                        0.0,\n",
            "                        0.0,\n",
            "                        0.0,\n",
            "                        0.0,\n",
            "                    ],\n",
            "                    target_stds=[\n",
            "                        0.1,\n",
            "                        0.1,\n",
            "                        0.2,\n",
            "                        0.2,\n",
            "                    ],\n",
            "                    type='DeltaXYWHBBoxCoder'),\n",
            "                fc_out_channels=1024,\n",
            "                in_channels=256,\n",
            "                loss_bbox=dict(beta=1.0, loss_weight=1.0, type='SmoothL1Loss'),\n",
            "                loss_cls=dict(\n",
            "                    loss_weight=1.0,\n",
            "                    type='CrossEntropyLoss',\n",
            "                    use_sigmoid=False),\n",
            "                num_classes=80,\n",
            "                reg_class_agnostic=True,\n",
            "                roi_feat_size=7,\n",
            "                type='Shared2FCBBoxHead'),\n",
            "            dict(\n",
            "                bbox_coder=dict(\n",
            "                    target_means=[\n",
            "                        0.0,\n",
            "                        0.0,\n",
            "                        0.0,\n",
            "                        0.0,\n",
            "                    ],\n",
            "                    target_stds=[\n",
            "                        0.05,\n",
            "                        0.05,\n",
            "                        0.1,\n",
            "                        0.1,\n",
            "                    ],\n",
            "                    type='DeltaXYWHBBoxCoder'),\n",
            "                fc_out_channels=1024,\n",
            "                in_channels=256,\n",
            "                loss_bbox=dict(beta=1.0, loss_weight=1.0, type='SmoothL1Loss'),\n",
            "                loss_cls=dict(\n",
            "                    loss_weight=1.0,\n",
            "                    type='CrossEntropyLoss',\n",
            "                    use_sigmoid=False),\n",
            "                num_classes=80,\n",
            "                reg_class_agnostic=True,\n",
            "                roi_feat_size=7,\n",
            "                type='Shared2FCBBoxHead'),\n",
            "            dict(\n",
            "                bbox_coder=dict(\n",
            "                    target_means=[\n",
            "                        0.0,\n",
            "                        0.0,\n",
            "                        0.0,\n",
            "                        0.0,\n",
            "                    ],\n",
            "                    target_stds=[\n",
            "                        0.033,\n",
            "                        0.033,\n",
            "                        0.067,\n",
            "                        0.067,\n",
            "                    ],\n",
            "                    type='DeltaXYWHBBoxCoder'),\n",
            "                fc_out_channels=1024,\n",
            "                in_channels=256,\n",
            "                loss_bbox=dict(beta=1.0, loss_weight=1.0, type='SmoothL1Loss'),\n",
            "                loss_cls=dict(\n",
            "                    loss_weight=1.0,\n",
            "                    type='CrossEntropyLoss',\n",
            "                    use_sigmoid=False),\n",
            "                num_classes=80,\n",
            "                reg_class_agnostic=True,\n",
            "                roi_feat_size=7,\n",
            "                type='Shared2FCBBoxHead'),\n",
            "        ],\n",
            "        bbox_roi_extractor=dict(\n",
            "            featmap_strides=[\n",
            "                4,\n",
            "                8,\n",
            "                16,\n",
            "                32,\n",
            "            ],\n",
            "            out_channels=256,\n",
            "            roi_layer=dict(output_size=7, sampling_ratio=0, type='RoIAlign'),\n",
            "            type='SingleRoIExtractor'),\n",
            "        interleaved=True,\n",
            "        mask_head=[\n",
            "            dict(\n",
            "                conv_out_channels=256,\n",
            "                in_channels=256,\n",
            "                loss_mask=dict(\n",
            "                    loss_weight=1.0, type='CrossEntropyLoss', use_mask=True),\n",
            "                num_classes=80,\n",
            "                num_convs=4,\n",
            "                type='HTCMaskHead',\n",
            "                with_conv_res=False),\n",
            "            dict(\n",
            "                conv_out_channels=256,\n",
            "                in_channels=256,\n",
            "                loss_mask=dict(\n",
            "                    loss_weight=1.0, type='CrossEntropyLoss', use_mask=True),\n",
            "                num_classes=80,\n",
            "                num_convs=4,\n",
            "                type='HTCMaskHead'),\n",
            "            dict(\n",
            "                conv_out_channels=256,\n",
            "                in_channels=256,\n",
            "                loss_mask=dict(\n",
            "                    loss_weight=1.0, type='CrossEntropyLoss', use_mask=True),\n",
            "                num_classes=80,\n",
            "                num_convs=4,\n",
            "                type='HTCMaskHead'),\n",
            "        ],\n",
            "        mask_info_flow=True,\n",
            "        mask_roi_extractor=dict(\n",
            "            featmap_strides=[\n",
            "                4,\n",
            "                8,\n",
            "                16,\n",
            "                32,\n",
            "            ],\n",
            "            out_channels=256,\n",
            "            roi_layer=dict(output_size=14, sampling_ratio=0, type='RoIAlign'),\n",
            "            type='SingleRoIExtractor'),\n",
            "        num_stages=3,\n",
            "        semantic_head=dict(\n",
            "            conv_out_channels=256,\n",
            "            fusion_level=1,\n",
            "            in_channels=256,\n",
            "            loss_seg=dict(\n",
            "                ignore_index=255, loss_weight=0.2, type='CrossEntropyLoss'),\n",
            "            num_classes=183,\n",
            "            num_convs=4,\n",
            "            num_ins=5,\n",
            "            seg_scale_factor=0.125,\n",
            "            type='FusedSemanticHead'),\n",
            "        semantic_roi_extractor=dict(\n",
            "            featmap_strides=[\n",
            "                8,\n",
            "            ],\n",
            "            out_channels=256,\n",
            "            roi_layer=dict(output_size=14, sampling_ratio=0, type='RoIAlign'),\n",
            "            type='SingleRoIExtractor'),\n",
            "        stage_loss_weights=[\n",
            "            1,\n",
            "            0.5,\n",
            "            0.25,\n",
            "        ],\n",
            "        type='HybridTaskCascadeRoIHead'),\n",
            "    rpn_head=dict(\n",
            "        anchor_generator=dict(\n",
            "            ratios=[\n",
            "                0.5,\n",
            "                1.0,\n",
            "                2.0,\n",
            "            ],\n",
            "            scales=[\n",
            "                8,\n",
            "            ],\n",
            "            strides=[\n",
            "                4,\n",
            "                8,\n",
            "                16,\n",
            "                32,\n",
            "                64,\n",
            "            ],\n",
            "            type='AnchorGenerator'),\n",
            "        bbox_coder=dict(\n",
            "            target_means=[\n",
            "                0.0,\n",
            "                0.0,\n",
            "                0.0,\n",
            "                0.0,\n",
            "            ],\n",
            "            target_stds=[\n",
            "                1.0,\n",
            "                1.0,\n",
            "                1.0,\n",
            "                1.0,\n",
            "            ],\n",
            "            type='DeltaXYWHBBoxCoder'),\n",
            "        feat_channels=256,\n",
            "        in_channels=256,\n",
            "        loss_bbox=dict(\n",
            "            beta=0.1111111111111111, loss_weight=1.0, type='SmoothL1Loss'),\n",
            "        loss_cls=dict(\n",
            "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=True),\n",
            "        type='RPNHead'),\n",
            "    test_cfg=dict(\n",
            "        rcnn=dict(\n",
            "            mask_thr_binary=0.5,\n",
            "            max_per_img=100,\n",
            "            nms=dict(iou_threshold=0.5, type='nms'),\n",
            "            score_thr=0.001),\n",
            "        rpn=dict(\n",
            "            max_per_img=1000,\n",
            "            min_bbox_size=0,\n",
            "            nms=dict(iou_threshold=0.7, type='nms'),\n",
            "            nms_pre=1000)),\n",
            "    train_cfg=dict(\n",
            "        rcnn=[\n",
            "            dict(\n",
            "                assigner=dict(\n",
            "                    ignore_iof_thr=-1,\n",
            "                    min_pos_iou=0.5,\n",
            "                    neg_iou_thr=0.5,\n",
            "                    pos_iou_thr=0.5,\n",
            "                    type='MaxIoUAssigner'),\n",
            "                debug=False,\n",
            "                mask_size=28,\n",
            "                pos_weight=-1,\n",
            "                sampler=dict(\n",
            "                    add_gt_as_proposals=True,\n",
            "                    neg_pos_ub=-1,\n",
            "                    num=512,\n",
            "                    pos_fraction=0.25,\n",
            "                    type='RandomSampler')),\n",
            "            dict(\n",
            "                assigner=dict(\n",
            "                    ignore_iof_thr=-1,\n",
            "                    min_pos_iou=0.6,\n",
            "                    neg_iou_thr=0.6,\n",
            "                    pos_iou_thr=0.6,\n",
            "                    type='MaxIoUAssigner'),\n",
            "                debug=False,\n",
            "                mask_size=28,\n",
            "                pos_weight=-1,\n",
            "                sampler=dict(\n",
            "                    add_gt_as_proposals=True,\n",
            "                    neg_pos_ub=-1,\n",
            "                    num=512,\n",
            "                    pos_fraction=0.25,\n",
            "                    type='RandomSampler')),\n",
            "            dict(\n",
            "                assigner=dict(\n",
            "                    ignore_iof_thr=-1,\n",
            "                    min_pos_iou=0.7,\n",
            "                    neg_iou_thr=0.7,\n",
            "                    pos_iou_thr=0.7,\n",
            "                    type='MaxIoUAssigner'),\n",
            "                debug=False,\n",
            "                mask_size=28,\n",
            "                pos_weight=-1,\n",
            "                sampler=dict(\n",
            "                    add_gt_as_proposals=True,\n",
            "                    neg_pos_ub=-1,\n",
            "                    num=512,\n",
            "                    pos_fraction=0.25,\n",
            "                    type='RandomSampler')),\n",
            "        ],\n",
            "        rpn=dict(\n",
            "            allowed_border=0,\n",
            "            assigner=dict(\n",
            "                ignore_iof_thr=-1,\n",
            "                min_pos_iou=0.3,\n",
            "                neg_iou_thr=0.3,\n",
            "                pos_iou_thr=0.7,\n",
            "                type='MaxIoUAssigner'),\n",
            "            debug=False,\n",
            "            pos_weight=-1,\n",
            "            sampler=dict(\n",
            "                add_gt_as_proposals=False,\n",
            "                neg_pos_ub=-1,\n",
            "                num=256,\n",
            "                pos_fraction=0.5,\n",
            "                type='RandomSampler')),\n",
            "        rpn_proposal=dict(\n",
            "            max_per_img=2000,\n",
            "            min_bbox_size=0,\n",
            "            nms=dict(iou_threshold=0.7, type='nms'),\n",
            "            nms_pre=2000)),\n",
            "    type='HybridTaskCascade')\n",
            "optim_wrapper = dict(\n",
            "    optimizer=dict(lr=0.005, momentum=0.9, type='SGD', weight_decay=0.0001),\n",
            "    type='OptimWrapper')\n",
            "param_scheduler = [\n",
            "    dict(\n",
            "        begin=0, by_epoch=False, end=500, start_factor=0.001, type='LinearLR'),\n",
            "    dict(\n",
            "        begin=0,\n",
            "        by_epoch=True,\n",
            "        end=12,\n",
            "        gamma=0.1,\n",
            "        milestones=[\n",
            "            21,\n",
            "            22,\n",
            "        ],\n",
            "        type='MultiStepLR'),\n",
            "]\n",
            "resume = False\n",
            "test_cfg = dict(type='TestLoop')\n",
            "test_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='ann/val.json',\n",
            "        backend_args=None,\n",
            "        data_prefix=dict(img='valid/'),\n",
            "        data_root='data/diagnosis',\n",
            "        metainfo=dict(\n",
            "            classes=(\n",
            "                'Bdr',\n",
            "                'Bone Loss',\n",
            "                'Bridge',\n",
            "                'Caries',\n",
            "                'Crown',\n",
            "                'Filling',\n",
            "                'Impaction',\n",
            "                'Implant',\n",
            "                'Periapical Abscess',\n",
            "                'Rct',\n",
            "                'Rct +Post',\n",
            "                'Retentive Pin',\n",
            "                'Shadow',\n",
            "                'Splinted Crowns',\n",
            "                'Unerupted',\n",
            "            )),\n",
            "        pipeline=[\n",
            "            dict(backend_args=None, type='LoadImageFromFile'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                1333,\n",
            "                800,\n",
            "            ), type='Resize'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'img_id',\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'scale_factor',\n",
            "                ),\n",
            "                type='PackDetInputs'),\n",
            "        ],\n",
            "        test_mode=True,\n",
            "        type='DiagnosisDataset'),\n",
            "    drop_last=False,\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "test_evaluator = dict(\n",
            "    ann_file='/content/drive/MyDrive/data/diagnosis/ann/val.json',\n",
            "    backend_args=None,\n",
            "    format_only=False,\n",
            "    metric=[\n",
            "        'bbox',\n",
            "        'segm',\n",
            "    ],\n",
            "    type='CocoMetric')\n",
            "test_pipeline = [\n",
            "    dict(backend_args=None, type='LoadImageFromFile'),\n",
            "    dict(keep_ratio=True, scale=(\n",
            "        1333,\n",
            "        800,\n",
            "    ), type='Resize'),\n",
            "    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
            "    dict(\n",
            "        meta_keys=(\n",
            "            'img_id',\n",
            "            'img_path',\n",
            "            'ori_shape',\n",
            "            'img_shape',\n",
            "            'scale_factor',\n",
            "        ),\n",
            "        type='PackDetInputs'),\n",
            "]\n",
            "train_cfg = dict(max_epochs=10, type='EpochBasedTrainLoop', val_interval=1)\n",
            "train_dataloader = dict(\n",
            "    batch_sampler=dict(type='AspectRatioBatchSampler'),\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='ann/train.json',\n",
            "        backend_args=None,\n",
            "        data_prefix=dict(img='train/'),\n",
            "        data_root='/content/drive/MyDrive/data/diagnosis',\n",
            "        filter_cfg=dict(filter_empty_gt=False, min_size=16),\n",
            "        metainfo=dict(\n",
            "            classes=(\n",
            "                'Bdr',\n",
            "                'Bone Loss',\n",
            "                'Bridge',\n",
            "                'Caries',\n",
            "                'Crown',\n",
            "                'Filling',\n",
            "                'Impaction',\n",
            "                'Implant',\n",
            "                'Periapical Abscess',\n",
            "                'Rct',\n",
            "                'Rct +Post',\n",
            "                'Retentive Pin',\n",
            "                'Shadow',\n",
            "                'Splinted Crowns',\n",
            "                'Unerupted',\n",
            "            )),\n",
            "        pipeline=[\n",
            "            dict(backend_args=None, type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                1333,\n",
            "                800,\n",
            "            ), type='Resize'),\n",
            "            dict(prob=0.0, type='RandomFlip'),\n",
            "            dict(type='PackDetInputs'),\n",
            "        ],\n",
            "        type='DiagnosisDataset'),\n",
            "    num_workers=8,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
            "train_pipeline = [\n",
            "    dict(backend_args=None, type='LoadImageFromFile'),\n",
            "    dict(\n",
            "        type='LoadAnnotations', with_bbox=True, with_mask=True, with_seg=True),\n",
            "    dict(keep_ratio=True, scale=(\n",
            "        1333,\n",
            "        800,\n",
            "    ), type='Resize'),\n",
            "    dict(prob=0.5, type='RandomFlip'),\n",
            "    dict(type='PackDetInputs'),\n",
            "]\n",
            "val_cfg = dict(type='ValLoop')\n",
            "val_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='ann/val.json',\n",
            "        backend_args=None,\n",
            "        data_prefix=dict(img='valid/'),\n",
            "        data_root='data/diagnosis',\n",
            "        metainfo=dict(\n",
            "            classes=(\n",
            "                'Bdr',\n",
            "                'Bone Loss',\n",
            "                'Bridge',\n",
            "                'Caries',\n",
            "                'Crown',\n",
            "                'Filling',\n",
            "                'Impaction',\n",
            "                'Implant',\n",
            "                'Periapical Abscess',\n",
            "                'Rct',\n",
            "                'Rct +Post',\n",
            "                'Retentive Pin',\n",
            "                'Shadow',\n",
            "                'Splinted Crowns',\n",
            "                'Unerupted',\n",
            "            )),\n",
            "        pipeline=[\n",
            "            dict(backend_args=None, type='LoadImageFromFile'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                1333,\n",
            "                800,\n",
            "            ), type='Resize'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'img_id',\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'scale_factor',\n",
            "                ),\n",
            "                type='PackDetInputs'),\n",
            "        ],\n",
            "        test_mode=True,\n",
            "        type='DiagnosisDataset'),\n",
            "    drop_last=False,\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "val_evaluator = dict(\n",
            "    ann_file='/content/drive/MyDrive/data/diagnosis/ann/val.json',\n",
            "    backend_args=None,\n",
            "    format_only=False,\n",
            "    metric=[\n",
            "        'bbox',\n",
            "        'segm',\n",
            "    ],\n",
            "    type='CocoMetric')\n",
            "vis_backends = [\n",
            "    dict(type='LocalVisBackend'),\n",
            "]\n",
            "visualizer = dict(\n",
            "    name='visualizer',\n",
            "    type='DetLocalVisualizer',\n",
            "    vis_backends=[\n",
            "        dict(type='LocalVisBackend'),\n",
            "    ])\n",
            "work_dir = 'C:\\\\Users\\\\HP\\\\mmdetection\\\\demo\\\\work_dir'\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/mmdetection/mmdet/models/losses/cross_entropy_loss.py:239: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "09/19 08:20:03 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
            "09/19 08:20:03 - mmengine - INFO - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "before_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DistSamplerSeedHook                \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DetVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_test_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DetVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_run:\n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "loading annotations into memory...\n",
            "Done (t=1.55s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.68s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "09/19 08:20:08 - mmengine - INFO - Loads checkpoint by torchvision backend from path: torchvision://resnet101\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet101-63fe2227.pth\" to /root/.cache/torch/hub/checkpoints/resnet101-63fe2227.pth\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "09/19 08:20:11 - mmengine - WARNING - The model and loaded state dict do not match exactly\n",
            "\n",
            "unexpected key in source state_dict: fc.weight, fc.bias\n",
            "\n",
            "missing keys in source state_dict: layer2.0.conv2.weight_diff, layer2.0.conv2.switch.weight, layer2.0.conv2.switch.bias, layer2.0.conv2.pre_context.weight, layer2.0.conv2.pre_context.bias, layer2.0.conv2.post_context.weight, layer2.0.conv2.post_context.bias, layer2.0.conv2.offset_s.weight, layer2.0.conv2.offset_s.bias, layer2.0.conv2.offset_l.weight, layer2.0.conv2.offset_l.bias, layer2.1.conv2.weight_diff, layer2.1.conv2.switch.weight, layer2.1.conv2.switch.bias, layer2.1.conv2.pre_context.weight, layer2.1.conv2.pre_context.bias, layer2.1.conv2.post_context.weight, layer2.1.conv2.post_context.bias, layer2.1.conv2.offset_s.weight, layer2.1.conv2.offset_s.bias, layer2.1.conv2.offset_l.weight, layer2.1.conv2.offset_l.bias, layer2.2.conv2.weight_diff, layer2.2.conv2.switch.weight, layer2.2.conv2.switch.bias, layer2.2.conv2.pre_context.weight, layer2.2.conv2.pre_context.bias, layer2.2.conv2.post_context.weight, layer2.2.conv2.post_context.bias, layer2.2.conv2.offset_s.weight, layer2.2.conv2.offset_s.bias, layer2.2.conv2.offset_l.weight, layer2.2.conv2.offset_l.bias, layer2.3.conv2.weight_diff, layer2.3.conv2.switch.weight, layer2.3.conv2.switch.bias, layer2.3.conv2.pre_context.weight, layer2.3.conv2.pre_context.bias, layer2.3.conv2.post_context.weight, layer2.3.conv2.post_context.bias, layer2.3.conv2.offset_s.weight, layer2.3.conv2.offset_s.bias, layer2.3.conv2.offset_l.weight, layer2.3.conv2.offset_l.bias, layer3.0.conv2.weight_diff, layer3.0.conv2.switch.weight, layer3.0.conv2.switch.bias, layer3.0.conv2.pre_context.weight, layer3.0.conv2.pre_context.bias, layer3.0.conv2.post_context.weight, layer3.0.conv2.post_context.bias, layer3.0.conv2.offset_s.weight, layer3.0.conv2.offset_s.bias, layer3.0.conv2.offset_l.weight, layer3.0.conv2.offset_l.bias, layer3.1.conv2.weight_diff, layer3.1.conv2.switch.weight, layer3.1.conv2.switch.bias, layer3.1.conv2.pre_context.weight, layer3.1.conv2.pre_context.bias, layer3.1.conv2.post_context.weight, layer3.1.conv2.post_context.bias, layer3.1.conv2.offset_s.weight, layer3.1.conv2.offset_s.bias, layer3.1.conv2.offset_l.weight, layer3.1.conv2.offset_l.bias, layer3.2.conv2.weight_diff, layer3.2.conv2.switch.weight, layer3.2.conv2.switch.bias, layer3.2.conv2.pre_context.weight, layer3.2.conv2.pre_context.bias, layer3.2.conv2.post_context.weight, layer3.2.conv2.post_context.bias, layer3.2.conv2.offset_s.weight, layer3.2.conv2.offset_s.bias, layer3.2.conv2.offset_l.weight, layer3.2.conv2.offset_l.bias, layer3.3.conv2.weight_diff, layer3.3.conv2.switch.weight, layer3.3.conv2.switch.bias, layer3.3.conv2.pre_context.weight, layer3.3.conv2.pre_context.bias, layer3.3.conv2.post_context.weight, layer3.3.conv2.post_context.bias, layer3.3.conv2.offset_s.weight, layer3.3.conv2.offset_s.bias, layer3.3.conv2.offset_l.weight, layer3.3.conv2.offset_l.bias, layer3.4.conv2.weight_diff, layer3.4.conv2.switch.weight, layer3.4.conv2.switch.bias, layer3.4.conv2.pre_context.weight, layer3.4.conv2.pre_context.bias, layer3.4.conv2.post_context.weight, layer3.4.conv2.post_context.bias, layer3.4.conv2.offset_s.weight, layer3.4.conv2.offset_s.bias, layer3.4.conv2.offset_l.weight, layer3.4.conv2.offset_l.bias, layer3.5.conv2.weight_diff, layer3.5.conv2.switch.weight, layer3.5.conv2.switch.bias, layer3.5.conv2.pre_context.weight, layer3.5.conv2.pre_context.bias, layer3.5.conv2.post_context.weight, layer3.5.conv2.post_context.bias, layer3.5.conv2.offset_s.weight, layer3.5.conv2.offset_s.bias, layer3.5.conv2.offset_l.weight, layer3.5.conv2.offset_l.bias, layer3.6.conv2.weight_diff, layer3.6.conv2.switch.weight, layer3.6.conv2.switch.bias, layer3.6.conv2.pre_context.weight, layer3.6.conv2.pre_context.bias, layer3.6.conv2.post_context.weight, layer3.6.conv2.post_context.bias, layer3.6.conv2.offset_s.weight, layer3.6.conv2.offset_s.bias, layer3.6.conv2.offset_l.weight, layer3.6.conv2.offset_l.bias, layer3.7.conv2.weight_diff, layer3.7.conv2.switch.weight, layer3.7.conv2.switch.bias, layer3.7.conv2.pre_context.weight, layer3.7.conv2.pre_context.bias, layer3.7.conv2.post_context.weight, layer3.7.conv2.post_context.bias, layer3.7.conv2.offset_s.weight, layer3.7.conv2.offset_s.bias, layer3.7.conv2.offset_l.weight, layer3.7.conv2.offset_l.bias, layer3.8.conv2.weight_diff, layer3.8.conv2.switch.weight, layer3.8.conv2.switch.bias, layer3.8.conv2.pre_context.weight, layer3.8.conv2.pre_context.bias, layer3.8.conv2.post_context.weight, layer3.8.conv2.post_context.bias, layer3.8.conv2.offset_s.weight, layer3.8.conv2.offset_s.bias, layer3.8.conv2.offset_l.weight, layer3.8.conv2.offset_l.bias, layer3.9.conv2.weight_diff, layer3.9.conv2.switch.weight, layer3.9.conv2.switch.bias, layer3.9.conv2.pre_context.weight, layer3.9.conv2.pre_context.bias, layer3.9.conv2.post_context.weight, layer3.9.conv2.post_context.bias, layer3.9.conv2.offset_s.weight, layer3.9.conv2.offset_s.bias, layer3.9.conv2.offset_l.weight, layer3.9.conv2.offset_l.bias, layer3.10.conv2.weight_diff, layer3.10.conv2.switch.weight, layer3.10.conv2.switch.bias, layer3.10.conv2.pre_context.weight, layer3.10.conv2.pre_context.bias, layer3.10.conv2.post_context.weight, layer3.10.conv2.post_context.bias, layer3.10.conv2.offset_s.weight, layer3.10.conv2.offset_s.bias, layer3.10.conv2.offset_l.weight, layer3.10.conv2.offset_l.bias, layer3.11.conv2.weight_diff, layer3.11.conv2.switch.weight, layer3.11.conv2.switch.bias, layer3.11.conv2.pre_context.weight, layer3.11.conv2.pre_context.bias, layer3.11.conv2.post_context.weight, layer3.11.conv2.post_context.bias, layer3.11.conv2.offset_s.weight, layer3.11.conv2.offset_s.bias, layer3.11.conv2.offset_l.weight, layer3.11.conv2.offset_l.bias, layer3.12.conv2.weight_diff, layer3.12.conv2.switch.weight, layer3.12.conv2.switch.bias, layer3.12.conv2.pre_context.weight, layer3.12.conv2.pre_context.bias, layer3.12.conv2.post_context.weight, layer3.12.conv2.post_context.bias, layer3.12.conv2.offset_s.weight, layer3.12.conv2.offset_s.bias, layer3.12.conv2.offset_l.weight, layer3.12.conv2.offset_l.bias, layer3.13.conv2.weight_diff, layer3.13.conv2.switch.weight, layer3.13.conv2.switch.bias, layer3.13.conv2.pre_context.weight, layer3.13.conv2.pre_context.bias, layer3.13.conv2.post_context.weight, layer3.13.conv2.post_context.bias, layer3.13.conv2.offset_s.weight, layer3.13.conv2.offset_s.bias, layer3.13.conv2.offset_l.weight, layer3.13.conv2.offset_l.bias, layer3.14.conv2.weight_diff, layer3.14.conv2.switch.weight, layer3.14.conv2.switch.bias, layer3.14.conv2.pre_context.weight, layer3.14.conv2.pre_context.bias, layer3.14.conv2.post_context.weight, layer3.14.conv2.post_context.bias, layer3.14.conv2.offset_s.weight, layer3.14.conv2.offset_s.bias, layer3.14.conv2.offset_l.weight, layer3.14.conv2.offset_l.bias, layer3.15.conv2.weight_diff, layer3.15.conv2.switch.weight, layer3.15.conv2.switch.bias, layer3.15.conv2.pre_context.weight, layer3.15.conv2.pre_context.bias, layer3.15.conv2.post_context.weight, layer3.15.conv2.post_context.bias, layer3.15.conv2.offset_s.weight, layer3.15.conv2.offset_s.bias, layer3.15.conv2.offset_l.weight, layer3.15.conv2.offset_l.bias, layer3.16.conv2.weight_diff, layer3.16.conv2.switch.weight, layer3.16.conv2.switch.bias, layer3.16.conv2.pre_context.weight, layer3.16.conv2.pre_context.bias, layer3.16.conv2.post_context.weight, layer3.16.conv2.post_context.bias, layer3.16.conv2.offset_s.weight, layer3.16.conv2.offset_s.bias, layer3.16.conv2.offset_l.weight, layer3.16.conv2.offset_l.bias, layer3.17.conv2.weight_diff, layer3.17.conv2.switch.weight, layer3.17.conv2.switch.bias, layer3.17.conv2.pre_context.weight, layer3.17.conv2.pre_context.bias, layer3.17.conv2.post_context.weight, layer3.17.conv2.post_context.bias, layer3.17.conv2.offset_s.weight, layer3.17.conv2.offset_s.bias, layer3.17.conv2.offset_l.weight, layer3.17.conv2.offset_l.bias, layer3.18.conv2.weight_diff, layer3.18.conv2.switch.weight, layer3.18.conv2.switch.bias, layer3.18.conv2.pre_context.weight, layer3.18.conv2.pre_context.bias, layer3.18.conv2.post_context.weight, layer3.18.conv2.post_context.bias, layer3.18.conv2.offset_s.weight, layer3.18.conv2.offset_s.bias, layer3.18.conv2.offset_l.weight, layer3.18.conv2.offset_l.bias, layer3.19.conv2.weight_diff, layer3.19.conv2.switch.weight, layer3.19.conv2.switch.bias, layer3.19.conv2.pre_context.weight, layer3.19.conv2.pre_context.bias, layer3.19.conv2.post_context.weight, layer3.19.conv2.post_context.bias, layer3.19.conv2.offset_s.weight, layer3.19.conv2.offset_s.bias, layer3.19.conv2.offset_l.weight, layer3.19.conv2.offset_l.bias, layer3.20.conv2.weight_diff, layer3.20.conv2.switch.weight, layer3.20.conv2.switch.bias, layer3.20.conv2.pre_context.weight, layer3.20.conv2.pre_context.bias, layer3.20.conv2.post_context.weight, layer3.20.conv2.post_context.bias, layer3.20.conv2.offset_s.weight, layer3.20.conv2.offset_s.bias, layer3.20.conv2.offset_l.weight, layer3.20.conv2.offset_l.bias, layer3.21.conv2.weight_diff, layer3.21.conv2.switch.weight, layer3.21.conv2.switch.bias, layer3.21.conv2.pre_context.weight, layer3.21.conv2.pre_context.bias, layer3.21.conv2.post_context.weight, layer3.21.conv2.post_context.bias, layer3.21.conv2.offset_s.weight, layer3.21.conv2.offset_s.bias, layer3.21.conv2.offset_l.weight, layer3.21.conv2.offset_l.bias, layer3.22.conv2.weight_diff, layer3.22.conv2.switch.weight, layer3.22.conv2.switch.bias, layer3.22.conv2.pre_context.weight, layer3.22.conv2.pre_context.bias, layer3.22.conv2.post_context.weight, layer3.22.conv2.post_context.bias, layer3.22.conv2.offset_s.weight, layer3.22.conv2.offset_s.bias, layer3.22.conv2.offset_l.weight, layer3.22.conv2.offset_l.bias, layer4.0.conv2.weight_diff, layer4.0.conv2.switch.weight, layer4.0.conv2.switch.bias, layer4.0.conv2.pre_context.weight, layer4.0.conv2.pre_context.bias, layer4.0.conv2.post_context.weight, layer4.0.conv2.post_context.bias, layer4.0.conv2.offset_s.weight, layer4.0.conv2.offset_s.bias, layer4.0.conv2.offset_l.weight, layer4.0.conv2.offset_l.bias, layer4.1.conv2.weight_diff, layer4.1.conv2.switch.weight, layer4.1.conv2.switch.bias, layer4.1.conv2.pre_context.weight, layer4.1.conv2.pre_context.bias, layer4.1.conv2.post_context.weight, layer4.1.conv2.post_context.bias, layer4.1.conv2.offset_s.weight, layer4.1.conv2.offset_s.bias, layer4.1.conv2.offset_l.weight, layer4.1.conv2.offset_l.bias, layer4.2.conv2.weight_diff, layer4.2.conv2.switch.weight, layer4.2.conv2.switch.bias, layer4.2.conv2.pre_context.weight, layer4.2.conv2.pre_context.bias, layer4.2.conv2.post_context.weight, layer4.2.conv2.post_context.bias, layer4.2.conv2.offset_s.weight, layer4.2.conv2.offset_s.bias, layer4.2.conv2.offset_l.weight, layer4.2.conv2.offset_l.bias\n",
            "\n",
            "09/19 08:20:11 - mmengine - INFO - Loads checkpoint by torchvision backend from path: torchvision://resnet101\n",
            "09/19 08:20:11 - mmengine - WARNING - The model and loaded state dict do not match exactly\n",
            "\n",
            "unexpected key in source state_dict: fc.weight, fc.bias\n",
            "\n",
            "missing keys in source state_dict: layer2.0.conv2.weight_diff, layer2.0.conv2.switch.weight, layer2.0.conv2.switch.bias, layer2.0.conv2.pre_context.weight, layer2.0.conv2.pre_context.bias, layer2.0.conv2.post_context.weight, layer2.0.conv2.post_context.bias, layer2.0.conv2.offset_s.weight, layer2.0.conv2.offset_s.bias, layer2.0.conv2.offset_l.weight, layer2.0.conv2.offset_l.bias, layer2.0.rfp_conv.weight, layer2.0.rfp_conv.bias, layer2.1.conv2.weight_diff, layer2.1.conv2.switch.weight, layer2.1.conv2.switch.bias, layer2.1.conv2.pre_context.weight, layer2.1.conv2.pre_context.bias, layer2.1.conv2.post_context.weight, layer2.1.conv2.post_context.bias, layer2.1.conv2.offset_s.weight, layer2.1.conv2.offset_s.bias, layer2.1.conv2.offset_l.weight, layer2.1.conv2.offset_l.bias, layer2.2.conv2.weight_diff, layer2.2.conv2.switch.weight, layer2.2.conv2.switch.bias, layer2.2.conv2.pre_context.weight, layer2.2.conv2.pre_context.bias, layer2.2.conv2.post_context.weight, layer2.2.conv2.post_context.bias, layer2.2.conv2.offset_s.weight, layer2.2.conv2.offset_s.bias, layer2.2.conv2.offset_l.weight, layer2.2.conv2.offset_l.bias, layer2.3.conv2.weight_diff, layer2.3.conv2.switch.weight, layer2.3.conv2.switch.bias, layer2.3.conv2.pre_context.weight, layer2.3.conv2.pre_context.bias, layer2.3.conv2.post_context.weight, layer2.3.conv2.post_context.bias, layer2.3.conv2.offset_s.weight, layer2.3.conv2.offset_s.bias, layer2.3.conv2.offset_l.weight, layer2.3.conv2.offset_l.bias, layer3.0.conv2.weight_diff, layer3.0.conv2.switch.weight, layer3.0.conv2.switch.bias, layer3.0.conv2.pre_context.weight, layer3.0.conv2.pre_context.bias, layer3.0.conv2.post_context.weight, layer3.0.conv2.post_context.bias, layer3.0.conv2.offset_s.weight, layer3.0.conv2.offset_s.bias, layer3.0.conv2.offset_l.weight, layer3.0.conv2.offset_l.bias, layer3.0.rfp_conv.weight, layer3.0.rfp_conv.bias, layer3.1.conv2.weight_diff, layer3.1.conv2.switch.weight, layer3.1.conv2.switch.bias, layer3.1.conv2.pre_context.weight, layer3.1.conv2.pre_context.bias, layer3.1.conv2.post_context.weight, layer3.1.conv2.post_context.bias, layer3.1.conv2.offset_s.weight, layer3.1.conv2.offset_s.bias, layer3.1.conv2.offset_l.weight, layer3.1.conv2.offset_l.bias, layer3.2.conv2.weight_diff, layer3.2.conv2.switch.weight, layer3.2.conv2.switch.bias, layer3.2.conv2.pre_context.weight, layer3.2.conv2.pre_context.bias, layer3.2.conv2.post_context.weight, layer3.2.conv2.post_context.bias, layer3.2.conv2.offset_s.weight, layer3.2.conv2.offset_s.bias, layer3.2.conv2.offset_l.weight, layer3.2.conv2.offset_l.bias, layer3.3.conv2.weight_diff, layer3.3.conv2.switch.weight, layer3.3.conv2.switch.bias, layer3.3.conv2.pre_context.weight, layer3.3.conv2.pre_context.bias, layer3.3.conv2.post_context.weight, layer3.3.conv2.post_context.bias, layer3.3.conv2.offset_s.weight, layer3.3.conv2.offset_s.bias, layer3.3.conv2.offset_l.weight, layer3.3.conv2.offset_l.bias, layer3.4.conv2.weight_diff, layer3.4.conv2.switch.weight, layer3.4.conv2.switch.bias, layer3.4.conv2.pre_context.weight, layer3.4.conv2.pre_context.bias, layer3.4.conv2.post_context.weight, layer3.4.conv2.post_context.bias, layer3.4.conv2.offset_s.weight, layer3.4.conv2.offset_s.bias, layer3.4.conv2.offset_l.weight, layer3.4.conv2.offset_l.bias, layer3.5.conv2.weight_diff, layer3.5.conv2.switch.weight, layer3.5.conv2.switch.bias, layer3.5.conv2.pre_context.weight, layer3.5.conv2.pre_context.bias, layer3.5.conv2.post_context.weight, layer3.5.conv2.post_context.bias, layer3.5.conv2.offset_s.weight, layer3.5.conv2.offset_s.bias, layer3.5.conv2.offset_l.weight, layer3.5.conv2.offset_l.bias, layer3.6.conv2.weight_diff, layer3.6.conv2.switch.weight, layer3.6.conv2.switch.bias, layer3.6.conv2.pre_context.weight, layer3.6.conv2.pre_context.bias, layer3.6.conv2.post_context.weight, layer3.6.conv2.post_context.bias, layer3.6.conv2.offset_s.weight, layer3.6.conv2.offset_s.bias, layer3.6.conv2.offset_l.weight, layer3.6.conv2.offset_l.bias, layer3.7.conv2.weight_diff, layer3.7.conv2.switch.weight, layer3.7.conv2.switch.bias, layer3.7.conv2.pre_context.weight, layer3.7.conv2.pre_context.bias, layer3.7.conv2.post_context.weight, layer3.7.conv2.post_context.bias, layer3.7.conv2.offset_s.weight, layer3.7.conv2.offset_s.bias, layer3.7.conv2.offset_l.weight, layer3.7.conv2.offset_l.bias, layer3.8.conv2.weight_diff, layer3.8.conv2.switch.weight, layer3.8.conv2.switch.bias, layer3.8.conv2.pre_context.weight, layer3.8.conv2.pre_context.bias, layer3.8.conv2.post_context.weight, layer3.8.conv2.post_context.bias, layer3.8.conv2.offset_s.weight, layer3.8.conv2.offset_s.bias, layer3.8.conv2.offset_l.weight, layer3.8.conv2.offset_l.bias, layer3.9.conv2.weight_diff, layer3.9.conv2.switch.weight, layer3.9.conv2.switch.bias, layer3.9.conv2.pre_context.weight, layer3.9.conv2.pre_context.bias, layer3.9.conv2.post_context.weight, layer3.9.conv2.post_context.bias, layer3.9.conv2.offset_s.weight, layer3.9.conv2.offset_s.bias, layer3.9.conv2.offset_l.weight, layer3.9.conv2.offset_l.bias, layer3.10.conv2.weight_diff, layer3.10.conv2.switch.weight, layer3.10.conv2.switch.bias, layer3.10.conv2.pre_context.weight, layer3.10.conv2.pre_context.bias, layer3.10.conv2.post_context.weight, layer3.10.conv2.post_context.bias, layer3.10.conv2.offset_s.weight, layer3.10.conv2.offset_s.bias, layer3.10.conv2.offset_l.weight, layer3.10.conv2.offset_l.bias, layer3.11.conv2.weight_diff, layer3.11.conv2.switch.weight, layer3.11.conv2.switch.bias, layer3.11.conv2.pre_context.weight, layer3.11.conv2.pre_context.bias, layer3.11.conv2.post_context.weight, layer3.11.conv2.post_context.bias, layer3.11.conv2.offset_s.weight, layer3.11.conv2.offset_s.bias, layer3.11.conv2.offset_l.weight, layer3.11.conv2.offset_l.bias, layer3.12.conv2.weight_diff, layer3.12.conv2.switch.weight, layer3.12.conv2.switch.bias, layer3.12.conv2.pre_context.weight, layer3.12.conv2.pre_context.bias, layer3.12.conv2.post_context.weight, layer3.12.conv2.post_context.bias, layer3.12.conv2.offset_s.weight, layer3.12.conv2.offset_s.bias, layer3.12.conv2.offset_l.weight, layer3.12.conv2.offset_l.bias, layer3.13.conv2.weight_diff, layer3.13.conv2.switch.weight, layer3.13.conv2.switch.bias, layer3.13.conv2.pre_context.weight, layer3.13.conv2.pre_context.bias, layer3.13.conv2.post_context.weight, layer3.13.conv2.post_context.bias, layer3.13.conv2.offset_s.weight, layer3.13.conv2.offset_s.bias, layer3.13.conv2.offset_l.weight, layer3.13.conv2.offset_l.bias, layer3.14.conv2.weight_diff, layer3.14.conv2.switch.weight, layer3.14.conv2.switch.bias, layer3.14.conv2.pre_context.weight, layer3.14.conv2.pre_context.bias, layer3.14.conv2.post_context.weight, layer3.14.conv2.post_context.bias, layer3.14.conv2.offset_s.weight, layer3.14.conv2.offset_s.bias, layer3.14.conv2.offset_l.weight, layer3.14.conv2.offset_l.bias, layer3.15.conv2.weight_diff, layer3.15.conv2.switch.weight, layer3.15.conv2.switch.bias, layer3.15.conv2.pre_context.weight, layer3.15.conv2.pre_context.bias, layer3.15.conv2.post_context.weight, layer3.15.conv2.post_context.bias, layer3.15.conv2.offset_s.weight, layer3.15.conv2.offset_s.bias, layer3.15.conv2.offset_l.weight, layer3.15.conv2.offset_l.bias, layer3.16.conv2.weight_diff, layer3.16.conv2.switch.weight, layer3.16.conv2.switch.bias, layer3.16.conv2.pre_context.weight, layer3.16.conv2.pre_context.bias, layer3.16.conv2.post_context.weight, layer3.16.conv2.post_context.bias, layer3.16.conv2.offset_s.weight, layer3.16.conv2.offset_s.bias, layer3.16.conv2.offset_l.weight, layer3.16.conv2.offset_l.bias, layer3.17.conv2.weight_diff, layer3.17.conv2.switch.weight, layer3.17.conv2.switch.bias, layer3.17.conv2.pre_context.weight, layer3.17.conv2.pre_context.bias, layer3.17.conv2.post_context.weight, layer3.17.conv2.post_context.bias, layer3.17.conv2.offset_s.weight, layer3.17.conv2.offset_s.bias, layer3.17.conv2.offset_l.weight, layer3.17.conv2.offset_l.bias, layer3.18.conv2.weight_diff, layer3.18.conv2.switch.weight, layer3.18.conv2.switch.bias, layer3.18.conv2.pre_context.weight, layer3.18.conv2.pre_context.bias, layer3.18.conv2.post_context.weight, layer3.18.conv2.post_context.bias, layer3.18.conv2.offset_s.weight, layer3.18.conv2.offset_s.bias, layer3.18.conv2.offset_l.weight, layer3.18.conv2.offset_l.bias, layer3.19.conv2.weight_diff, layer3.19.conv2.switch.weight, layer3.19.conv2.switch.bias, layer3.19.conv2.pre_context.weight, layer3.19.conv2.pre_context.bias, layer3.19.conv2.post_context.weight, layer3.19.conv2.post_context.bias, layer3.19.conv2.offset_s.weight, layer3.19.conv2.offset_s.bias, layer3.19.conv2.offset_l.weight, layer3.19.conv2.offset_l.bias, layer3.20.conv2.weight_diff, layer3.20.conv2.switch.weight, layer3.20.conv2.switch.bias, layer3.20.conv2.pre_context.weight, layer3.20.conv2.pre_context.bias, layer3.20.conv2.post_context.weight, layer3.20.conv2.post_context.bias, layer3.20.conv2.offset_s.weight, layer3.20.conv2.offset_s.bias, layer3.20.conv2.offset_l.weight, layer3.20.conv2.offset_l.bias, layer3.21.conv2.weight_diff, layer3.21.conv2.switch.weight, layer3.21.conv2.switch.bias, layer3.21.conv2.pre_context.weight, layer3.21.conv2.pre_context.bias, layer3.21.conv2.post_context.weight, layer3.21.conv2.post_context.bias, layer3.21.conv2.offset_s.weight, layer3.21.conv2.offset_s.bias, layer3.21.conv2.offset_l.weight, layer3.21.conv2.offset_l.bias, layer3.22.conv2.weight_diff, layer3.22.conv2.switch.weight, layer3.22.conv2.switch.bias, layer3.22.conv2.pre_context.weight, layer3.22.conv2.pre_context.bias, layer3.22.conv2.post_context.weight, layer3.22.conv2.post_context.bias, layer3.22.conv2.offset_s.weight, layer3.22.conv2.offset_s.bias, layer3.22.conv2.offset_l.weight, layer3.22.conv2.offset_l.bias, layer4.0.conv2.weight_diff, layer4.0.conv2.switch.weight, layer4.0.conv2.switch.bias, layer4.0.conv2.pre_context.weight, layer4.0.conv2.pre_context.bias, layer4.0.conv2.post_context.weight, layer4.0.conv2.post_context.bias, layer4.0.conv2.offset_s.weight, layer4.0.conv2.offset_s.bias, layer4.0.conv2.offset_l.weight, layer4.0.conv2.offset_l.bias, layer4.0.rfp_conv.weight, layer4.0.rfp_conv.bias, layer4.1.conv2.weight_diff, layer4.1.conv2.switch.weight, layer4.1.conv2.switch.bias, layer4.1.conv2.pre_context.weight, layer4.1.conv2.pre_context.bias, layer4.1.conv2.post_context.weight, layer4.1.conv2.post_context.bias, layer4.1.conv2.offset_s.weight, layer4.1.conv2.offset_s.bias, layer4.1.conv2.offset_l.weight, layer4.1.conv2.offset_l.bias, layer4.2.conv2.weight_diff, layer4.2.conv2.switch.weight, layer4.2.conv2.switch.bias, layer4.2.conv2.pre_context.weight, layer4.2.conv2.pre_context.bias, layer4.2.conv2.post_context.weight, layer4.2.conv2.post_context.bias, layer4.2.conv2.offset_s.weight, layer4.2.conv2.offset_s.bias, layer4.2.conv2.offset_l.weight, layer4.2.conv2.offset_l.bias\n",
            "\n",
            "Loads checkpoint by local backend from path: /content/drive/MyDrive/models/detectors_htc_r101_20e_coco_20210419_203638-348d533b.pth\n",
            "09/19 08:20:36 - mmengine - INFO - Load checkpoint from /content/drive/MyDrive/models/detectors_htc_r101_20e_coco_20210419_203638-348d533b.pth\n",
            "09/19 08:20:36 - mmengine - WARNING - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
            "09/19 08:20:36 - mmengine - WARNING - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
            "09/19 08:20:36 - mmengine - INFO - Checkpoints will be saved to /content/drive/MyDrive/C:\\Users\\HP\\mmdetection\\demo\\work_dir.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-1359d677ff08>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmmengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunner\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRunner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mrunner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_cfg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mmengine/runner/runner.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1743\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train_step'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1744\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1745\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1746\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_run'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1747\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mmengine/runner/loops.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_epoch\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_max_epochs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decide_current_val_interval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mmengine/runner/loops.py\u001b[0m in \u001b[0;36mrun_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_train_epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mmengine/runner/loops.py\u001b[0m in \u001b[0;36mrun_iter\u001b[0;34m(self, idx, data_batch)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;31m# synchronization during gradient accumulation process.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;31m# outputs should be a dict of loss.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         outputs = self.runner.model.train_step(\n\u001b[0m\u001b[1;32m    129\u001b[0m             data_batch, optim_wrapper=self.runner.optim_wrapper)\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mmengine/model/base_model/base_model.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, data, optim_wrapper)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0moptim_wrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_preprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0mparsed_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_losses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0moptim_wrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mmengine/model/base_model/base_model.py\u001b[0m in \u001b[0;36m_run_forward\u001b[0;34m(self, data, mode)\u001b[0m\n\u001b[1;32m    338\u001b[0m         \"\"\"\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/mmdetection/mmdet/models/detectors/base.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, data_samples, mode)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \"\"\"\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'loss'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'predict'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/mmdetection/mmdet/models/detectors/two_stage.py\u001b[0m in \u001b[0;36mloss\u001b[0;34m(self, batch_inputs, batch_data_samples)\u001b[0m\n\u001b[1;32m    188\u001b[0m             ]\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         roi_losses = self.roi_head.loss(x, rpn_results_list,\n\u001b[0m\u001b[1;32m    191\u001b[0m                                         batch_data_samples)\n\u001b[1;32m    192\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroi_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/mmdetection/mmdet/models/roi_heads/htc_roi_head.py\u001b[0m in \u001b[0;36mloss\u001b[0;34m(self, x, rpn_results_list, batch_data_samples)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_semantic\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             gt_semantic_segs = [\n\u001b[0m\u001b[1;32m    289\u001b[0m                 \u001b[0mdata_sample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgt_sem_seg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msem_seg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mdata_sample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch_data_samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/mmdetection/mmdet/models/roi_heads/htc_roi_head.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_semantic\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             gt_semantic_segs = [\n\u001b[0;32m--> 289\u001b[0;31m                 \u001b[0mdata_sample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgt_sem_seg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msem_seg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mdata_sample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch_data_samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m             ]\n",
            "\u001b[0;32m/content/mmdetection/mmdet/structures/det_data_sample.py\u001b[0m in \u001b[0;36mgt_sem_seg\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgt_sem_seg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mPixelData\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gt_sem_seg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mgt_sem_seg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'DetDataSample' object has no attribute '_gt_sem_seg'"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive\n",
        "\n",
        "from mmengine.runner import Runner\n",
        "runner = Runner.from_cfg(cfg)\n",
        "runner.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3VgOhk-lMrJ",
        "outputId": "aa05e8d6-b58a-4114-e5d4-b3ae735b5acd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive\n",
            "09/19 08:39:29 - mmengine - INFO - \n",
            "------------------------------------------------------------\n",
            "System environment:\n",
            "    sys.platform: linux\n",
            "    Python: 3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0]\n",
            "    CUDA available: True\n",
            "    numpy_random_seed: 15826234\n",
            "    GPU 0: Tesla T4\n",
            "    CUDA_HOME: /usr/local/cuda\n",
            "    NVCC: Cuda compilation tools, release 11.8, V11.8.89\n",
            "    GCC: x86_64-linux-gnu-gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
            "    PyTorch: 2.0.1+cu118\n",
            "    PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 9.3\n",
            "  - C++ Version: 201703\n",
            "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 11.8\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
            "  - CuDNN 8.7\n",
            "  - Magma 2.6.1\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "    TorchVision: 0.15.2+cu118\n",
            "    OpenCV: 4.8.0\n",
            "    MMEngine: 0.8.4\n",
            "\n",
            "Runtime environment:\n",
            "    cudnn_benchmark: False\n",
            "    dist_cfg: {'backend': 'nccl'}\n",
            "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
            "    seed: 15826234\n",
            "    Distributed launcher: none\n",
            "    Distributed training: False\n",
            "    GPU number: 1\n",
            "------------------------------------------------------------\n",
            "\n",
            "09/19 08:39:30 - mmengine - INFO - Config:\n",
            "auto_scale_lr = dict(base_batch_size=16, enable=False)\n",
            "backend_args = None\n",
            "classes = (\n",
            "    'Bdr',\n",
            "    'Bone Loss',\n",
            "    'Bridge',\n",
            "    'Caries',\n",
            "    'Crown',\n",
            "    'Filling',\n",
            "    'Impaction',\n",
            "    'Implant',\n",
            "    'Periapical Abscess',\n",
            "    'Rct',\n",
            "    'Rct +Post',\n",
            "    'Retentive Pin',\n",
            "    'Shadow',\n",
            "    'Splinted Crowns',\n",
            "    'Unerupted',\n",
            ")\n",
            "data_root = 'data/diagnosis'\n",
            "dataset_type = 'DiagnosisDataset'\n",
            "default_hooks = dict(\n",
            "    checkpoint=dict(interval=1, type='CheckpointHook'),\n",
            "    logger=dict(interval=1774, type='LoggerHook'),\n",
            "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    timer=dict(type='IterTimerHook'),\n",
            "    visualization=dict(type='DetVisualizationHook'))\n",
            "default_scope = 'mmdet'\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=False,\n",
            "    dist_cfg=dict(backend='nccl'),\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
            "load_from = '/content/drive/MyDrive/models/detectors_htc_r101_20e_coco_20210419_203638-348d533b.pth'\n",
            "log_level = 'INFO'\n",
            "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=1774)\n",
            "lr_config = dict(step=[\n",
            "    25,\n",
            "    30,\n",
            "])\n",
            "max_epochs = 20\n",
            "model = dict(\n",
            "    backbone=dict(\n",
            "        conv_cfg=dict(type='ConvAWS'),\n",
            "        depth=101,\n",
            "        frozen_stages=4,\n",
            "        init_cfg=dict(checkpoint='torchvision://resnet101', type='Pretrained'),\n",
            "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "        norm_eval=True,\n",
            "        num_stages=4,\n",
            "        out_indices=(\n",
            "            0,\n",
            "            1,\n",
            "            2,\n",
            "            3,\n",
            "        ),\n",
            "        output_img=True,\n",
            "        sac=dict(type='SAC', use_deform=True),\n",
            "        stage_with_sac=(\n",
            "            False,\n",
            "            True,\n",
            "            True,\n",
            "            True,\n",
            "        ),\n",
            "        style='pytorch',\n",
            "        type='DetectoRS_ResNet'),\n",
            "    data_preprocessor=dict(\n",
            "        bgr_to_rgb=True,\n",
            "        mean=[\n",
            "            123.675,\n",
            "            116.28,\n",
            "            103.53,\n",
            "        ],\n",
            "        pad_seg=True,\n",
            "        pad_size_divisor=32,\n",
            "        std=[\n",
            "            58.395,\n",
            "            57.12,\n",
            "            57.375,\n",
            "        ],\n",
            "        type='DetDataPreprocessor'),\n",
            "    neck=dict(\n",
            "        aspp_dilations=(\n",
            "            1,\n",
            "            3,\n",
            "            6,\n",
            "            1,\n",
            "        ),\n",
            "        aspp_out_channels=64,\n",
            "        in_channels=[\n",
            "            256,\n",
            "            512,\n",
            "            1024,\n",
            "            2048,\n",
            "        ],\n",
            "        num_outs=5,\n",
            "        out_channels=256,\n",
            "        rfp_backbone=dict(\n",
            "            conv_cfg=dict(type='ConvAWS'),\n",
            "            depth=101,\n",
            "            frozen_stages=1,\n",
            "            norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "            norm_eval=True,\n",
            "            num_stages=4,\n",
            "            out_indices=(\n",
            "                0,\n",
            "                1,\n",
            "                2,\n",
            "                3,\n",
            "            ),\n",
            "            pretrained='torchvision://resnet101',\n",
            "            rfp_inplanes=256,\n",
            "            sac=dict(type='SAC', use_deform=True),\n",
            "            stage_with_sac=(\n",
            "                False,\n",
            "                True,\n",
            "                True,\n",
            "                True,\n",
            "            ),\n",
            "            style='pytorch',\n",
            "            type='DetectoRS_ResNet'),\n",
            "        rfp_steps=2,\n",
            "        type='RFP'),\n",
            "    roi_head=dict(\n",
            "        bbox_head=[\n",
            "            dict(\n",
            "                bbox_coder=dict(\n",
            "                    target_means=[\n",
            "                        0.0,\n",
            "                        0.0,\n",
            "                        0.0,\n",
            "                        0.0,\n",
            "                    ],\n",
            "                    target_stds=[\n",
            "                        0.1,\n",
            "                        0.1,\n",
            "                        0.2,\n",
            "                        0.2,\n",
            "                    ],\n",
            "                    type='DeltaXYWHBBoxCoder'),\n",
            "                fc_out_channels=1024,\n",
            "                in_channels=256,\n",
            "                loss_bbox=dict(beta=1.0, loss_weight=1.0, type='SmoothL1Loss'),\n",
            "                loss_cls=dict(\n",
            "                    loss_weight=1.0,\n",
            "                    type='CrossEntropyLoss',\n",
            "                    use_sigmoid=False),\n",
            "                num_classes=15,\n",
            "                reg_class_agnostic=True,\n",
            "                roi_feat_size=7,\n",
            "                type='Shared2FCBBoxHead'),\n",
            "            dict(\n",
            "                bbox_coder=dict(\n",
            "                    target_means=[\n",
            "                        0.0,\n",
            "                        0.0,\n",
            "                        0.0,\n",
            "                        0.0,\n",
            "                    ],\n",
            "                    target_stds=[\n",
            "                        0.05,\n",
            "                        0.05,\n",
            "                        0.1,\n",
            "                        0.1,\n",
            "                    ],\n",
            "                    type='DeltaXYWHBBoxCoder'),\n",
            "                fc_out_channels=1024,\n",
            "                in_channels=256,\n",
            "                loss_bbox=dict(beta=1.0, loss_weight=1.0, type='SmoothL1Loss'),\n",
            "                loss_cls=dict(\n",
            "                    loss_weight=1.0,\n",
            "                    type='CrossEntropyLoss',\n",
            "                    use_sigmoid=False),\n",
            "                num_classes=15,\n",
            "                reg_class_agnostic=True,\n",
            "                roi_feat_size=7,\n",
            "                type='Shared2FCBBoxHead'),\n",
            "            dict(\n",
            "                bbox_coder=dict(\n",
            "                    target_means=[\n",
            "                        0.0,\n",
            "                        0.0,\n",
            "                        0.0,\n",
            "                        0.0,\n",
            "                    ],\n",
            "                    target_stds=[\n",
            "                        0.033,\n",
            "                        0.033,\n",
            "                        0.067,\n",
            "                        0.067,\n",
            "                    ],\n",
            "                    type='DeltaXYWHBBoxCoder'),\n",
            "                fc_out_channels=1024,\n",
            "                in_channels=256,\n",
            "                loss_bbox=dict(beta=1.0, loss_weight=1.0, type='SmoothL1Loss'),\n",
            "                loss_cls=dict(\n",
            "                    loss_weight=1.0,\n",
            "                    type='CrossEntropyLoss',\n",
            "                    use_sigmoid=False),\n",
            "                num_classes=15,\n",
            "                reg_class_agnostic=True,\n",
            "                roi_feat_size=7,\n",
            "                type='Shared2FCBBoxHead'),\n",
            "        ],\n",
            "        bbox_roi_extractor=dict(\n",
            "            featmap_strides=[\n",
            "                4,\n",
            "                8,\n",
            "                16,\n",
            "                32,\n",
            "            ],\n",
            "            out_channels=256,\n",
            "            roi_layer=dict(output_size=7, sampling_ratio=0, type='RoIAlign'),\n",
            "            type='SingleRoIExtractor'),\n",
            "        interleaved=True,\n",
            "        mask_head=[\n",
            "            dict(\n",
            "                conv_out_channels=256,\n",
            "                in_channels=256,\n",
            "                loss_mask=dict(\n",
            "                    loss_weight=1.0, type='CrossEntropyLoss', use_mask=True),\n",
            "                num_classes=80,\n",
            "                num_convs=4,\n",
            "                type='HTCMaskHead',\n",
            "                with_conv_res=False),\n",
            "            dict(\n",
            "                conv_out_channels=256,\n",
            "                in_channels=256,\n",
            "                loss_mask=dict(\n",
            "                    loss_weight=1.0, type='CrossEntropyLoss', use_mask=True),\n",
            "                num_classes=15,\n",
            "                num_convs=4,\n",
            "                type='HTCMaskHead'),\n",
            "            dict(\n",
            "                conv_out_channels=256,\n",
            "                in_channels=256,\n",
            "                loss_mask=dict(\n",
            "                    loss_weight=1.0, type='CrossEntropyLoss', use_mask=True),\n",
            "                num_classes=15,\n",
            "                num_convs=4,\n",
            "                type='HTCMaskHead'),\n",
            "        ],\n",
            "        mask_info_flow=True,\n",
            "        mask_roi_extractor=dict(\n",
            "            featmap_strides=[\n",
            "                4,\n",
            "                8,\n",
            "                16,\n",
            "                32,\n",
            "            ],\n",
            "            out_channels=256,\n",
            "            roi_layer=dict(output_size=14, sampling_ratio=0, type='RoIAlign'),\n",
            "            type='SingleRoIExtractor'),\n",
            "        num_stages=3,\n",
            "        stage_loss_weights=[\n",
            "            1,\n",
            "            0.5,\n",
            "            0.25,\n",
            "        ],\n",
            "        type='HybridTaskCascadeRoIHead'),\n",
            "    rpn_head=dict(\n",
            "        anchor_generator=dict(\n",
            "            ratios=[\n",
            "                0.5,\n",
            "                1.0,\n",
            "                2.0,\n",
            "            ],\n",
            "            scales=[\n",
            "                8,\n",
            "            ],\n",
            "            strides=[\n",
            "                4,\n",
            "                8,\n",
            "                16,\n",
            "                32,\n",
            "                64,\n",
            "            ],\n",
            "            type='AnchorGenerator'),\n",
            "        bbox_coder=dict(\n",
            "            target_means=[\n",
            "                0.0,\n",
            "                0.0,\n",
            "                0.0,\n",
            "                0.0,\n",
            "            ],\n",
            "            target_stds=[\n",
            "                1.0,\n",
            "                1.0,\n",
            "                1.0,\n",
            "                1.0,\n",
            "            ],\n",
            "            type='DeltaXYWHBBoxCoder'),\n",
            "        feat_channels=256,\n",
            "        in_channels=256,\n",
            "        loss_bbox=dict(\n",
            "            beta=0.1111111111111111, loss_weight=1.0, type='SmoothL1Loss'),\n",
            "        loss_cls=dict(\n",
            "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=True),\n",
            "        type='RPNHead'),\n",
            "    test_cfg=dict(\n",
            "        rcnn=dict(\n",
            "            mask_thr_binary=0.5,\n",
            "            max_per_img=100,\n",
            "            nms=dict(iou_threshold=0.5, type='nms'),\n",
            "            score_thr=0.001),\n",
            "        rpn=dict(\n",
            "            max_per_img=1000,\n",
            "            min_bbox_size=0,\n",
            "            nms=dict(iou_threshold=0.7, type='nms'),\n",
            "            nms_pre=1000)),\n",
            "    train_cfg=dict(\n",
            "        rcnn=[\n",
            "            dict(\n",
            "                assigner=dict(\n",
            "                    ignore_iof_thr=-1,\n",
            "                    min_pos_iou=0.5,\n",
            "                    neg_iou_thr=0.5,\n",
            "                    pos_iou_thr=0.5,\n",
            "                    type='MaxIoUAssigner'),\n",
            "                debug=False,\n",
            "                mask_size=28,\n",
            "                pos_weight=-1,\n",
            "                sampler=dict(\n",
            "                    add_gt_as_proposals=True,\n",
            "                    neg_pos_ub=-1,\n",
            "                    num=512,\n",
            "                    pos_fraction=0.25,\n",
            "                    type='RandomSampler')),\n",
            "            dict(\n",
            "                assigner=dict(\n",
            "                    ignore_iof_thr=-1,\n",
            "                    min_pos_iou=0.6,\n",
            "                    neg_iou_thr=0.6,\n",
            "                    pos_iou_thr=0.6,\n",
            "                    type='MaxIoUAssigner'),\n",
            "                debug=False,\n",
            "                mask_size=28,\n",
            "                pos_weight=-1,\n",
            "                sampler=dict(\n",
            "                    add_gt_as_proposals=True,\n",
            "                    neg_pos_ub=-1,\n",
            "                    num=512,\n",
            "                    pos_fraction=0.25,\n",
            "                    type='RandomSampler')),\n",
            "            dict(\n",
            "                assigner=dict(\n",
            "                    ignore_iof_thr=-1,\n",
            "                    min_pos_iou=0.7,\n",
            "                    neg_iou_thr=0.7,\n",
            "                    pos_iou_thr=0.7,\n",
            "                    type='MaxIoUAssigner'),\n",
            "                debug=False,\n",
            "                mask_size=28,\n",
            "                pos_weight=-1,\n",
            "                sampler=dict(\n",
            "                    add_gt_as_proposals=True,\n",
            "                    neg_pos_ub=-1,\n",
            "                    num=512,\n",
            "                    pos_fraction=0.25,\n",
            "                    type='RandomSampler')),\n",
            "        ],\n",
            "        rpn=dict(\n",
            "            allowed_border=0,\n",
            "            assigner=dict(\n",
            "                ignore_iof_thr=-1,\n",
            "                min_pos_iou=0.3,\n",
            "                neg_iou_thr=0.3,\n",
            "                pos_iou_thr=0.7,\n",
            "                type='MaxIoUAssigner'),\n",
            "            debug=False,\n",
            "            pos_weight=-1,\n",
            "            sampler=dict(\n",
            "                add_gt_as_proposals=False,\n",
            "                neg_pos_ub=-1,\n",
            "                num=256,\n",
            "                pos_fraction=0.5,\n",
            "                type='RandomSampler')),\n",
            "        rpn_proposal=dict(\n",
            "            max_per_img=2000,\n",
            "            min_bbox_size=0,\n",
            "            nms=dict(iou_threshold=0.7, type='nms'),\n",
            "            nms_pre=2000)),\n",
            "    type='HybridTaskCascade')\n",
            "optim_wrapper = dict(\n",
            "    optimizer=dict(lr=0.005, momentum=0.9, type='SGD', weight_decay=0.0001),\n",
            "    type='OptimWrapper')\n",
            "param_scheduler = [\n",
            "    dict(\n",
            "        begin=0, by_epoch=False, end=500, start_factor=0.001, type='LinearLR'),\n",
            "    dict(\n",
            "        begin=0,\n",
            "        by_epoch=True,\n",
            "        end=12,\n",
            "        gamma=0.1,\n",
            "        milestones=[\n",
            "            21,\n",
            "            22,\n",
            "        ],\n",
            "        type='MultiStepLR'),\n",
            "]\n",
            "resume = False\n",
            "test_cfg = dict(type='TestLoop')\n",
            "test_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='ann/val.json',\n",
            "        backend_args=None,\n",
            "        data_prefix=dict(img='valid/'),\n",
            "        data_root='data/diagnosis',\n",
            "        metainfo=dict(\n",
            "            classes=(\n",
            "                'Bdr',\n",
            "                'Bone Loss',\n",
            "                'Bridge',\n",
            "                'Caries',\n",
            "                'Crown',\n",
            "                'Filling',\n",
            "                'Impaction',\n",
            "                'Implant',\n",
            "                'Periapical Abscess',\n",
            "                'Rct',\n",
            "                'Rct +Post',\n",
            "                'Retentive Pin',\n",
            "                'Shadow',\n",
            "                'Splinted Crowns',\n",
            "                'Unerupted',\n",
            "            )),\n",
            "        pipeline=[\n",
            "            dict(backend_args=None, type='LoadImageFromFile'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                1333,\n",
            "                800,\n",
            "            ), type='Resize'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'img_id',\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'scale_factor',\n",
            "                ),\n",
            "                type='PackDetInputs'),\n",
            "        ],\n",
            "        test_mode=True,\n",
            "        type='DiagnosisDataset'),\n",
            "    drop_last=False,\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "test_evaluator = dict(\n",
            "    ann_file='/content/drive/MyDrive/data/diagnosis/ann/val.json',\n",
            "    backend_args=None,\n",
            "    format_only=False,\n",
            "    metric=[\n",
            "        'bbox',\n",
            "        'segm',\n",
            "    ],\n",
            "    type='CocoMetric')\n",
            "test_pipeline = [\n",
            "    dict(backend_args=None, type='LoadImageFromFile'),\n",
            "    dict(keep_ratio=True, scale=(\n",
            "        1333,\n",
            "        800,\n",
            "    ), type='Resize'),\n",
            "    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
            "    dict(\n",
            "        meta_keys=(\n",
            "            'img_id',\n",
            "            'img_path',\n",
            "            'ori_shape',\n",
            "            'img_shape',\n",
            "            'scale_factor',\n",
            "        ),\n",
            "        type='PackDetInputs'),\n",
            "]\n",
            "train_cfg = dict(max_epochs=10, type='EpochBasedTrainLoop', val_interval=1)\n",
            "train_dataloader = dict(\n",
            "    batch_sampler=dict(type='AspectRatioBatchSampler'),\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='ann/train.json',\n",
            "        backend_args=None,\n",
            "        data_prefix=dict(img='train/'),\n",
            "        data_root='/content/drive/MyDrive/data/diagnosis',\n",
            "        filter_cfg=dict(filter_empty_gt=False, min_size=16),\n",
            "        metainfo=dict(\n",
            "            classes=(\n",
            "                'Bdr',\n",
            "                'Bone Loss',\n",
            "                'Bridge',\n",
            "                'Caries',\n",
            "                'Crown',\n",
            "                'Filling',\n",
            "                'Impaction',\n",
            "                'Implant',\n",
            "                'Periapical Abscess',\n",
            "                'Rct',\n",
            "                'Rct +Post',\n",
            "                'Retentive Pin',\n",
            "                'Shadow',\n",
            "                'Splinted Crowns',\n",
            "                'Unerupted',\n",
            "            )),\n",
            "        pipeline=[\n",
            "            dict(backend_args=None, type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                1333,\n",
            "                800,\n",
            "            ), type='Resize'),\n",
            "            dict(prob=0.0, type='RandomFlip'),\n",
            "            dict(type='PackDetInputs'),\n",
            "        ],\n",
            "        type='DiagnosisDataset'),\n",
            "    num_workers=8,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
            "train_pipeline = [\n",
            "    dict(backend_args=None, type='LoadImageFromFile'),\n",
            "    dict(\n",
            "        type='LoadAnnotations', with_bbox=True, with_mask=True, with_seg=True),\n",
            "    dict(keep_ratio=True, scale=(\n",
            "        1333,\n",
            "        800,\n",
            "    ), type='Resize'),\n",
            "    dict(prob=0.5, type='RandomFlip'),\n",
            "    dict(type='PackDetInputs'),\n",
            "]\n",
            "val_cfg = dict(type='ValLoop')\n",
            "val_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='ann/val.json',\n",
            "        backend_args=None,\n",
            "        data_prefix=dict(img='valid/'),\n",
            "        data_root='data/diagnosis',\n",
            "        metainfo=dict(\n",
            "            classes=(\n",
            "                'Bdr',\n",
            "                'Bone Loss',\n",
            "                'Bridge',\n",
            "                'Caries',\n",
            "                'Crown',\n",
            "                'Filling',\n",
            "                'Impaction',\n",
            "                'Implant',\n",
            "                'Periapical Abscess',\n",
            "                'Rct',\n",
            "                'Rct +Post',\n",
            "                'Retentive Pin',\n",
            "                'Shadow',\n",
            "                'Splinted Crowns',\n",
            "                'Unerupted',\n",
            "            )),\n",
            "        pipeline=[\n",
            "            dict(backend_args=None, type='LoadImageFromFile'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                1333,\n",
            "                800,\n",
            "            ), type='Resize'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'img_id',\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'scale_factor',\n",
            "                ),\n",
            "                type='PackDetInputs'),\n",
            "        ],\n",
            "        test_mode=True,\n",
            "        type='DiagnosisDataset'),\n",
            "    drop_last=False,\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "val_evaluator = dict(\n",
            "    ann_file='/content/drive/MyDrive/data/diagnosis/ann/val.json',\n",
            "    backend_args=None,\n",
            "    format_only=False,\n",
            "    metric=[\n",
            "        'bbox',\n",
            "        'segm',\n",
            "    ],\n",
            "    type='CocoMetric')\n",
            "vis_backends = [\n",
            "    dict(type='LocalVisBackend'),\n",
            "]\n",
            "visualizer = dict(\n",
            "    name='visualizer',\n",
            "    type='DetLocalVisualizer',\n",
            "    vis_backends=[\n",
            "        dict(type='LocalVisBackend'),\n",
            "    ])\n",
            "work_dir = 'C:\\\\Users\\\\HP\\\\mmdetection\\\\demo\\\\work_dir'\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/mmengine/utils/manager.py:113: UserWarning: <class 'mmdet.visualization.local_visualizer.DetLocalVisualizer'> instance named of visualizer has been created, the method `get_instance` should not accept any other arguments\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "09/19 08:39:34 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
            "09/19 08:39:34 - mmengine - INFO - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "before_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DistSamplerSeedHook                \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DetVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_test_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DetVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_run:\n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "loading annotations into memory...\n",
            "Done (t=0.07s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.05s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "09/19 08:40:17 - mmengine - INFO - Loads checkpoint by torchvision backend from path: torchvision://resnet101\n",
            "09/19 08:40:17 - mmengine - WARNING - The model and loaded state dict do not match exactly\n",
            "\n",
            "unexpected key in source state_dict: fc.weight, fc.bias\n",
            "\n",
            "missing keys in source state_dict: layer2.0.conv2.weight_diff, layer2.0.conv2.switch.weight, layer2.0.conv2.switch.bias, layer2.0.conv2.pre_context.weight, layer2.0.conv2.pre_context.bias, layer2.0.conv2.post_context.weight, layer2.0.conv2.post_context.bias, layer2.0.conv2.offset_s.weight, layer2.0.conv2.offset_s.bias, layer2.0.conv2.offset_l.weight, layer2.0.conv2.offset_l.bias, layer2.1.conv2.weight_diff, layer2.1.conv2.switch.weight, layer2.1.conv2.switch.bias, layer2.1.conv2.pre_context.weight, layer2.1.conv2.pre_context.bias, layer2.1.conv2.post_context.weight, layer2.1.conv2.post_context.bias, layer2.1.conv2.offset_s.weight, layer2.1.conv2.offset_s.bias, layer2.1.conv2.offset_l.weight, layer2.1.conv2.offset_l.bias, layer2.2.conv2.weight_diff, layer2.2.conv2.switch.weight, layer2.2.conv2.switch.bias, layer2.2.conv2.pre_context.weight, layer2.2.conv2.pre_context.bias, layer2.2.conv2.post_context.weight, layer2.2.conv2.post_context.bias, layer2.2.conv2.offset_s.weight, layer2.2.conv2.offset_s.bias, layer2.2.conv2.offset_l.weight, layer2.2.conv2.offset_l.bias, layer2.3.conv2.weight_diff, layer2.3.conv2.switch.weight, layer2.3.conv2.switch.bias, layer2.3.conv2.pre_context.weight, layer2.3.conv2.pre_context.bias, layer2.3.conv2.post_context.weight, layer2.3.conv2.post_context.bias, layer2.3.conv2.offset_s.weight, layer2.3.conv2.offset_s.bias, layer2.3.conv2.offset_l.weight, layer2.3.conv2.offset_l.bias, layer3.0.conv2.weight_diff, layer3.0.conv2.switch.weight, layer3.0.conv2.switch.bias, layer3.0.conv2.pre_context.weight, layer3.0.conv2.pre_context.bias, layer3.0.conv2.post_context.weight, layer3.0.conv2.post_context.bias, layer3.0.conv2.offset_s.weight, layer3.0.conv2.offset_s.bias, layer3.0.conv2.offset_l.weight, layer3.0.conv2.offset_l.bias, layer3.1.conv2.weight_diff, layer3.1.conv2.switch.weight, layer3.1.conv2.switch.bias, layer3.1.conv2.pre_context.weight, layer3.1.conv2.pre_context.bias, layer3.1.conv2.post_context.weight, layer3.1.conv2.post_context.bias, layer3.1.conv2.offset_s.weight, layer3.1.conv2.offset_s.bias, layer3.1.conv2.offset_l.weight, layer3.1.conv2.offset_l.bias, layer3.2.conv2.weight_diff, layer3.2.conv2.switch.weight, layer3.2.conv2.switch.bias, layer3.2.conv2.pre_context.weight, layer3.2.conv2.pre_context.bias, layer3.2.conv2.post_context.weight, layer3.2.conv2.post_context.bias, layer3.2.conv2.offset_s.weight, layer3.2.conv2.offset_s.bias, layer3.2.conv2.offset_l.weight, layer3.2.conv2.offset_l.bias, layer3.3.conv2.weight_diff, layer3.3.conv2.switch.weight, layer3.3.conv2.switch.bias, layer3.3.conv2.pre_context.weight, layer3.3.conv2.pre_context.bias, layer3.3.conv2.post_context.weight, layer3.3.conv2.post_context.bias, layer3.3.conv2.offset_s.weight, layer3.3.conv2.offset_s.bias, layer3.3.conv2.offset_l.weight, layer3.3.conv2.offset_l.bias, layer3.4.conv2.weight_diff, layer3.4.conv2.switch.weight, layer3.4.conv2.switch.bias, layer3.4.conv2.pre_context.weight, layer3.4.conv2.pre_context.bias, layer3.4.conv2.post_context.weight, layer3.4.conv2.post_context.bias, layer3.4.conv2.offset_s.weight, layer3.4.conv2.offset_s.bias, layer3.4.conv2.offset_l.weight, layer3.4.conv2.offset_l.bias, layer3.5.conv2.weight_diff, layer3.5.conv2.switch.weight, layer3.5.conv2.switch.bias, layer3.5.conv2.pre_context.weight, layer3.5.conv2.pre_context.bias, layer3.5.conv2.post_context.weight, layer3.5.conv2.post_context.bias, layer3.5.conv2.offset_s.weight, layer3.5.conv2.offset_s.bias, layer3.5.conv2.offset_l.weight, layer3.5.conv2.offset_l.bias, layer3.6.conv2.weight_diff, layer3.6.conv2.switch.weight, layer3.6.conv2.switch.bias, layer3.6.conv2.pre_context.weight, layer3.6.conv2.pre_context.bias, layer3.6.conv2.post_context.weight, layer3.6.conv2.post_context.bias, layer3.6.conv2.offset_s.weight, layer3.6.conv2.offset_s.bias, layer3.6.conv2.offset_l.weight, layer3.6.conv2.offset_l.bias, layer3.7.conv2.weight_diff, layer3.7.conv2.switch.weight, layer3.7.conv2.switch.bias, layer3.7.conv2.pre_context.weight, layer3.7.conv2.pre_context.bias, layer3.7.conv2.post_context.weight, layer3.7.conv2.post_context.bias, layer3.7.conv2.offset_s.weight, layer3.7.conv2.offset_s.bias, layer3.7.conv2.offset_l.weight, layer3.7.conv2.offset_l.bias, layer3.8.conv2.weight_diff, layer3.8.conv2.switch.weight, layer3.8.conv2.switch.bias, layer3.8.conv2.pre_context.weight, layer3.8.conv2.pre_context.bias, layer3.8.conv2.post_context.weight, layer3.8.conv2.post_context.bias, layer3.8.conv2.offset_s.weight, layer3.8.conv2.offset_s.bias, layer3.8.conv2.offset_l.weight, layer3.8.conv2.offset_l.bias, layer3.9.conv2.weight_diff, layer3.9.conv2.switch.weight, layer3.9.conv2.switch.bias, layer3.9.conv2.pre_context.weight, layer3.9.conv2.pre_context.bias, layer3.9.conv2.post_context.weight, layer3.9.conv2.post_context.bias, layer3.9.conv2.offset_s.weight, layer3.9.conv2.offset_s.bias, layer3.9.conv2.offset_l.weight, layer3.9.conv2.offset_l.bias, layer3.10.conv2.weight_diff, layer3.10.conv2.switch.weight, layer3.10.conv2.switch.bias, layer3.10.conv2.pre_context.weight, layer3.10.conv2.pre_context.bias, layer3.10.conv2.post_context.weight, layer3.10.conv2.post_context.bias, layer3.10.conv2.offset_s.weight, layer3.10.conv2.offset_s.bias, layer3.10.conv2.offset_l.weight, layer3.10.conv2.offset_l.bias, layer3.11.conv2.weight_diff, layer3.11.conv2.switch.weight, layer3.11.conv2.switch.bias, layer3.11.conv2.pre_context.weight, layer3.11.conv2.pre_context.bias, layer3.11.conv2.post_context.weight, layer3.11.conv2.post_context.bias, layer3.11.conv2.offset_s.weight, layer3.11.conv2.offset_s.bias, layer3.11.conv2.offset_l.weight, layer3.11.conv2.offset_l.bias, layer3.12.conv2.weight_diff, layer3.12.conv2.switch.weight, layer3.12.conv2.switch.bias, layer3.12.conv2.pre_context.weight, layer3.12.conv2.pre_context.bias, layer3.12.conv2.post_context.weight, layer3.12.conv2.post_context.bias, layer3.12.conv2.offset_s.weight, layer3.12.conv2.offset_s.bias, layer3.12.conv2.offset_l.weight, layer3.12.conv2.offset_l.bias, layer3.13.conv2.weight_diff, layer3.13.conv2.switch.weight, layer3.13.conv2.switch.bias, layer3.13.conv2.pre_context.weight, layer3.13.conv2.pre_context.bias, layer3.13.conv2.post_context.weight, layer3.13.conv2.post_context.bias, layer3.13.conv2.offset_s.weight, layer3.13.conv2.offset_s.bias, layer3.13.conv2.offset_l.weight, layer3.13.conv2.offset_l.bias, layer3.14.conv2.weight_diff, layer3.14.conv2.switch.weight, layer3.14.conv2.switch.bias, layer3.14.conv2.pre_context.weight, layer3.14.conv2.pre_context.bias, layer3.14.conv2.post_context.weight, layer3.14.conv2.post_context.bias, layer3.14.conv2.offset_s.weight, layer3.14.conv2.offset_s.bias, layer3.14.conv2.offset_l.weight, layer3.14.conv2.offset_l.bias, layer3.15.conv2.weight_diff, layer3.15.conv2.switch.weight, layer3.15.conv2.switch.bias, layer3.15.conv2.pre_context.weight, layer3.15.conv2.pre_context.bias, layer3.15.conv2.post_context.weight, layer3.15.conv2.post_context.bias, layer3.15.conv2.offset_s.weight, layer3.15.conv2.offset_s.bias, layer3.15.conv2.offset_l.weight, layer3.15.conv2.offset_l.bias, layer3.16.conv2.weight_diff, layer3.16.conv2.switch.weight, layer3.16.conv2.switch.bias, layer3.16.conv2.pre_context.weight, layer3.16.conv2.pre_context.bias, layer3.16.conv2.post_context.weight, layer3.16.conv2.post_context.bias, layer3.16.conv2.offset_s.weight, layer3.16.conv2.offset_s.bias, layer3.16.conv2.offset_l.weight, layer3.16.conv2.offset_l.bias, layer3.17.conv2.weight_diff, layer3.17.conv2.switch.weight, layer3.17.conv2.switch.bias, layer3.17.conv2.pre_context.weight, layer3.17.conv2.pre_context.bias, layer3.17.conv2.post_context.weight, layer3.17.conv2.post_context.bias, layer3.17.conv2.offset_s.weight, layer3.17.conv2.offset_s.bias, layer3.17.conv2.offset_l.weight, layer3.17.conv2.offset_l.bias, layer3.18.conv2.weight_diff, layer3.18.conv2.switch.weight, layer3.18.conv2.switch.bias, layer3.18.conv2.pre_context.weight, layer3.18.conv2.pre_context.bias, layer3.18.conv2.post_context.weight, layer3.18.conv2.post_context.bias, layer3.18.conv2.offset_s.weight, layer3.18.conv2.offset_s.bias, layer3.18.conv2.offset_l.weight, layer3.18.conv2.offset_l.bias, layer3.19.conv2.weight_diff, layer3.19.conv2.switch.weight, layer3.19.conv2.switch.bias, layer3.19.conv2.pre_context.weight, layer3.19.conv2.pre_context.bias, layer3.19.conv2.post_context.weight, layer3.19.conv2.post_context.bias, layer3.19.conv2.offset_s.weight, layer3.19.conv2.offset_s.bias, layer3.19.conv2.offset_l.weight, layer3.19.conv2.offset_l.bias, layer3.20.conv2.weight_diff, layer3.20.conv2.switch.weight, layer3.20.conv2.switch.bias, layer3.20.conv2.pre_context.weight, layer3.20.conv2.pre_context.bias, layer3.20.conv2.post_context.weight, layer3.20.conv2.post_context.bias, layer3.20.conv2.offset_s.weight, layer3.20.conv2.offset_s.bias, layer3.20.conv2.offset_l.weight, layer3.20.conv2.offset_l.bias, layer3.21.conv2.weight_diff, layer3.21.conv2.switch.weight, layer3.21.conv2.switch.bias, layer3.21.conv2.pre_context.weight, layer3.21.conv2.pre_context.bias, layer3.21.conv2.post_context.weight, layer3.21.conv2.post_context.bias, layer3.21.conv2.offset_s.weight, layer3.21.conv2.offset_s.bias, layer3.21.conv2.offset_l.weight, layer3.21.conv2.offset_l.bias, layer3.22.conv2.weight_diff, layer3.22.conv2.switch.weight, layer3.22.conv2.switch.bias, layer3.22.conv2.pre_context.weight, layer3.22.conv2.pre_context.bias, layer3.22.conv2.post_context.weight, layer3.22.conv2.post_context.bias, layer3.22.conv2.offset_s.weight, layer3.22.conv2.offset_s.bias, layer3.22.conv2.offset_l.weight, layer3.22.conv2.offset_l.bias, layer4.0.conv2.weight_diff, layer4.0.conv2.switch.weight, layer4.0.conv2.switch.bias, layer4.0.conv2.pre_context.weight, layer4.0.conv2.pre_context.bias, layer4.0.conv2.post_context.weight, layer4.0.conv2.post_context.bias, layer4.0.conv2.offset_s.weight, layer4.0.conv2.offset_s.bias, layer4.0.conv2.offset_l.weight, layer4.0.conv2.offset_l.bias, layer4.1.conv2.weight_diff, layer4.1.conv2.switch.weight, layer4.1.conv2.switch.bias, layer4.1.conv2.pre_context.weight, layer4.1.conv2.pre_context.bias, layer4.1.conv2.post_context.weight, layer4.1.conv2.post_context.bias, layer4.1.conv2.offset_s.weight, layer4.1.conv2.offset_s.bias, layer4.1.conv2.offset_l.weight, layer4.1.conv2.offset_l.bias, layer4.2.conv2.weight_diff, layer4.2.conv2.switch.weight, layer4.2.conv2.switch.bias, layer4.2.conv2.pre_context.weight, layer4.2.conv2.pre_context.bias, layer4.2.conv2.post_context.weight, layer4.2.conv2.post_context.bias, layer4.2.conv2.offset_s.weight, layer4.2.conv2.offset_s.bias, layer4.2.conv2.offset_l.weight, layer4.2.conv2.offset_l.bias\n",
            "\n",
            "09/19 08:40:17 - mmengine - INFO - Loads checkpoint by torchvision backend from path: torchvision://resnet101\n",
            "09/19 08:40:17 - mmengine - WARNING - The model and loaded state dict do not match exactly\n",
            "\n",
            "unexpected key in source state_dict: fc.weight, fc.bias\n",
            "\n",
            "missing keys in source state_dict: layer2.0.conv2.weight_diff, layer2.0.conv2.switch.weight, layer2.0.conv2.switch.bias, layer2.0.conv2.pre_context.weight, layer2.0.conv2.pre_context.bias, layer2.0.conv2.post_context.weight, layer2.0.conv2.post_context.bias, layer2.0.conv2.offset_s.weight, layer2.0.conv2.offset_s.bias, layer2.0.conv2.offset_l.weight, layer2.0.conv2.offset_l.bias, layer2.0.rfp_conv.weight, layer2.0.rfp_conv.bias, layer2.1.conv2.weight_diff, layer2.1.conv2.switch.weight, layer2.1.conv2.switch.bias, layer2.1.conv2.pre_context.weight, layer2.1.conv2.pre_context.bias, layer2.1.conv2.post_context.weight, layer2.1.conv2.post_context.bias, layer2.1.conv2.offset_s.weight, layer2.1.conv2.offset_s.bias, layer2.1.conv2.offset_l.weight, layer2.1.conv2.offset_l.bias, layer2.2.conv2.weight_diff, layer2.2.conv2.switch.weight, layer2.2.conv2.switch.bias, layer2.2.conv2.pre_context.weight, layer2.2.conv2.pre_context.bias, layer2.2.conv2.post_context.weight, layer2.2.conv2.post_context.bias, layer2.2.conv2.offset_s.weight, layer2.2.conv2.offset_s.bias, layer2.2.conv2.offset_l.weight, layer2.2.conv2.offset_l.bias, layer2.3.conv2.weight_diff, layer2.3.conv2.switch.weight, layer2.3.conv2.switch.bias, layer2.3.conv2.pre_context.weight, layer2.3.conv2.pre_context.bias, layer2.3.conv2.post_context.weight, layer2.3.conv2.post_context.bias, layer2.3.conv2.offset_s.weight, layer2.3.conv2.offset_s.bias, layer2.3.conv2.offset_l.weight, layer2.3.conv2.offset_l.bias, layer3.0.conv2.weight_diff, layer3.0.conv2.switch.weight, layer3.0.conv2.switch.bias, layer3.0.conv2.pre_context.weight, layer3.0.conv2.pre_context.bias, layer3.0.conv2.post_context.weight, layer3.0.conv2.post_context.bias, layer3.0.conv2.offset_s.weight, layer3.0.conv2.offset_s.bias, layer3.0.conv2.offset_l.weight, layer3.0.conv2.offset_l.bias, layer3.0.rfp_conv.weight, layer3.0.rfp_conv.bias, layer3.1.conv2.weight_diff, layer3.1.conv2.switch.weight, layer3.1.conv2.switch.bias, layer3.1.conv2.pre_context.weight, layer3.1.conv2.pre_context.bias, layer3.1.conv2.post_context.weight, layer3.1.conv2.post_context.bias, layer3.1.conv2.offset_s.weight, layer3.1.conv2.offset_s.bias, layer3.1.conv2.offset_l.weight, layer3.1.conv2.offset_l.bias, layer3.2.conv2.weight_diff, layer3.2.conv2.switch.weight, layer3.2.conv2.switch.bias, layer3.2.conv2.pre_context.weight, layer3.2.conv2.pre_context.bias, layer3.2.conv2.post_context.weight, layer3.2.conv2.post_context.bias, layer3.2.conv2.offset_s.weight, layer3.2.conv2.offset_s.bias, layer3.2.conv2.offset_l.weight, layer3.2.conv2.offset_l.bias, layer3.3.conv2.weight_diff, layer3.3.conv2.switch.weight, layer3.3.conv2.switch.bias, layer3.3.conv2.pre_context.weight, layer3.3.conv2.pre_context.bias, layer3.3.conv2.post_context.weight, layer3.3.conv2.post_context.bias, layer3.3.conv2.offset_s.weight, layer3.3.conv2.offset_s.bias, layer3.3.conv2.offset_l.weight, layer3.3.conv2.offset_l.bias, layer3.4.conv2.weight_diff, layer3.4.conv2.switch.weight, layer3.4.conv2.switch.bias, layer3.4.conv2.pre_context.weight, layer3.4.conv2.pre_context.bias, layer3.4.conv2.post_context.weight, layer3.4.conv2.post_context.bias, layer3.4.conv2.offset_s.weight, layer3.4.conv2.offset_s.bias, layer3.4.conv2.offset_l.weight, layer3.4.conv2.offset_l.bias, layer3.5.conv2.weight_diff, layer3.5.conv2.switch.weight, layer3.5.conv2.switch.bias, layer3.5.conv2.pre_context.weight, layer3.5.conv2.pre_context.bias, layer3.5.conv2.post_context.weight, layer3.5.conv2.post_context.bias, layer3.5.conv2.offset_s.weight, layer3.5.conv2.offset_s.bias, layer3.5.conv2.offset_l.weight, layer3.5.conv2.offset_l.bias, layer3.6.conv2.weight_diff, layer3.6.conv2.switch.weight, layer3.6.conv2.switch.bias, layer3.6.conv2.pre_context.weight, layer3.6.conv2.pre_context.bias, layer3.6.conv2.post_context.weight, layer3.6.conv2.post_context.bias, layer3.6.conv2.offset_s.weight, layer3.6.conv2.offset_s.bias, layer3.6.conv2.offset_l.weight, layer3.6.conv2.offset_l.bias, layer3.7.conv2.weight_diff, layer3.7.conv2.switch.weight, layer3.7.conv2.switch.bias, layer3.7.conv2.pre_context.weight, layer3.7.conv2.pre_context.bias, layer3.7.conv2.post_context.weight, layer3.7.conv2.post_context.bias, layer3.7.conv2.offset_s.weight, layer3.7.conv2.offset_s.bias, layer3.7.conv2.offset_l.weight, layer3.7.conv2.offset_l.bias, layer3.8.conv2.weight_diff, layer3.8.conv2.switch.weight, layer3.8.conv2.switch.bias, layer3.8.conv2.pre_context.weight, layer3.8.conv2.pre_context.bias, layer3.8.conv2.post_context.weight, layer3.8.conv2.post_context.bias, layer3.8.conv2.offset_s.weight, layer3.8.conv2.offset_s.bias, layer3.8.conv2.offset_l.weight, layer3.8.conv2.offset_l.bias, layer3.9.conv2.weight_diff, layer3.9.conv2.switch.weight, layer3.9.conv2.switch.bias, layer3.9.conv2.pre_context.weight, layer3.9.conv2.pre_context.bias, layer3.9.conv2.post_context.weight, layer3.9.conv2.post_context.bias, layer3.9.conv2.offset_s.weight, layer3.9.conv2.offset_s.bias, layer3.9.conv2.offset_l.weight, layer3.9.conv2.offset_l.bias, layer3.10.conv2.weight_diff, layer3.10.conv2.switch.weight, layer3.10.conv2.switch.bias, layer3.10.conv2.pre_context.weight, layer3.10.conv2.pre_context.bias, layer3.10.conv2.post_context.weight, layer3.10.conv2.post_context.bias, layer3.10.conv2.offset_s.weight, layer3.10.conv2.offset_s.bias, layer3.10.conv2.offset_l.weight, layer3.10.conv2.offset_l.bias, layer3.11.conv2.weight_diff, layer3.11.conv2.switch.weight, layer3.11.conv2.switch.bias, layer3.11.conv2.pre_context.weight, layer3.11.conv2.pre_context.bias, layer3.11.conv2.post_context.weight, layer3.11.conv2.post_context.bias, layer3.11.conv2.offset_s.weight, layer3.11.conv2.offset_s.bias, layer3.11.conv2.offset_l.weight, layer3.11.conv2.offset_l.bias, layer3.12.conv2.weight_diff, layer3.12.conv2.switch.weight, layer3.12.conv2.switch.bias, layer3.12.conv2.pre_context.weight, layer3.12.conv2.pre_context.bias, layer3.12.conv2.post_context.weight, layer3.12.conv2.post_context.bias, layer3.12.conv2.offset_s.weight, layer3.12.conv2.offset_s.bias, layer3.12.conv2.offset_l.weight, layer3.12.conv2.offset_l.bias, layer3.13.conv2.weight_diff, layer3.13.conv2.switch.weight, layer3.13.conv2.switch.bias, layer3.13.conv2.pre_context.weight, layer3.13.conv2.pre_context.bias, layer3.13.conv2.post_context.weight, layer3.13.conv2.post_context.bias, layer3.13.conv2.offset_s.weight, layer3.13.conv2.offset_s.bias, layer3.13.conv2.offset_l.weight, layer3.13.conv2.offset_l.bias, layer3.14.conv2.weight_diff, layer3.14.conv2.switch.weight, layer3.14.conv2.switch.bias, layer3.14.conv2.pre_context.weight, layer3.14.conv2.pre_context.bias, layer3.14.conv2.post_context.weight, layer3.14.conv2.post_context.bias, layer3.14.conv2.offset_s.weight, layer3.14.conv2.offset_s.bias, layer3.14.conv2.offset_l.weight, layer3.14.conv2.offset_l.bias, layer3.15.conv2.weight_diff, layer3.15.conv2.switch.weight, layer3.15.conv2.switch.bias, layer3.15.conv2.pre_context.weight, layer3.15.conv2.pre_context.bias, layer3.15.conv2.post_context.weight, layer3.15.conv2.post_context.bias, layer3.15.conv2.offset_s.weight, layer3.15.conv2.offset_s.bias, layer3.15.conv2.offset_l.weight, layer3.15.conv2.offset_l.bias, layer3.16.conv2.weight_diff, layer3.16.conv2.switch.weight, layer3.16.conv2.switch.bias, layer3.16.conv2.pre_context.weight, layer3.16.conv2.pre_context.bias, layer3.16.conv2.post_context.weight, layer3.16.conv2.post_context.bias, layer3.16.conv2.offset_s.weight, layer3.16.conv2.offset_s.bias, layer3.16.conv2.offset_l.weight, layer3.16.conv2.offset_l.bias, layer3.17.conv2.weight_diff, layer3.17.conv2.switch.weight, layer3.17.conv2.switch.bias, layer3.17.conv2.pre_context.weight, layer3.17.conv2.pre_context.bias, layer3.17.conv2.post_context.weight, layer3.17.conv2.post_context.bias, layer3.17.conv2.offset_s.weight, layer3.17.conv2.offset_s.bias, layer3.17.conv2.offset_l.weight, layer3.17.conv2.offset_l.bias, layer3.18.conv2.weight_diff, layer3.18.conv2.switch.weight, layer3.18.conv2.switch.bias, layer3.18.conv2.pre_context.weight, layer3.18.conv2.pre_context.bias, layer3.18.conv2.post_context.weight, layer3.18.conv2.post_context.bias, layer3.18.conv2.offset_s.weight, layer3.18.conv2.offset_s.bias, layer3.18.conv2.offset_l.weight, layer3.18.conv2.offset_l.bias, layer3.19.conv2.weight_diff, layer3.19.conv2.switch.weight, layer3.19.conv2.switch.bias, layer3.19.conv2.pre_context.weight, layer3.19.conv2.pre_context.bias, layer3.19.conv2.post_context.weight, layer3.19.conv2.post_context.bias, layer3.19.conv2.offset_s.weight, layer3.19.conv2.offset_s.bias, layer3.19.conv2.offset_l.weight, layer3.19.conv2.offset_l.bias, layer3.20.conv2.weight_diff, layer3.20.conv2.switch.weight, layer3.20.conv2.switch.bias, layer3.20.conv2.pre_context.weight, layer3.20.conv2.pre_context.bias, layer3.20.conv2.post_context.weight, layer3.20.conv2.post_context.bias, layer3.20.conv2.offset_s.weight, layer3.20.conv2.offset_s.bias, layer3.20.conv2.offset_l.weight, layer3.20.conv2.offset_l.bias, layer3.21.conv2.weight_diff, layer3.21.conv2.switch.weight, layer3.21.conv2.switch.bias, layer3.21.conv2.pre_context.weight, layer3.21.conv2.pre_context.bias, layer3.21.conv2.post_context.weight, layer3.21.conv2.post_context.bias, layer3.21.conv2.offset_s.weight, layer3.21.conv2.offset_s.bias, layer3.21.conv2.offset_l.weight, layer3.21.conv2.offset_l.bias, layer3.22.conv2.weight_diff, layer3.22.conv2.switch.weight, layer3.22.conv2.switch.bias, layer3.22.conv2.pre_context.weight, layer3.22.conv2.pre_context.bias, layer3.22.conv2.post_context.weight, layer3.22.conv2.post_context.bias, layer3.22.conv2.offset_s.weight, layer3.22.conv2.offset_s.bias, layer3.22.conv2.offset_l.weight, layer3.22.conv2.offset_l.bias, layer4.0.conv2.weight_diff, layer4.0.conv2.switch.weight, layer4.0.conv2.switch.bias, layer4.0.conv2.pre_context.weight, layer4.0.conv2.pre_context.bias, layer4.0.conv2.post_context.weight, layer4.0.conv2.post_context.bias, layer4.0.conv2.offset_s.weight, layer4.0.conv2.offset_s.bias, layer4.0.conv2.offset_l.weight, layer4.0.conv2.offset_l.bias, layer4.0.rfp_conv.weight, layer4.0.rfp_conv.bias, layer4.1.conv2.weight_diff, layer4.1.conv2.switch.weight, layer4.1.conv2.switch.bias, layer4.1.conv2.pre_context.weight, layer4.1.conv2.pre_context.bias, layer4.1.conv2.post_context.weight, layer4.1.conv2.post_context.bias, layer4.1.conv2.offset_s.weight, layer4.1.conv2.offset_s.bias, layer4.1.conv2.offset_l.weight, layer4.1.conv2.offset_l.bias, layer4.2.conv2.weight_diff, layer4.2.conv2.switch.weight, layer4.2.conv2.switch.bias, layer4.2.conv2.pre_context.weight, layer4.2.conv2.pre_context.bias, layer4.2.conv2.post_context.weight, layer4.2.conv2.post_context.bias, layer4.2.conv2.offset_s.weight, layer4.2.conv2.offset_s.bias, layer4.2.conv2.offset_l.weight, layer4.2.conv2.offset_l.bias\n",
            "\n",
            "Loads checkpoint by local backend from path: /content/drive/MyDrive/models/detectors_htc_r101_20e_coco_20210419_203638-348d533b.pth\n",
            "The model and loaded state dict do not match exactly\n",
            "\n",
            "size mismatch for roi_head.bbox_head.0.fc_cls.weight: copying a param with shape torch.Size([81, 1024]) from checkpoint, the shape in current model is torch.Size([16, 1024]).\n",
            "size mismatch for roi_head.bbox_head.0.fc_cls.bias: copying a param with shape torch.Size([81]) from checkpoint, the shape in current model is torch.Size([16]).\n",
            "size mismatch for roi_head.bbox_head.1.fc_cls.weight: copying a param with shape torch.Size([81, 1024]) from checkpoint, the shape in current model is torch.Size([16, 1024]).\n",
            "size mismatch for roi_head.bbox_head.1.fc_cls.bias: copying a param with shape torch.Size([81]) from checkpoint, the shape in current model is torch.Size([16]).\n",
            "size mismatch for roi_head.bbox_head.2.fc_cls.weight: copying a param with shape torch.Size([81, 1024]) from checkpoint, the shape in current model is torch.Size([16, 1024]).\n",
            "size mismatch for roi_head.bbox_head.2.fc_cls.bias: copying a param with shape torch.Size([81]) from checkpoint, the shape in current model is torch.Size([16]).\n",
            "size mismatch for roi_head.mask_head.1.conv_logits.weight: copying a param with shape torch.Size([80, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([15, 256, 1, 1]).\n",
            "size mismatch for roi_head.mask_head.1.conv_logits.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([15]).\n",
            "size mismatch for roi_head.mask_head.2.conv_logits.weight: copying a param with shape torch.Size([80, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([15, 256, 1, 1]).\n",
            "size mismatch for roi_head.mask_head.2.conv_logits.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([15]).\n",
            "unexpected key in source state_dict: roi_head.semantic_head.lateral_convs.0.conv.weight, roi_head.semantic_head.lateral_convs.0.conv.bias, roi_head.semantic_head.lateral_convs.1.conv.weight, roi_head.semantic_head.lateral_convs.1.conv.bias, roi_head.semantic_head.lateral_convs.2.conv.weight, roi_head.semantic_head.lateral_convs.2.conv.bias, roi_head.semantic_head.lateral_convs.3.conv.weight, roi_head.semantic_head.lateral_convs.3.conv.bias, roi_head.semantic_head.lateral_convs.4.conv.weight, roi_head.semantic_head.lateral_convs.4.conv.bias, roi_head.semantic_head.convs.0.conv.weight, roi_head.semantic_head.convs.0.conv.bias, roi_head.semantic_head.convs.1.conv.weight, roi_head.semantic_head.convs.1.conv.bias, roi_head.semantic_head.convs.2.conv.weight, roi_head.semantic_head.convs.2.conv.bias, roi_head.semantic_head.convs.3.conv.weight, roi_head.semantic_head.convs.3.conv.bias, roi_head.semantic_head.conv_embedding.conv.weight, roi_head.semantic_head.conv_embedding.conv.bias, roi_head.semantic_head.conv_logits.weight, roi_head.semantic_head.conv_logits.bias\n",
            "\n",
            "09/19 08:40:18 - mmengine - INFO - Load checkpoint from /content/drive/MyDrive/models/detectors_htc_r101_20e_coco_20210419_203638-348d533b.pth\n",
            "09/19 08:40:18 - mmengine - WARNING - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
            "09/19 08:40:18 - mmengine - INFO - Checkpoints will be saved to /content/drive/MyDrive/C:\\Users\\HP\\mmdetection\\demo\\work_dir.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "09/19 08:58:46 - mmengine - INFO - Exp name: customconfig (2)_20230919_083929\n",
            "09/19 09:13:26 - mmengine - INFO - Exp name: customconfig (2)_20230919_083929\n",
            "09/19 09:13:26 - mmengine - INFO - Epoch(train)  [1][1774/1774]  lr: 5.0000e-03  eta: 4:58:11  time: 1.1206  data_time: 0.0193  memory: 5360  loss: 1.5590  loss_rpn_cls: 0.0989  loss_rpn_bbox: 0.0539  s0.loss_cls: 0.3085  s0.acc: 83.3984  s0.loss_bbox: 0.1288  s0.loss_mask: 0.3291  s1.loss_cls: 0.1449  s1.acc: 83.0078  s1.loss_bbox: 0.1219  s1.loss_mask: 0.1618  s2.loss_cls: 0.0689  s2.acc: 85.9375  s2.loss_bbox: 0.0637  s2.loss_mask: 0.0785\n",
            "09/19 09:13:26 - mmengine - INFO - Saving checkpoint at 1 epochs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/mmdetection/mmdet/models/roi_heads/mask_heads/fcn_mask_head.py:339: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
            "  mask_preds = bboxes.new_tensor(mask_preds)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "09/19 09:19:02 - mmengine - INFO - Evaluating bbox...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.05s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.84s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=1.55s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.260\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.459\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.266\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.123\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.282\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.263\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.480\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.480\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.480\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.176\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.493\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.466\n",
            "09/19 09:19:06 - mmengine - INFO - bbox_mAP_copypaste: 0.260 0.459 0.266 0.123 0.282 0.263\n",
            "09/19 09:19:06 - mmengine - INFO - Evaluating segm...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.59s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=4.26s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=1.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.250\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.451\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.274\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.071\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.269\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.273\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.448\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.448\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.448\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.134\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.458\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.436\n",
            "09/19 09:19:13 - mmengine - INFO - segm_mAP_copypaste: 0.250 0.451 0.274 0.071 0.269 0.273\n",
            "09/19 09:19:13 - mmengine - INFO - Epoch(val) [1][336/336]    coco/bbox_mAP: 0.2600  coco/bbox_mAP_50: 0.4590  coco/bbox_mAP_75: 0.2660  coco/bbox_mAP_s: 0.1230  coco/bbox_mAP_m: 0.2820  coco/bbox_mAP_l: 0.2630  coco/segm_mAP: 0.2500  coco/segm_mAP_50: 0.4510  coco/segm_mAP_75: 0.2740  coco/segm_mAP_s: 0.0710  coco/segm_mAP_m: 0.2690  coco/segm_mAP_l: 0.2730  data_time: 0.0893  time: 0.9314\n",
            "09/19 09:23:34 - mmengine - INFO - Exp name: customconfig (2)_20230919_083929\n",
            "09/19 09:42:40 - mmengine - INFO - Exp name: customconfig (2)_20230919_083929\n",
            "09/19 09:53:15 - mmengine - INFO - Exp name: customconfig (2)_20230919_083929\n",
            "09/19 09:53:15 - mmengine - INFO - Epoch(train)  [2][1774/1774]  lr: 5.0000e-03  eta: 4:28:42  time: 1.1514  data_time: 0.0195  memory: 5360  loss: 1.2883  loss_rpn_cls: 0.0535  loss_rpn_bbox: 0.0440  s0.loss_cls: 0.2085  s0.acc: 96.8750  s0.loss_bbox: 0.1236  s0.loss_mask: 0.2958  s1.loss_cls: 0.0974  s1.acc: 98.4375  s1.loss_bbox: 0.1329  s1.loss_mask: 0.1420  s2.loss_cls: 0.0471  s2.acc: 99.4141  s2.loss_bbox: 0.0762  s2.loss_mask: 0.0672\n",
            "09/19 09:53:15 - mmengine - INFO - Saving checkpoint at 2 epochs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/mmdetection/mmdet/models/roi_heads/mask_heads/fcn_mask_head.py:339: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
            "  mask_preds = bboxes.new_tensor(mask_preds)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "09/19 09:58:28 - mmengine - INFO - Evaluating bbox...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.29s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.85s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=1.00s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.324\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.562\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.326\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.137\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.327\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.338\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.524\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.524\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.524\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.216\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.521\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.523\n",
            "09/19 09:58:31 - mmengine - INFO - bbox_mAP_copypaste: 0.324 0.562 0.326 0.137 0.327 0.338\n",
            "09/19 09:58:31 - mmengine - INFO - Evaluating segm...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.37s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=2.38s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.98s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.283\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.539\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.262\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.062\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.291\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.321\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.448\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.448\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.448\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.163\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.451\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.433\n",
            "09/19 09:58:35 - mmengine - INFO - segm_mAP_copypaste: 0.283 0.539 0.262 0.062 0.291 0.321\n",
            "09/19 09:58:35 - mmengine - INFO - Epoch(val) [2][336/336]    coco/bbox_mAP: 0.3240  coco/bbox_mAP_50: 0.5620  coco/bbox_mAP_75: 0.3260  coco/bbox_mAP_s: 0.1370  coco/bbox_mAP_m: 0.3270  coco/bbox_mAP_l: 0.3380  coco/segm_mAP: 0.2830  coco/segm_mAP_50: 0.5390  coco/segm_mAP_75: 0.2620  coco/segm_mAP_s: 0.0620  coco/segm_mAP_m: 0.2910  coco/segm_mAP_l: 0.3210  data_time: 0.0765  time: 0.8965\n",
            "09/19 10:07:21 - mmengine - INFO - Exp name: customconfig (2)_20230919_083929\n",
            "09/19 10:26:45 - mmengine - INFO - Exp name: customconfig (2)_20230919_083929\n",
            "09/19 10:33:03 - mmengine - INFO - Exp name: customconfig (2)_20230919_083929\n",
            "09/19 10:33:03 - mmengine - INFO - Epoch(train)  [3][1774/1774]  lr: 5.0000e-03  eta: 3:57:08  time: 1.1653  data_time: 0.0191  memory: 5360  loss: 1.1926  loss_rpn_cls: 0.0376  loss_rpn_bbox: 0.0390  s0.loss_cls: 0.1840  s0.acc: 100.0000  s0.loss_bbox: 0.1161  s0.loss_mask: 0.2761  s1.loss_cls: 0.0858  s1.acc: 100.0000  s1.loss_bbox: 0.1331  s1.loss_mask: 0.1340  s2.loss_cls: 0.0423  s2.acc: 100.0000  s2.loss_bbox: 0.0810  s2.loss_mask: 0.0637\n",
            "09/19 10:33:03 - mmengine - INFO - Saving checkpoint at 3 epochs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/mmdetection/mmdet/models/roi_heads/mask_heads/fcn_mask_head.py:339: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
            "  mask_preds = bboxes.new_tensor(mask_preds)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "09/19 10:38:14 - mmengine - INFO - Evaluating bbox...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.05s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=2.10s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=1.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.351\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.595\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.363\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.107\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.345\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.358\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.538\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.538\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.538\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.191\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.531\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.565\n",
            "09/19 10:38:17 - mmengine - INFO - bbox_mAP_copypaste: 0.351 0.595 0.363 0.107 0.345 0.358\n",
            "09/19 10:38:17 - mmengine - INFO - Evaluating segm...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.40s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=2.67s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=1.79s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.328\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.582\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.329\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.071\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.313\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.355\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.486\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.486\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.486\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.146\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.487\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.488\n",
            "09/19 10:38:23 - mmengine - INFO - segm_mAP_copypaste: 0.328 0.582 0.329 0.071 0.313 0.355\n",
            "09/19 10:38:23 - mmengine - INFO - Epoch(val) [3][336/336]    coco/bbox_mAP: 0.3510  coco/bbox_mAP_50: 0.5950  coco/bbox_mAP_75: 0.3630  coco/bbox_mAP_s: 0.1070  coco/bbox_mAP_m: 0.3450  coco/bbox_mAP_l: 0.3580  coco/segm_mAP: 0.3280  coco/segm_mAP_50: 0.5820  coco/segm_mAP_75: 0.3290  coco/segm_mAP_s: 0.0710  coco/segm_mAP_m: 0.3130  coco/segm_mAP_l: 0.3550  data_time: 0.0787  time: 0.8953\n",
            "09/19 10:51:47 - mmengine - INFO - Exp name: customconfig (2)_20230919_083929\n",
            "09/19 11:11:13 - mmengine - INFO - Exp name: customconfig (2)_20230919_083929\n",
            "09/19 11:13:05 - mmengine - INFO - Exp name: customconfig (2)_20230919_083929\n",
            "09/19 11:13:05 - mmengine - INFO - Epoch(train)  [4][1774/1774]  lr: 5.0000e-03  eta: 3:24:29  time: 1.1736  data_time: 0.0191  memory: 5360  loss: 1.1123  loss_rpn_cls: 0.0291  loss_rpn_bbox: 0.0357  s0.loss_cls: 0.1604  s0.acc: 92.9688  s0.loss_bbox: 0.1061  s0.loss_mask: 0.2658  s1.loss_cls: 0.0748  s1.acc: 94.9219  s1.loss_bbox: 0.1291  s1.loss_mask: 0.1297  s2.loss_cls: 0.0378  s2.acc: 96.6797  s2.loss_bbox: 0.0822  s2.loss_mask: 0.0617\n",
            "09/19 11:13:05 - mmengine - INFO - Saving checkpoint at 4 epochs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/mmdetection/mmdet/models/roi_heads/mask_heads/fcn_mask_head.py:339: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
            "  mask_preds = bboxes.new_tensor(mask_preds)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "09/19 11:18:14 - mmengine - INFO - Evaluating bbox...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=2.09s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.99s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.361\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.608\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.381\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.160\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.353\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.415\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.548\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.548\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.548\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.226\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.538\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.576\n",
            "09/19 11:18:18 - mmengine - INFO - bbox_mAP_copypaste: 0.361 0.608 0.381 0.160 0.353 0.415\n",
            "09/19 11:18:18 - mmengine - INFO - Evaluating segm...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.41s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=4.71s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=1.65s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.345\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.597\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.367\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.104\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.347\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.402\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.507\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.507\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.507\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.175\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.519\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.514\n",
            "09/19 11:18:25 - mmengine - INFO - segm_mAP_copypaste: 0.345 0.597 0.367 0.104 0.347 0.402\n",
            "09/19 11:18:25 - mmengine - INFO - Epoch(val) [4][336/336]    coco/bbox_mAP: 0.3610  coco/bbox_mAP_50: 0.6080  coco/bbox_mAP_75: 0.3810  coco/bbox_mAP_s: 0.1600  coco/bbox_mAP_m: 0.3530  coco/bbox_mAP_l: 0.4150  coco/segm_mAP: 0.3450  coco/segm_mAP_50: 0.5970  coco/segm_mAP_75: 0.3670  coco/segm_mAP_s: 0.1040  coco/segm_mAP_m: 0.3470  coco/segm_mAP_l: 0.4020  data_time: 0.0760  time: 0.8890\n",
            "09/19 11:36:10 - mmengine - INFO - Exp name: customconfig (2)_20230919_083929\n",
            "09/19 11:53:18 - mmengine - INFO - Exp name: customconfig (2)_20230919_083929\n",
            "09/19 11:53:18 - mmengine - INFO - Epoch(train)  [5][1774/1774]  lr: 5.0000e-03  eta: 2:51:12  time: 1.1798  data_time: 0.0188  memory: 5360  loss: 1.0527  loss_rpn_cls: 0.0243  loss_rpn_bbox: 0.0328  s0.loss_cls: 0.1476  s0.acc: 98.4375  s0.loss_bbox: 0.0993  s0.loss_mask: 0.2533  s1.loss_cls: 0.0684  s1.acc: 99.8047  s1.loss_bbox: 0.1245  s1.loss_mask: 0.1244  s2.loss_cls: 0.0355  s2.acc: 99.8047  s2.loss_bbox: 0.0829  s2.loss_mask: 0.0596\n",
            "09/19 11:53:18 - mmengine - INFO - Saving checkpoint at 5 epochs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/mmdetection/mmdet/models/roi_heads/mask_heads/fcn_mask_head.py:339: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
            "  mask_preds = bboxes.new_tensor(mask_preds)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "09/19 11:58:05 - mmengine - INFO - Evaluating bbox...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.72s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.89s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.350\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.597\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.347\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.144\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.362\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.365\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.528\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.528\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.528\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.246\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.531\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.554\n",
            "09/19 11:58:08 - mmengine - INFO - bbox_mAP_copypaste: 0.350 0.597 0.347 0.144 0.362 0.365\n",
            "09/19 11:58:08 - mmengine - INFO - Evaluating segm...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.31s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=2.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.85s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.323\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.584\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.326\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.090\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.346\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.345\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.488\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.488\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.488\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.207\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.499\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.501\n",
            "09/19 11:58:12 - mmengine - INFO - segm_mAP_copypaste: 0.323 0.584 0.326 0.090 0.346 0.345\n",
            "09/19 11:58:12 - mmengine - INFO - Epoch(val) [5][336/336]    coco/bbox_mAP: 0.3500  coco/bbox_mAP_50: 0.5970  coco/bbox_mAP_75: 0.3470  coco/bbox_mAP_s: 0.1440  coco/bbox_mAP_m: 0.3620  coco/bbox_mAP_l: 0.3650  coco/segm_mAP: 0.3230  coco/segm_mAP_50: 0.5840  coco/segm_mAP_75: 0.3260  coco/segm_mAP_s: 0.0900  coco/segm_mAP_m: 0.3460  coco/segm_mAP_l: 0.3450  data_time: 0.0760  time: 0.8220\n",
            "09/19 12:00:49 - mmengine - INFO - Exp name: customconfig (2)_20230919_083929\n"
          ]
        }
      ],
      "source": [
        "from mmengine import Config\n",
        "\n",
        "cfg = Config.fromfile('/content/drive/MyDrive/models/customconfig (2).py')\n",
        "cfg['load_from']=r'/content/drive/MyDrive/models/detectors_htc_r101_20e_coco_20210419_203638-348d533b.pth'\n",
        "%cd /content/drive/MyDrive\n",
        "\n",
        "from mmengine.runner import Runner\n",
        "runner = Runner.from_cfg(cfg)\n",
        "runner.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYhAwhxvRf92",
        "outputId": "4a9338b6-0008-45fd-a654-3391812a4b14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive\n",
            "09/20 14:39:11 - mmengine - INFO - \n",
            "------------------------------------------------------------\n",
            "System environment:\n",
            "    sys.platform: linux\n",
            "    Python: 3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0]\n",
            "    CUDA available: True\n",
            "    numpy_random_seed: 431679970\n",
            "    GPU 0: Tesla T4\n",
            "    CUDA_HOME: /usr/local/cuda\n",
            "    NVCC: Cuda compilation tools, release 11.8, V11.8.89\n",
            "    GCC: x86_64-linux-gnu-gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
            "    PyTorch: 2.0.1+cu118\n",
            "    PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 9.3\n",
            "  - C++ Version: 201703\n",
            "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 11.8\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
            "  - CuDNN 8.7\n",
            "  - Magma 2.6.1\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "    TorchVision: 0.15.2+cu118\n",
            "    OpenCV: 4.8.0\n",
            "    MMEngine: 0.8.4\n",
            "\n",
            "Runtime environment:\n",
            "    cudnn_benchmark: False\n",
            "    dist_cfg: {'backend': 'nccl'}\n",
            "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
            "    seed: 431679970\n",
            "    Distributed launcher: none\n",
            "    Distributed training: False\n",
            "    GPU number: 1\n",
            "------------------------------------------------------------\n",
            "\n",
            "09/20 14:39:11 - mmengine - INFO - Config:\n",
            "auto_scale_lr = dict(base_batch_size=16, enable=False)\n",
            "backend_args = None\n",
            "classes = (\n",
            "    'Bdr',\n",
            "    'Bone Loss',\n",
            "    'Bridge',\n",
            "    'Caries',\n",
            "    'Crown',\n",
            "    'Filling',\n",
            "    'Impaction',\n",
            "    'Implant',\n",
            "    'Periapical Abscess',\n",
            "    'Rct',\n",
            "    'Rct +Post',\n",
            "    'Retentive Pin',\n",
            "    'Shadow',\n",
            "    'Splinted Crowns',\n",
            "    'Unerupted',\n",
            ")\n",
            "data_root = 'data/diagnosis'\n",
            "dataset_type = 'DiagnosisDataset'\n",
            "default_hooks = dict(\n",
            "    checkpoint=dict(interval=1, type='CheckpointHook'),\n",
            "    logger=dict(interval=1774, type='LoggerHook'),\n",
            "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    timer=dict(type='IterTimerHook'),\n",
            "    visualization=dict(type='DetVisualizationHook'))\n",
            "default_scope = 'mmdet'\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=False,\n",
            "    dist_cfg=dict(backend='nccl'),\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
            "load_from = '/content/drive/MyDrive/models/epoch_5.pth'\n",
            "log_level = 'INFO'\n",
            "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=1774)\n",
            "lr_config = dict(step=[\n",
            "    25,\n",
            "    30,\n",
            "])\n",
            "max_epochs = 20\n",
            "model = dict(\n",
            "    backbone=dict(\n",
            "        conv_cfg=dict(type='ConvAWS'),\n",
            "        depth=101,\n",
            "        frozen_stages=4,\n",
            "        init_cfg=dict(checkpoint='torchvision://resnet101', type='Pretrained'),\n",
            "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "        norm_eval=True,\n",
            "        num_stages=4,\n",
            "        out_indices=(\n",
            "            0,\n",
            "            1,\n",
            "            2,\n",
            "            3,\n",
            "        ),\n",
            "        output_img=True,\n",
            "        sac=dict(type='SAC', use_deform=True),\n",
            "        stage_with_sac=(\n",
            "            False,\n",
            "            True,\n",
            "            True,\n",
            "            True,\n",
            "        ),\n",
            "        style='pytorch',\n",
            "        type='DetectoRS_ResNet'),\n",
            "    data_preprocessor=dict(\n",
            "        bgr_to_rgb=True,\n",
            "        mean=[\n",
            "            123.675,\n",
            "            116.28,\n",
            "            103.53,\n",
            "        ],\n",
            "        pad_seg=True,\n",
            "        pad_size_divisor=32,\n",
            "        std=[\n",
            "            58.395,\n",
            "            57.12,\n",
            "            57.375,\n",
            "        ],\n",
            "        type='DetDataPreprocessor'),\n",
            "    neck=dict(\n",
            "        aspp_dilations=(\n",
            "            1,\n",
            "            3,\n",
            "            6,\n",
            "            1,\n",
            "        ),\n",
            "        aspp_out_channels=64,\n",
            "        in_channels=[\n",
            "            256,\n",
            "            512,\n",
            "            1024,\n",
            "            2048,\n",
            "        ],\n",
            "        num_outs=5,\n",
            "        out_channels=256,\n",
            "        rfp_backbone=dict(\n",
            "            conv_cfg=dict(type='ConvAWS'),\n",
            "            depth=101,\n",
            "            frozen_stages=1,\n",
            "            norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "            norm_eval=True,\n",
            "            num_stages=4,\n",
            "            out_indices=(\n",
            "                0,\n",
            "                1,\n",
            "                2,\n",
            "                3,\n",
            "            ),\n",
            "            pretrained='torchvision://resnet101',\n",
            "            rfp_inplanes=256,\n",
            "            sac=dict(type='SAC', use_deform=True),\n",
            "            stage_with_sac=(\n",
            "                False,\n",
            "                True,\n",
            "                True,\n",
            "                True,\n",
            "            ),\n",
            "            style='pytorch',\n",
            "            type='DetectoRS_ResNet'),\n",
            "        rfp_steps=2,\n",
            "        type='RFP'),\n",
            "    roi_head=dict(\n",
            "        bbox_head=[\n",
            "            dict(\n",
            "                bbox_coder=dict(\n",
            "                    target_means=[\n",
            "                        0.0,\n",
            "                        0.0,\n",
            "                        0.0,\n",
            "                        0.0,\n",
            "                    ],\n",
            "                    target_stds=[\n",
            "                        0.1,\n",
            "                        0.1,\n",
            "                        0.2,\n",
            "                        0.2,\n",
            "                    ],\n",
            "                    type='DeltaXYWHBBoxCoder'),\n",
            "                fc_out_channels=1024,\n",
            "                in_channels=256,\n",
            "                loss_bbox=dict(beta=1.0, loss_weight=1.0, type='SmoothL1Loss'),\n",
            "                loss_cls=dict(\n",
            "                    loss_weight=1.0,\n",
            "                    type='CrossEntropyLoss',\n",
            "                    use_sigmoid=False),\n",
            "                num_classes=15,\n",
            "                reg_class_agnostic=True,\n",
            "                roi_feat_size=7,\n",
            "                type='Shared2FCBBoxHead'),\n",
            "            dict(\n",
            "                bbox_coder=dict(\n",
            "                    target_means=[\n",
            "                        0.0,\n",
            "                        0.0,\n",
            "                        0.0,\n",
            "                        0.0,\n",
            "                    ],\n",
            "                    target_stds=[\n",
            "                        0.05,\n",
            "                        0.05,\n",
            "                        0.1,\n",
            "                        0.1,\n",
            "                    ],\n",
            "                    type='DeltaXYWHBBoxCoder'),\n",
            "                fc_out_channels=1024,\n",
            "                in_channels=256,\n",
            "                loss_bbox=dict(beta=1.0, loss_weight=1.0, type='SmoothL1Loss'),\n",
            "                loss_cls=dict(\n",
            "                    loss_weight=1.0,\n",
            "                    type='CrossEntropyLoss',\n",
            "                    use_sigmoid=False),\n",
            "                num_classes=15,\n",
            "                reg_class_agnostic=True,\n",
            "                roi_feat_size=7,\n",
            "                type='Shared2FCBBoxHead'),\n",
            "            dict(\n",
            "                bbox_coder=dict(\n",
            "                    target_means=[\n",
            "                        0.0,\n",
            "                        0.0,\n",
            "                        0.0,\n",
            "                        0.0,\n",
            "                    ],\n",
            "                    target_stds=[\n",
            "                        0.033,\n",
            "                        0.033,\n",
            "                        0.067,\n",
            "                        0.067,\n",
            "                    ],\n",
            "                    type='DeltaXYWHBBoxCoder'),\n",
            "                fc_out_channels=1024,\n",
            "                in_channels=256,\n",
            "                loss_bbox=dict(beta=1.0, loss_weight=1.0, type='SmoothL1Loss'),\n",
            "                loss_cls=dict(\n",
            "                    loss_weight=1.0,\n",
            "                    type='CrossEntropyLoss',\n",
            "                    use_sigmoid=False),\n",
            "                num_classes=15,\n",
            "                reg_class_agnostic=True,\n",
            "                roi_feat_size=7,\n",
            "                type='Shared2FCBBoxHead'),\n",
            "        ],\n",
            "        bbox_roi_extractor=dict(\n",
            "            featmap_strides=[\n",
            "                4,\n",
            "                8,\n",
            "                16,\n",
            "                32,\n",
            "            ],\n",
            "            out_channels=256,\n",
            "            roi_layer=dict(output_size=7, sampling_ratio=0, type='RoIAlign'),\n",
            "            type='SingleRoIExtractor'),\n",
            "        interleaved=True,\n",
            "        mask_head=[\n",
            "            dict(\n",
            "                conv_out_channels=256,\n",
            "                in_channels=256,\n",
            "                loss_mask=dict(\n",
            "                    loss_weight=1.0, type='CrossEntropyLoss', use_mask=True),\n",
            "                num_classes=80,\n",
            "                num_convs=4,\n",
            "                type='HTCMaskHead',\n",
            "                with_conv_res=False),\n",
            "            dict(\n",
            "                conv_out_channels=256,\n",
            "                in_channels=256,\n",
            "                loss_mask=dict(\n",
            "                    loss_weight=1.0, type='CrossEntropyLoss', use_mask=True),\n",
            "                num_classes=15,\n",
            "                num_convs=4,\n",
            "                type='HTCMaskHead'),\n",
            "            dict(\n",
            "                conv_out_channels=256,\n",
            "                in_channels=256,\n",
            "                loss_mask=dict(\n",
            "                    loss_weight=1.0, type='CrossEntropyLoss', use_mask=True),\n",
            "                num_classes=15,\n",
            "                num_convs=4,\n",
            "                type='HTCMaskHead'),\n",
            "        ],\n",
            "        mask_info_flow=True,\n",
            "        mask_roi_extractor=dict(\n",
            "            featmap_strides=[\n",
            "                4,\n",
            "                8,\n",
            "                16,\n",
            "                32,\n",
            "            ],\n",
            "            out_channels=256,\n",
            "            roi_layer=dict(output_size=14, sampling_ratio=0, type='RoIAlign'),\n",
            "            type='SingleRoIExtractor'),\n",
            "        num_stages=3,\n",
            "        stage_loss_weights=[\n",
            "            1,\n",
            "            0.5,\n",
            "            0.25,\n",
            "        ],\n",
            "        type='HybridTaskCascadeRoIHead'),\n",
            "    rpn_head=dict(\n",
            "        anchor_generator=dict(\n",
            "            ratios=[\n",
            "                0.5,\n",
            "                1.0,\n",
            "                2.0,\n",
            "            ],\n",
            "            scales=[\n",
            "                8,\n",
            "            ],\n",
            "            strides=[\n",
            "                4,\n",
            "                8,\n",
            "                16,\n",
            "                32,\n",
            "                64,\n",
            "            ],\n",
            "            type='AnchorGenerator'),\n",
            "        bbox_coder=dict(\n",
            "            target_means=[\n",
            "                0.0,\n",
            "                0.0,\n",
            "                0.0,\n",
            "                0.0,\n",
            "            ],\n",
            "            target_stds=[\n",
            "                1.0,\n",
            "                1.0,\n",
            "                1.0,\n",
            "                1.0,\n",
            "            ],\n",
            "            type='DeltaXYWHBBoxCoder'),\n",
            "        feat_channels=256,\n",
            "        in_channels=256,\n",
            "        loss_bbox=dict(\n",
            "            beta=0.1111111111111111, loss_weight=1.0, type='SmoothL1Loss'),\n",
            "        loss_cls=dict(\n",
            "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=True),\n",
            "        type='RPNHead'),\n",
            "    test_cfg=dict(\n",
            "        rcnn=dict(\n",
            "            mask_thr_binary=0.5,\n",
            "            max_per_img=100,\n",
            "            nms=dict(iou_threshold=0.5, type='nms'),\n",
            "            score_thr=0.001),\n",
            "        rpn=dict(\n",
            "            max_per_img=1000,\n",
            "            min_bbox_size=0,\n",
            "            nms=dict(iou_threshold=0.7, type='nms'),\n",
            "            nms_pre=1000)),\n",
            "    train_cfg=dict(\n",
            "        rcnn=[\n",
            "            dict(\n",
            "                assigner=dict(\n",
            "                    ignore_iof_thr=-1,\n",
            "                    min_pos_iou=0.5,\n",
            "                    neg_iou_thr=0.5,\n",
            "                    pos_iou_thr=0.5,\n",
            "                    type='MaxIoUAssigner'),\n",
            "                debug=False,\n",
            "                mask_size=28,\n",
            "                pos_weight=-1,\n",
            "                sampler=dict(\n",
            "                    add_gt_as_proposals=True,\n",
            "                    neg_pos_ub=-1,\n",
            "                    num=512,\n",
            "                    pos_fraction=0.25,\n",
            "                    type='RandomSampler')),\n",
            "            dict(\n",
            "                assigner=dict(\n",
            "                    ignore_iof_thr=-1,\n",
            "                    min_pos_iou=0.6,\n",
            "                    neg_iou_thr=0.6,\n",
            "                    pos_iou_thr=0.6,\n",
            "                    type='MaxIoUAssigner'),\n",
            "                debug=False,\n",
            "                mask_size=28,\n",
            "                pos_weight=-1,\n",
            "                sampler=dict(\n",
            "                    add_gt_as_proposals=True,\n",
            "                    neg_pos_ub=-1,\n",
            "                    num=512,\n",
            "                    pos_fraction=0.25,\n",
            "                    type='RandomSampler')),\n",
            "            dict(\n",
            "                assigner=dict(\n",
            "                    ignore_iof_thr=-1,\n",
            "                    min_pos_iou=0.7,\n",
            "                    neg_iou_thr=0.7,\n",
            "                    pos_iou_thr=0.7,\n",
            "                    type='MaxIoUAssigner'),\n",
            "                debug=False,\n",
            "                mask_size=28,\n",
            "                pos_weight=-1,\n",
            "                sampler=dict(\n",
            "                    add_gt_as_proposals=True,\n",
            "                    neg_pos_ub=-1,\n",
            "                    num=512,\n",
            "                    pos_fraction=0.25,\n",
            "                    type='RandomSampler')),\n",
            "        ],\n",
            "        rpn=dict(\n",
            "            allowed_border=0,\n",
            "            assigner=dict(\n",
            "                ignore_iof_thr=-1,\n",
            "                min_pos_iou=0.3,\n",
            "                neg_iou_thr=0.3,\n",
            "                pos_iou_thr=0.7,\n",
            "                type='MaxIoUAssigner'),\n",
            "            debug=False,\n",
            "            pos_weight=-1,\n",
            "            sampler=dict(\n",
            "                add_gt_as_proposals=False,\n",
            "                neg_pos_ub=-1,\n",
            "                num=256,\n",
            "                pos_fraction=0.5,\n",
            "                type='RandomSampler')),\n",
            "        rpn_proposal=dict(\n",
            "            max_per_img=2000,\n",
            "            min_bbox_size=0,\n",
            "            nms=dict(iou_threshold=0.7, type='nms'),\n",
            "            nms_pre=2000)),\n",
            "    type='HybridTaskCascade')\n",
            "optim_wrapper = dict(\n",
            "    optimizer=dict(lr=0.005, momentum=0.9, type='SGD', weight_decay=0.0001),\n",
            "    type='OptimWrapper')\n",
            "param_scheduler = [\n",
            "    dict(\n",
            "        begin=0, by_epoch=False, end=500, start_factor=0.001, type='LinearLR'),\n",
            "    dict(\n",
            "        begin=0,\n",
            "        by_epoch=True,\n",
            "        end=12,\n",
            "        gamma=0.1,\n",
            "        milestones=[\n",
            "            21,\n",
            "            22,\n",
            "        ],\n",
            "        type='MultiStepLR'),\n",
            "]\n",
            "resume = False\n",
            "test_cfg = dict(type='TestLoop')\n",
            "test_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='ann/val.json',\n",
            "        backend_args=None,\n",
            "        data_prefix=dict(img='valid/'),\n",
            "        data_root='data/diagnosis',\n",
            "        metainfo=dict(\n",
            "            classes=(\n",
            "                'Bdr',\n",
            "                'Bone Loss',\n",
            "                'Bridge',\n",
            "                'Caries',\n",
            "                'Crown',\n",
            "                'Filling',\n",
            "                'Impaction',\n",
            "                'Implant',\n",
            "                'Periapical Abscess',\n",
            "                'Rct',\n",
            "                'Rct +Post',\n",
            "                'Retentive Pin',\n",
            "                'Shadow',\n",
            "                'Splinted Crowns',\n",
            "                'Unerupted',\n",
            "            )),\n",
            "        pipeline=[\n",
            "            dict(backend_args=None, type='LoadImageFromFile'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                1333,\n",
            "                800,\n",
            "            ), type='Resize'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'img_id',\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'scale_factor',\n",
            "                ),\n",
            "                type='PackDetInputs'),\n",
            "        ],\n",
            "        test_mode=True,\n",
            "        type='DiagnosisDataset'),\n",
            "    drop_last=False,\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "test_evaluator = dict(\n",
            "    ann_file='/content/drive/MyDrive/data/diagnosis/ann/val.json',\n",
            "    backend_args=None,\n",
            "    format_only=False,\n",
            "    metric=[\n",
            "        'bbox',\n",
            "        'segm',\n",
            "    ],\n",
            "    type='CocoMetric')\n",
            "test_pipeline = [\n",
            "    dict(backend_args=None, type='LoadImageFromFile'),\n",
            "    dict(keep_ratio=True, scale=(\n",
            "        1333,\n",
            "        800,\n",
            "    ), type='Resize'),\n",
            "    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
            "    dict(\n",
            "        meta_keys=(\n",
            "            'img_id',\n",
            "            'img_path',\n",
            "            'ori_shape',\n",
            "            'img_shape',\n",
            "            'scale_factor',\n",
            "        ),\n",
            "        type='PackDetInputs'),\n",
            "]\n",
            "train_cfg = dict(max_epochs=10, type='EpochBasedTrainLoop', val_interval=1)\n",
            "train_dataloader = dict(\n",
            "    batch_sampler=dict(type='AspectRatioBatchSampler'),\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='ann/train.json',\n",
            "        backend_args=None,\n",
            "        data_prefix=dict(img='train/'),\n",
            "        data_root='/content/drive/MyDrive/data/diagnosis',\n",
            "        filter_cfg=dict(filter_empty_gt=False, min_size=16),\n",
            "        metainfo=dict(\n",
            "            classes=(\n",
            "                'Bdr',\n",
            "                'Bone Loss',\n",
            "                'Bridge',\n",
            "                'Caries',\n",
            "                'Crown',\n",
            "                'Filling',\n",
            "                'Impaction',\n",
            "                'Implant',\n",
            "                'Periapical Abscess',\n",
            "                'Rct',\n",
            "                'Rct +Post',\n",
            "                'Retentive Pin',\n",
            "                'Shadow',\n",
            "                'Splinted Crowns',\n",
            "                'Unerupted',\n",
            "            )),\n",
            "        pipeline=[\n",
            "            dict(backend_args=None, type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                1333,\n",
            "                800,\n",
            "            ), type='Resize'),\n",
            "            dict(prob=0.0, type='RandomFlip'),\n",
            "            dict(type='PackDetInputs'),\n",
            "        ],\n",
            "        type='DiagnosisDataset'),\n",
            "    num_workers=8,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
            "train_pipeline = [\n",
            "    dict(backend_args=None, type='LoadImageFromFile'),\n",
            "    dict(\n",
            "        type='LoadAnnotations', with_bbox=True, with_mask=True, with_seg=True),\n",
            "    dict(keep_ratio=True, scale=(\n",
            "        1333,\n",
            "        800,\n",
            "    ), type='Resize'),\n",
            "    dict(prob=0.5, type='RandomFlip'),\n",
            "    dict(type='PackDetInputs'),\n",
            "]\n",
            "val_cfg = dict(type='ValLoop')\n",
            "val_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='ann/val.json',\n",
            "        backend_args=None,\n",
            "        data_prefix=dict(img='valid/'),\n",
            "        data_root='data/diagnosis',\n",
            "        metainfo=dict(\n",
            "            classes=(\n",
            "                'Bdr',\n",
            "                'Bone Loss',\n",
            "                'Bridge',\n",
            "                'Caries',\n",
            "                'Crown',\n",
            "                'Filling',\n",
            "                'Impaction',\n",
            "                'Implant',\n",
            "                'Periapical Abscess',\n",
            "                'Rct',\n",
            "                'Rct +Post',\n",
            "                'Retentive Pin',\n",
            "                'Shadow',\n",
            "                'Splinted Crowns',\n",
            "                'Unerupted',\n",
            "            )),\n",
            "        pipeline=[\n",
            "            dict(backend_args=None, type='LoadImageFromFile'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                1333,\n",
            "                800,\n",
            "            ), type='Resize'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'img_id',\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'scale_factor',\n",
            "                ),\n",
            "                type='PackDetInputs'),\n",
            "        ],\n",
            "        test_mode=True,\n",
            "        type='DiagnosisDataset'),\n",
            "    drop_last=False,\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "val_evaluator = dict(\n",
            "    ann_file='/content/drive/MyDrive/data/diagnosis/ann/val.json',\n",
            "    backend_args=None,\n",
            "    format_only=False,\n",
            "    metric=[\n",
            "        'bbox',\n",
            "        'segm',\n",
            "    ],\n",
            "    type='CocoMetric')\n",
            "vis_backends = [\n",
            "    dict(type='LocalVisBackend'),\n",
            "]\n",
            "visualizer = dict(\n",
            "    name='visualizer',\n",
            "    type='DetLocalVisualizer',\n",
            "    vis_backends=[\n",
            "        dict(type='LocalVisBackend'),\n",
            "    ])\n",
            "work_dir = 'C:\\\\Users\\\\HP\\\\mmdetection\\\\demo\\\\work_dir'\n",
            "\n",
            "09/20 14:39:23 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
            "09/20 14:39:23 - mmengine - INFO - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "before_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DistSamplerSeedHook                \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DetVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_test_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DetVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_run:\n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "loading annotations into memory...\n",
            "Done (t=1.12s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.37s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "09/20 14:39:27 - mmengine - INFO - Loads checkpoint by torchvision backend from path: torchvision://resnet101\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet101-63fe2227.pth\" to /root/.cache/torch/hub/checkpoints/resnet101-63fe2227.pth\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "09/20 14:39:29 - mmengine - WARNING - The model and loaded state dict do not match exactly\n",
            "\n",
            "unexpected key in source state_dict: fc.weight, fc.bias\n",
            "\n",
            "missing keys in source state_dict: layer2.0.conv2.weight_diff, layer2.0.conv2.switch.weight, layer2.0.conv2.switch.bias, layer2.0.conv2.pre_context.weight, layer2.0.conv2.pre_context.bias, layer2.0.conv2.post_context.weight, layer2.0.conv2.post_context.bias, layer2.0.conv2.offset_s.weight, layer2.0.conv2.offset_s.bias, layer2.0.conv2.offset_l.weight, layer2.0.conv2.offset_l.bias, layer2.1.conv2.weight_diff, layer2.1.conv2.switch.weight, layer2.1.conv2.switch.bias, layer2.1.conv2.pre_context.weight, layer2.1.conv2.pre_context.bias, layer2.1.conv2.post_context.weight, layer2.1.conv2.post_context.bias, layer2.1.conv2.offset_s.weight, layer2.1.conv2.offset_s.bias, layer2.1.conv2.offset_l.weight, layer2.1.conv2.offset_l.bias, layer2.2.conv2.weight_diff, layer2.2.conv2.switch.weight, layer2.2.conv2.switch.bias, layer2.2.conv2.pre_context.weight, layer2.2.conv2.pre_context.bias, layer2.2.conv2.post_context.weight, layer2.2.conv2.post_context.bias, layer2.2.conv2.offset_s.weight, layer2.2.conv2.offset_s.bias, layer2.2.conv2.offset_l.weight, layer2.2.conv2.offset_l.bias, layer2.3.conv2.weight_diff, layer2.3.conv2.switch.weight, layer2.3.conv2.switch.bias, layer2.3.conv2.pre_context.weight, layer2.3.conv2.pre_context.bias, layer2.3.conv2.post_context.weight, layer2.3.conv2.post_context.bias, layer2.3.conv2.offset_s.weight, layer2.3.conv2.offset_s.bias, layer2.3.conv2.offset_l.weight, layer2.3.conv2.offset_l.bias, layer3.0.conv2.weight_diff, layer3.0.conv2.switch.weight, layer3.0.conv2.switch.bias, layer3.0.conv2.pre_context.weight, layer3.0.conv2.pre_context.bias, layer3.0.conv2.post_context.weight, layer3.0.conv2.post_context.bias, layer3.0.conv2.offset_s.weight, layer3.0.conv2.offset_s.bias, layer3.0.conv2.offset_l.weight, layer3.0.conv2.offset_l.bias, layer3.1.conv2.weight_diff, layer3.1.conv2.switch.weight, layer3.1.conv2.switch.bias, layer3.1.conv2.pre_context.weight, layer3.1.conv2.pre_context.bias, layer3.1.conv2.post_context.weight, layer3.1.conv2.post_context.bias, layer3.1.conv2.offset_s.weight, layer3.1.conv2.offset_s.bias, layer3.1.conv2.offset_l.weight, layer3.1.conv2.offset_l.bias, layer3.2.conv2.weight_diff, layer3.2.conv2.switch.weight, layer3.2.conv2.switch.bias, layer3.2.conv2.pre_context.weight, layer3.2.conv2.pre_context.bias, layer3.2.conv2.post_context.weight, layer3.2.conv2.post_context.bias, layer3.2.conv2.offset_s.weight, layer3.2.conv2.offset_s.bias, layer3.2.conv2.offset_l.weight, layer3.2.conv2.offset_l.bias, layer3.3.conv2.weight_diff, layer3.3.conv2.switch.weight, layer3.3.conv2.switch.bias, layer3.3.conv2.pre_context.weight, layer3.3.conv2.pre_context.bias, layer3.3.conv2.post_context.weight, layer3.3.conv2.post_context.bias, layer3.3.conv2.offset_s.weight, layer3.3.conv2.offset_s.bias, layer3.3.conv2.offset_l.weight, layer3.3.conv2.offset_l.bias, layer3.4.conv2.weight_diff, layer3.4.conv2.switch.weight, layer3.4.conv2.switch.bias, layer3.4.conv2.pre_context.weight, layer3.4.conv2.pre_context.bias, layer3.4.conv2.post_context.weight, layer3.4.conv2.post_context.bias, layer3.4.conv2.offset_s.weight, layer3.4.conv2.offset_s.bias, layer3.4.conv2.offset_l.weight, layer3.4.conv2.offset_l.bias, layer3.5.conv2.weight_diff, layer3.5.conv2.switch.weight, layer3.5.conv2.switch.bias, layer3.5.conv2.pre_context.weight, layer3.5.conv2.pre_context.bias, layer3.5.conv2.post_context.weight, layer3.5.conv2.post_context.bias, layer3.5.conv2.offset_s.weight, layer3.5.conv2.offset_s.bias, layer3.5.conv2.offset_l.weight, layer3.5.conv2.offset_l.bias, layer3.6.conv2.weight_diff, layer3.6.conv2.switch.weight, layer3.6.conv2.switch.bias, layer3.6.conv2.pre_context.weight, layer3.6.conv2.pre_context.bias, layer3.6.conv2.post_context.weight, layer3.6.conv2.post_context.bias, layer3.6.conv2.offset_s.weight, layer3.6.conv2.offset_s.bias, layer3.6.conv2.offset_l.weight, layer3.6.conv2.offset_l.bias, layer3.7.conv2.weight_diff, layer3.7.conv2.switch.weight, layer3.7.conv2.switch.bias, layer3.7.conv2.pre_context.weight, layer3.7.conv2.pre_context.bias, layer3.7.conv2.post_context.weight, layer3.7.conv2.post_context.bias, layer3.7.conv2.offset_s.weight, layer3.7.conv2.offset_s.bias, layer3.7.conv2.offset_l.weight, layer3.7.conv2.offset_l.bias, layer3.8.conv2.weight_diff, layer3.8.conv2.switch.weight, layer3.8.conv2.switch.bias, layer3.8.conv2.pre_context.weight, layer3.8.conv2.pre_context.bias, layer3.8.conv2.post_context.weight, layer3.8.conv2.post_context.bias, layer3.8.conv2.offset_s.weight, layer3.8.conv2.offset_s.bias, layer3.8.conv2.offset_l.weight, layer3.8.conv2.offset_l.bias, layer3.9.conv2.weight_diff, layer3.9.conv2.switch.weight, layer3.9.conv2.switch.bias, layer3.9.conv2.pre_context.weight, layer3.9.conv2.pre_context.bias, layer3.9.conv2.post_context.weight, layer3.9.conv2.post_context.bias, layer3.9.conv2.offset_s.weight, layer3.9.conv2.offset_s.bias, layer3.9.conv2.offset_l.weight, layer3.9.conv2.offset_l.bias, layer3.10.conv2.weight_diff, layer3.10.conv2.switch.weight, layer3.10.conv2.switch.bias, layer3.10.conv2.pre_context.weight, layer3.10.conv2.pre_context.bias, layer3.10.conv2.post_context.weight, layer3.10.conv2.post_context.bias, layer3.10.conv2.offset_s.weight, layer3.10.conv2.offset_s.bias, layer3.10.conv2.offset_l.weight, layer3.10.conv2.offset_l.bias, layer3.11.conv2.weight_diff, layer3.11.conv2.switch.weight, layer3.11.conv2.switch.bias, layer3.11.conv2.pre_context.weight, layer3.11.conv2.pre_context.bias, layer3.11.conv2.post_context.weight, layer3.11.conv2.post_context.bias, layer3.11.conv2.offset_s.weight, layer3.11.conv2.offset_s.bias, layer3.11.conv2.offset_l.weight, layer3.11.conv2.offset_l.bias, layer3.12.conv2.weight_diff, layer3.12.conv2.switch.weight, layer3.12.conv2.switch.bias, layer3.12.conv2.pre_context.weight, layer3.12.conv2.pre_context.bias, layer3.12.conv2.post_context.weight, layer3.12.conv2.post_context.bias, layer3.12.conv2.offset_s.weight, layer3.12.conv2.offset_s.bias, layer3.12.conv2.offset_l.weight, layer3.12.conv2.offset_l.bias, layer3.13.conv2.weight_diff, layer3.13.conv2.switch.weight, layer3.13.conv2.switch.bias, layer3.13.conv2.pre_context.weight, layer3.13.conv2.pre_context.bias, layer3.13.conv2.post_context.weight, layer3.13.conv2.post_context.bias, layer3.13.conv2.offset_s.weight, layer3.13.conv2.offset_s.bias, layer3.13.conv2.offset_l.weight, layer3.13.conv2.offset_l.bias, layer3.14.conv2.weight_diff, layer3.14.conv2.switch.weight, layer3.14.conv2.switch.bias, layer3.14.conv2.pre_context.weight, layer3.14.conv2.pre_context.bias, layer3.14.conv2.post_context.weight, layer3.14.conv2.post_context.bias, layer3.14.conv2.offset_s.weight, layer3.14.conv2.offset_s.bias, layer3.14.conv2.offset_l.weight, layer3.14.conv2.offset_l.bias, layer3.15.conv2.weight_diff, layer3.15.conv2.switch.weight, layer3.15.conv2.switch.bias, layer3.15.conv2.pre_context.weight, layer3.15.conv2.pre_context.bias, layer3.15.conv2.post_context.weight, layer3.15.conv2.post_context.bias, layer3.15.conv2.offset_s.weight, layer3.15.conv2.offset_s.bias, layer3.15.conv2.offset_l.weight, layer3.15.conv2.offset_l.bias, layer3.16.conv2.weight_diff, layer3.16.conv2.switch.weight, layer3.16.conv2.switch.bias, layer3.16.conv2.pre_context.weight, layer3.16.conv2.pre_context.bias, layer3.16.conv2.post_context.weight, layer3.16.conv2.post_context.bias, layer3.16.conv2.offset_s.weight, layer3.16.conv2.offset_s.bias, layer3.16.conv2.offset_l.weight, layer3.16.conv2.offset_l.bias, layer3.17.conv2.weight_diff, layer3.17.conv2.switch.weight, layer3.17.conv2.switch.bias, layer3.17.conv2.pre_context.weight, layer3.17.conv2.pre_context.bias, layer3.17.conv2.post_context.weight, layer3.17.conv2.post_context.bias, layer3.17.conv2.offset_s.weight, layer3.17.conv2.offset_s.bias, layer3.17.conv2.offset_l.weight, layer3.17.conv2.offset_l.bias, layer3.18.conv2.weight_diff, layer3.18.conv2.switch.weight, layer3.18.conv2.switch.bias, layer3.18.conv2.pre_context.weight, layer3.18.conv2.pre_context.bias, layer3.18.conv2.post_context.weight, layer3.18.conv2.post_context.bias, layer3.18.conv2.offset_s.weight, layer3.18.conv2.offset_s.bias, layer3.18.conv2.offset_l.weight, layer3.18.conv2.offset_l.bias, layer3.19.conv2.weight_diff, layer3.19.conv2.switch.weight, layer3.19.conv2.switch.bias, layer3.19.conv2.pre_context.weight, layer3.19.conv2.pre_context.bias, layer3.19.conv2.post_context.weight, layer3.19.conv2.post_context.bias, layer3.19.conv2.offset_s.weight, layer3.19.conv2.offset_s.bias, layer3.19.conv2.offset_l.weight, layer3.19.conv2.offset_l.bias, layer3.20.conv2.weight_diff, layer3.20.conv2.switch.weight, layer3.20.conv2.switch.bias, layer3.20.conv2.pre_context.weight, layer3.20.conv2.pre_context.bias, layer3.20.conv2.post_context.weight, layer3.20.conv2.post_context.bias, layer3.20.conv2.offset_s.weight, layer3.20.conv2.offset_s.bias, layer3.20.conv2.offset_l.weight, layer3.20.conv2.offset_l.bias, layer3.21.conv2.weight_diff, layer3.21.conv2.switch.weight, layer3.21.conv2.switch.bias, layer3.21.conv2.pre_context.weight, layer3.21.conv2.pre_context.bias, layer3.21.conv2.post_context.weight, layer3.21.conv2.post_context.bias, layer3.21.conv2.offset_s.weight, layer3.21.conv2.offset_s.bias, layer3.21.conv2.offset_l.weight, layer3.21.conv2.offset_l.bias, layer3.22.conv2.weight_diff, layer3.22.conv2.switch.weight, layer3.22.conv2.switch.bias, layer3.22.conv2.pre_context.weight, layer3.22.conv2.pre_context.bias, layer3.22.conv2.post_context.weight, layer3.22.conv2.post_context.bias, layer3.22.conv2.offset_s.weight, layer3.22.conv2.offset_s.bias, layer3.22.conv2.offset_l.weight, layer3.22.conv2.offset_l.bias, layer4.0.conv2.weight_diff, layer4.0.conv2.switch.weight, layer4.0.conv2.switch.bias, layer4.0.conv2.pre_context.weight, layer4.0.conv2.pre_context.bias, layer4.0.conv2.post_context.weight, layer4.0.conv2.post_context.bias, layer4.0.conv2.offset_s.weight, layer4.0.conv2.offset_s.bias, layer4.0.conv2.offset_l.weight, layer4.0.conv2.offset_l.bias, layer4.1.conv2.weight_diff, layer4.1.conv2.switch.weight, layer4.1.conv2.switch.bias, layer4.1.conv2.pre_context.weight, layer4.1.conv2.pre_context.bias, layer4.1.conv2.post_context.weight, layer4.1.conv2.post_context.bias, layer4.1.conv2.offset_s.weight, layer4.1.conv2.offset_s.bias, layer4.1.conv2.offset_l.weight, layer4.1.conv2.offset_l.bias, layer4.2.conv2.weight_diff, layer4.2.conv2.switch.weight, layer4.2.conv2.switch.bias, layer4.2.conv2.pre_context.weight, layer4.2.conv2.pre_context.bias, layer4.2.conv2.post_context.weight, layer4.2.conv2.post_context.bias, layer4.2.conv2.offset_s.weight, layer4.2.conv2.offset_s.bias, layer4.2.conv2.offset_l.weight, layer4.2.conv2.offset_l.bias\n",
            "\n",
            "09/20 14:39:29 - mmengine - INFO - Loads checkpoint by torchvision backend from path: torchvision://resnet101\n",
            "09/20 14:39:29 - mmengine - WARNING - The model and loaded state dict do not match exactly\n",
            "\n",
            "unexpected key in source state_dict: fc.weight, fc.bias\n",
            "\n",
            "missing keys in source state_dict: layer2.0.conv2.weight_diff, layer2.0.conv2.switch.weight, layer2.0.conv2.switch.bias, layer2.0.conv2.pre_context.weight, layer2.0.conv2.pre_context.bias, layer2.0.conv2.post_context.weight, layer2.0.conv2.post_context.bias, layer2.0.conv2.offset_s.weight, layer2.0.conv2.offset_s.bias, layer2.0.conv2.offset_l.weight, layer2.0.conv2.offset_l.bias, layer2.0.rfp_conv.weight, layer2.0.rfp_conv.bias, layer2.1.conv2.weight_diff, layer2.1.conv2.switch.weight, layer2.1.conv2.switch.bias, layer2.1.conv2.pre_context.weight, layer2.1.conv2.pre_context.bias, layer2.1.conv2.post_context.weight, layer2.1.conv2.post_context.bias, layer2.1.conv2.offset_s.weight, layer2.1.conv2.offset_s.bias, layer2.1.conv2.offset_l.weight, layer2.1.conv2.offset_l.bias, layer2.2.conv2.weight_diff, layer2.2.conv2.switch.weight, layer2.2.conv2.switch.bias, layer2.2.conv2.pre_context.weight, layer2.2.conv2.pre_context.bias, layer2.2.conv2.post_context.weight, layer2.2.conv2.post_context.bias, layer2.2.conv2.offset_s.weight, layer2.2.conv2.offset_s.bias, layer2.2.conv2.offset_l.weight, layer2.2.conv2.offset_l.bias, layer2.3.conv2.weight_diff, layer2.3.conv2.switch.weight, layer2.3.conv2.switch.bias, layer2.3.conv2.pre_context.weight, layer2.3.conv2.pre_context.bias, layer2.3.conv2.post_context.weight, layer2.3.conv2.post_context.bias, layer2.3.conv2.offset_s.weight, layer2.3.conv2.offset_s.bias, layer2.3.conv2.offset_l.weight, layer2.3.conv2.offset_l.bias, layer3.0.conv2.weight_diff, layer3.0.conv2.switch.weight, layer3.0.conv2.switch.bias, layer3.0.conv2.pre_context.weight, layer3.0.conv2.pre_context.bias, layer3.0.conv2.post_context.weight, layer3.0.conv2.post_context.bias, layer3.0.conv2.offset_s.weight, layer3.0.conv2.offset_s.bias, layer3.0.conv2.offset_l.weight, layer3.0.conv2.offset_l.bias, layer3.0.rfp_conv.weight, layer3.0.rfp_conv.bias, layer3.1.conv2.weight_diff, layer3.1.conv2.switch.weight, layer3.1.conv2.switch.bias, layer3.1.conv2.pre_context.weight, layer3.1.conv2.pre_context.bias, layer3.1.conv2.post_context.weight, layer3.1.conv2.post_context.bias, layer3.1.conv2.offset_s.weight, layer3.1.conv2.offset_s.bias, layer3.1.conv2.offset_l.weight, layer3.1.conv2.offset_l.bias, layer3.2.conv2.weight_diff, layer3.2.conv2.switch.weight, layer3.2.conv2.switch.bias, layer3.2.conv2.pre_context.weight, layer3.2.conv2.pre_context.bias, layer3.2.conv2.post_context.weight, layer3.2.conv2.post_context.bias, layer3.2.conv2.offset_s.weight, layer3.2.conv2.offset_s.bias, layer3.2.conv2.offset_l.weight, layer3.2.conv2.offset_l.bias, layer3.3.conv2.weight_diff, layer3.3.conv2.switch.weight, layer3.3.conv2.switch.bias, layer3.3.conv2.pre_context.weight, layer3.3.conv2.pre_context.bias, layer3.3.conv2.post_context.weight, layer3.3.conv2.post_context.bias, layer3.3.conv2.offset_s.weight, layer3.3.conv2.offset_s.bias, layer3.3.conv2.offset_l.weight, layer3.3.conv2.offset_l.bias, layer3.4.conv2.weight_diff, layer3.4.conv2.switch.weight, layer3.4.conv2.switch.bias, layer3.4.conv2.pre_context.weight, layer3.4.conv2.pre_context.bias, layer3.4.conv2.post_context.weight, layer3.4.conv2.post_context.bias, layer3.4.conv2.offset_s.weight, layer3.4.conv2.offset_s.bias, layer3.4.conv2.offset_l.weight, layer3.4.conv2.offset_l.bias, layer3.5.conv2.weight_diff, layer3.5.conv2.switch.weight, layer3.5.conv2.switch.bias, layer3.5.conv2.pre_context.weight, layer3.5.conv2.pre_context.bias, layer3.5.conv2.post_context.weight, layer3.5.conv2.post_context.bias, layer3.5.conv2.offset_s.weight, layer3.5.conv2.offset_s.bias, layer3.5.conv2.offset_l.weight, layer3.5.conv2.offset_l.bias, layer3.6.conv2.weight_diff, layer3.6.conv2.switch.weight, layer3.6.conv2.switch.bias, layer3.6.conv2.pre_context.weight, layer3.6.conv2.pre_context.bias, layer3.6.conv2.post_context.weight, layer3.6.conv2.post_context.bias, layer3.6.conv2.offset_s.weight, layer3.6.conv2.offset_s.bias, layer3.6.conv2.offset_l.weight, layer3.6.conv2.offset_l.bias, layer3.7.conv2.weight_diff, layer3.7.conv2.switch.weight, layer3.7.conv2.switch.bias, layer3.7.conv2.pre_context.weight, layer3.7.conv2.pre_context.bias, layer3.7.conv2.post_context.weight, layer3.7.conv2.post_context.bias, layer3.7.conv2.offset_s.weight, layer3.7.conv2.offset_s.bias, layer3.7.conv2.offset_l.weight, layer3.7.conv2.offset_l.bias, layer3.8.conv2.weight_diff, layer3.8.conv2.switch.weight, layer3.8.conv2.switch.bias, layer3.8.conv2.pre_context.weight, layer3.8.conv2.pre_context.bias, layer3.8.conv2.post_context.weight, layer3.8.conv2.post_context.bias, layer3.8.conv2.offset_s.weight, layer3.8.conv2.offset_s.bias, layer3.8.conv2.offset_l.weight, layer3.8.conv2.offset_l.bias, layer3.9.conv2.weight_diff, layer3.9.conv2.switch.weight, layer3.9.conv2.switch.bias, layer3.9.conv2.pre_context.weight, layer3.9.conv2.pre_context.bias, layer3.9.conv2.post_context.weight, layer3.9.conv2.post_context.bias, layer3.9.conv2.offset_s.weight, layer3.9.conv2.offset_s.bias, layer3.9.conv2.offset_l.weight, layer3.9.conv2.offset_l.bias, layer3.10.conv2.weight_diff, layer3.10.conv2.switch.weight, layer3.10.conv2.switch.bias, layer3.10.conv2.pre_context.weight, layer3.10.conv2.pre_context.bias, layer3.10.conv2.post_context.weight, layer3.10.conv2.post_context.bias, layer3.10.conv2.offset_s.weight, layer3.10.conv2.offset_s.bias, layer3.10.conv2.offset_l.weight, layer3.10.conv2.offset_l.bias, layer3.11.conv2.weight_diff, layer3.11.conv2.switch.weight, layer3.11.conv2.switch.bias, layer3.11.conv2.pre_context.weight, layer3.11.conv2.pre_context.bias, layer3.11.conv2.post_context.weight, layer3.11.conv2.post_context.bias, layer3.11.conv2.offset_s.weight, layer3.11.conv2.offset_s.bias, layer3.11.conv2.offset_l.weight, layer3.11.conv2.offset_l.bias, layer3.12.conv2.weight_diff, layer3.12.conv2.switch.weight, layer3.12.conv2.switch.bias, layer3.12.conv2.pre_context.weight, layer3.12.conv2.pre_context.bias, layer3.12.conv2.post_context.weight, layer3.12.conv2.post_context.bias, layer3.12.conv2.offset_s.weight, layer3.12.conv2.offset_s.bias, layer3.12.conv2.offset_l.weight, layer3.12.conv2.offset_l.bias, layer3.13.conv2.weight_diff, layer3.13.conv2.switch.weight, layer3.13.conv2.switch.bias, layer3.13.conv2.pre_context.weight, layer3.13.conv2.pre_context.bias, layer3.13.conv2.post_context.weight, layer3.13.conv2.post_context.bias, layer3.13.conv2.offset_s.weight, layer3.13.conv2.offset_s.bias, layer3.13.conv2.offset_l.weight, layer3.13.conv2.offset_l.bias, layer3.14.conv2.weight_diff, layer3.14.conv2.switch.weight, layer3.14.conv2.switch.bias, layer3.14.conv2.pre_context.weight, layer3.14.conv2.pre_context.bias, layer3.14.conv2.post_context.weight, layer3.14.conv2.post_context.bias, layer3.14.conv2.offset_s.weight, layer3.14.conv2.offset_s.bias, layer3.14.conv2.offset_l.weight, layer3.14.conv2.offset_l.bias, layer3.15.conv2.weight_diff, layer3.15.conv2.switch.weight, layer3.15.conv2.switch.bias, layer3.15.conv2.pre_context.weight, layer3.15.conv2.pre_context.bias, layer3.15.conv2.post_context.weight, layer3.15.conv2.post_context.bias, layer3.15.conv2.offset_s.weight, layer3.15.conv2.offset_s.bias, layer3.15.conv2.offset_l.weight, layer3.15.conv2.offset_l.bias, layer3.16.conv2.weight_diff, layer3.16.conv2.switch.weight, layer3.16.conv2.switch.bias, layer3.16.conv2.pre_context.weight, layer3.16.conv2.pre_context.bias, layer3.16.conv2.post_context.weight, layer3.16.conv2.post_context.bias, layer3.16.conv2.offset_s.weight, layer3.16.conv2.offset_s.bias, layer3.16.conv2.offset_l.weight, layer3.16.conv2.offset_l.bias, layer3.17.conv2.weight_diff, layer3.17.conv2.switch.weight, layer3.17.conv2.switch.bias, layer3.17.conv2.pre_context.weight, layer3.17.conv2.pre_context.bias, layer3.17.conv2.post_context.weight, layer3.17.conv2.post_context.bias, layer3.17.conv2.offset_s.weight, layer3.17.conv2.offset_s.bias, layer3.17.conv2.offset_l.weight, layer3.17.conv2.offset_l.bias, layer3.18.conv2.weight_diff, layer3.18.conv2.switch.weight, layer3.18.conv2.switch.bias, layer3.18.conv2.pre_context.weight, layer3.18.conv2.pre_context.bias, layer3.18.conv2.post_context.weight, layer3.18.conv2.post_context.bias, layer3.18.conv2.offset_s.weight, layer3.18.conv2.offset_s.bias, layer3.18.conv2.offset_l.weight, layer3.18.conv2.offset_l.bias, layer3.19.conv2.weight_diff, layer3.19.conv2.switch.weight, layer3.19.conv2.switch.bias, layer3.19.conv2.pre_context.weight, layer3.19.conv2.pre_context.bias, layer3.19.conv2.post_context.weight, layer3.19.conv2.post_context.bias, layer3.19.conv2.offset_s.weight, layer3.19.conv2.offset_s.bias, layer3.19.conv2.offset_l.weight, layer3.19.conv2.offset_l.bias, layer3.20.conv2.weight_diff, layer3.20.conv2.switch.weight, layer3.20.conv2.switch.bias, layer3.20.conv2.pre_context.weight, layer3.20.conv2.pre_context.bias, layer3.20.conv2.post_context.weight, layer3.20.conv2.post_context.bias, layer3.20.conv2.offset_s.weight, layer3.20.conv2.offset_s.bias, layer3.20.conv2.offset_l.weight, layer3.20.conv2.offset_l.bias, layer3.21.conv2.weight_diff, layer3.21.conv2.switch.weight, layer3.21.conv2.switch.bias, layer3.21.conv2.pre_context.weight, layer3.21.conv2.pre_context.bias, layer3.21.conv2.post_context.weight, layer3.21.conv2.post_context.bias, layer3.21.conv2.offset_s.weight, layer3.21.conv2.offset_s.bias, layer3.21.conv2.offset_l.weight, layer3.21.conv2.offset_l.bias, layer3.22.conv2.weight_diff, layer3.22.conv2.switch.weight, layer3.22.conv2.switch.bias, layer3.22.conv2.pre_context.weight, layer3.22.conv2.pre_context.bias, layer3.22.conv2.post_context.weight, layer3.22.conv2.post_context.bias, layer3.22.conv2.offset_s.weight, layer3.22.conv2.offset_s.bias, layer3.22.conv2.offset_l.weight, layer3.22.conv2.offset_l.bias, layer4.0.conv2.weight_diff, layer4.0.conv2.switch.weight, layer4.0.conv2.switch.bias, layer4.0.conv2.pre_context.weight, layer4.0.conv2.pre_context.bias, layer4.0.conv2.post_context.weight, layer4.0.conv2.post_context.bias, layer4.0.conv2.offset_s.weight, layer4.0.conv2.offset_s.bias, layer4.0.conv2.offset_l.weight, layer4.0.conv2.offset_l.bias, layer4.0.rfp_conv.weight, layer4.0.rfp_conv.bias, layer4.1.conv2.weight_diff, layer4.1.conv2.switch.weight, layer4.1.conv2.switch.bias, layer4.1.conv2.pre_context.weight, layer4.1.conv2.pre_context.bias, layer4.1.conv2.post_context.weight, layer4.1.conv2.post_context.bias, layer4.1.conv2.offset_s.weight, layer4.1.conv2.offset_s.bias, layer4.1.conv2.offset_l.weight, layer4.1.conv2.offset_l.bias, layer4.2.conv2.weight_diff, layer4.2.conv2.switch.weight, layer4.2.conv2.switch.bias, layer4.2.conv2.pre_context.weight, layer4.2.conv2.pre_context.bias, layer4.2.conv2.post_context.weight, layer4.2.conv2.post_context.bias, layer4.2.conv2.offset_s.weight, layer4.2.conv2.offset_s.bias, layer4.2.conv2.offset_l.weight, layer4.2.conv2.offset_l.bias\n",
            "\n",
            "Loads checkpoint by local backend from path: /content/drive/MyDrive/models/epoch_5.pth\n",
            "09/20 14:39:48 - mmengine - INFO - Load checkpoint from /content/drive/MyDrive/models/epoch_5.pth\n",
            "09/20 14:39:48 - mmengine - WARNING - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
            "09/20 14:39:48 - mmengine - WARNING - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
            "09/20 14:39:48 - mmengine - INFO - Checkpoints will be saved to /content/drive/MyDrive/C:\\Users\\HP\\mmdetection\\demo\\work_dir.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "09/20 14:59:52 - mmengine - INFO - Exp name: customconfig (2)_20230920_143907\n",
            "09/20 15:15:18 - mmengine - INFO - Exp name: customconfig (2)_20230920_143907\n",
            "09/20 15:15:18 - mmengine - INFO - Epoch(train)  [1][1774/1774]  lr: 5.0000e-03  eta: 5:19:30  time: 1.2007  data_time: 0.0203  memory: 5356  loss: 0.9665  loss_rpn_cls: 0.0195  loss_rpn_bbox: 0.0296  s0.loss_cls: 0.1265  s0.acc: 100.0000  s0.loss_bbox: 0.0866  s0.loss_mask: 0.2407  s1.loss_cls: 0.0587  s1.acc: 100.0000  s1.loss_bbox: 0.1157  s1.loss_mask: 0.1191  s2.loss_cls: 0.0311  s2.acc: 100.0000  s2.loss_bbox: 0.0816  s2.loss_mask: 0.0574\n",
            "09/20 15:15:18 - mmengine - INFO - Saving checkpoint at 1 epochs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/mmdetection/mmdet/models/roi_heads/mask_heads/fcn_mask_head.py:339: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
            "  mask_preds = bboxes.new_tensor(mask_preds)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "09/20 15:20:33 - mmengine - INFO - Evaluating bbox...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.04s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.94s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.96s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.347\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.599\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.346\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.156\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.344\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.372\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.547\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.547\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.547\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.235\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.545\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.558\n",
            "09/20 15:20:36 - mmengine - INFO - bbox_mAP_copypaste: 0.347 0.599 0.346 0.156 0.344 0.372\n",
            "09/20 15:20:36 - mmengine - INFO - Evaluating segm...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.40s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=2.79s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.91s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.332\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.594\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.349\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.084\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.337\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.359\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.500\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.500\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.500\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.188\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.499\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.489\n",
            "09/20 15:20:41 - mmengine - INFO - segm_mAP_copypaste: 0.332 0.594 0.349 0.084 0.337 0.359\n",
            "09/20 15:20:41 - mmengine - INFO - Epoch(val) [1][336/336]    coco/bbox_mAP: 0.3470  coco/bbox_mAP_50: 0.5990  coco/bbox_mAP_75: 0.3460  coco/bbox_mAP_s: 0.1560  coco/bbox_mAP_m: 0.3440  coco/bbox_mAP_l: 0.3720  coco/segm_mAP: 0.3320  coco/segm_mAP_50: 0.5940  coco/segm_mAP_75: 0.3490  coco/segm_mAP_s: 0.0840  coco/segm_mAP_m: 0.3370  coco/segm_mAP_l: 0.3590  data_time: 0.0992  time: 0.9023\n",
            "09/20 15:25:13 - mmengine - INFO - Exp name: customconfig (2)_20230920_143907\n",
            "09/20 15:45:14 - mmengine - INFO - Exp name: customconfig (2)_20230920_143907\n",
            "09/20 15:56:04 - mmengine - INFO - Exp name: customconfig (2)_20230920_143907\n",
            "09/20 15:56:04 - mmengine - INFO - Epoch(train)  [2][1774/1774]  lr: 5.0000e-03  eta: 4:43:30  time: 1.1965  data_time: 0.0199  memory: 5356  loss: 0.9408  loss_rpn_cls: 0.0166  loss_rpn_bbox: 0.0294  s0.loss_cls: 0.1173  s0.acc: 90.8203  s0.loss_bbox: 0.0834  s0.loss_mask: 0.2392  s1.loss_cls: 0.0540  s1.acc: 91.5743  s1.loss_bbox: 0.1130  s1.loss_mask: 0.1188  s2.loss_cls: 0.0292  s2.acc: 91.4607  s2.loss_bbox: 0.0825  s2.loss_mask: 0.0575\n",
            "09/20 15:56:04 - mmengine - INFO - Saving checkpoint at 2 epochs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/mmdetection/mmdet/models/roi_heads/mask_heads/fcn_mask_head.py:339: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
            "  mask_preds = bboxes.new_tensor(mask_preds)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "09/20 16:00:43 - mmengine - INFO - Evaluating bbox...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.07s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=3.35s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=1.49s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.362\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.608\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.381\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.088\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.383\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.397\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.537\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.537\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.537\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.176\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.541\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.523\n",
            "09/20 16:00:49 - mmengine - INFO - bbox_mAP_copypaste: 0.362 0.608 0.381 0.088 0.383 0.397\n",
            "09/20 16:00:49 - mmengine - INFO - Evaluating segm...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.33s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=2.22s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.95s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.343\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.608\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.349\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.087\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.364\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.385\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.493\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.493\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.493\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.159\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.508\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.470\n",
            "09/20 16:00:53 - mmengine - INFO - segm_mAP_copypaste: 0.343 0.608 0.349 0.087 0.364 0.385\n",
            "09/20 16:00:53 - mmengine - INFO - Epoch(val) [2][336/336]    coco/bbox_mAP: 0.3620  coco/bbox_mAP_50: 0.6080  coco/bbox_mAP_75: 0.3810  coco/bbox_mAP_s: 0.0880  coco/bbox_mAP_m: 0.3830  coco/bbox_mAP_l: 0.3970  coco/segm_mAP: 0.3430  coco/segm_mAP_50: 0.6080  coco/segm_mAP_75: 0.3490  coco/segm_mAP_s: 0.0870  coco/segm_mAP_m: 0.3640  coco/segm_mAP_l: 0.3850  data_time: 0.0939  time: 0.7854\n",
            "09/20 16:09:53 - mmengine - INFO - Exp name: customconfig (2)_20230920_143907\n",
            "09/20 16:29:58 - mmengine - INFO - Exp name: customconfig (2)_20230920_143907\n",
            "09/20 16:36:21 - mmengine - INFO - Exp name: customconfig (2)_20230920_143907\n",
            "09/20 16:36:21 - mmengine - INFO - Epoch(train)  [3][1774/1774]  lr: 5.0000e-03  eta: 4:08:08  time: 1.1996  data_time: 0.0197  memory: 5501  loss: 0.9105  loss_rpn_cls: 0.0155  loss_rpn_bbox: 0.0284  s0.loss_cls: 0.1099  s0.acc: 99.0234  s0.loss_bbox: 0.0791  s0.loss_mask: 0.2328  s1.loss_cls: 0.0508  s1.acc: 98.2422  s1.loss_bbox: 0.1106  s1.loss_mask: 0.1163  s2.loss_cls: 0.0283  s2.acc: 97.6562  s2.loss_bbox: 0.0824  s2.loss_mask: 0.0564\n",
            "09/20 16:36:21 - mmengine - INFO - Saving checkpoint at 3 epochs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/mmdetection/mmdet/models/roi_heads/mask_heads/fcn_mask_head.py:339: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
            "  mask_preds = bboxes.new_tensor(mask_preds)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "09/20 16:41:26 - mmengine - INFO - Evaluating bbox...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=3.26s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=1.76s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.356\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.615\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.373\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.151\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.341\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.398\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.515\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.515\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.515\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.242\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.513\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.563\n",
            "09/20 16:41:31 - mmengine - INFO - bbox_mAP_copypaste: 0.356 0.615 0.373 0.151 0.341 0.398\n",
            "09/20 16:41:31 - mmengine - INFO - Evaluating segm...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.69s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=3.92s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.91s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.339\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.598\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.345\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.096\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.330\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.387\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.475\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.475\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.475\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.195\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.473\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.508\n",
            "09/20 16:41:37 - mmengine - INFO - segm_mAP_copypaste: 0.339 0.598 0.345 0.096 0.330 0.387\n",
            "09/20 16:41:37 - mmengine - INFO - Epoch(val) [3][336/336]    coco/bbox_mAP: 0.3560  coco/bbox_mAP_50: 0.6150  coco/bbox_mAP_75: 0.3730  coco/bbox_mAP_s: 0.1510  coco/bbox_mAP_m: 0.3410  coco/bbox_mAP_l: 0.3980  coco/segm_mAP: 0.3390  coco/segm_mAP_50: 0.5980  coco/segm_mAP_75: 0.3450  coco/segm_mAP_s: 0.0960  coco/segm_mAP_m: 0.3300  coco/segm_mAP_l: 0.3870  data_time: 0.0883  time: 0.8000\n",
            "09/20 16:55:20 - mmengine - INFO - Exp name: customconfig (2)_20230920_143907\n",
            "09/20 17:15:19 - mmengine - INFO - Exp name: customconfig (2)_20230920_143907\n",
            "09/20 17:17:14 - mmengine - INFO - Exp name: customconfig (2)_20230920_143907\n",
            "09/20 17:17:14 - mmengine - INFO - Epoch(train)  [4][1774/1774]  lr: 5.0000e-03  eta: 3:32:55  time: 1.2042  data_time: 0.0198  memory: 5356  loss: 0.8341  loss_rpn_cls: 0.0119  loss_rpn_bbox: 0.0260  s0.loss_cls: 0.0925  s0.acc: 91.4062  s0.loss_bbox: 0.0700  s0.loss_mask: 0.2221  s1.loss_cls: 0.0416  s1.acc: 92.7632  s1.loss_bbox: 0.1011  s1.loss_mask: 0.1116  s2.loss_cls: 0.0235  s2.acc: 96.1009  s2.loss_bbox: 0.0794  s2.loss_mask: 0.0545\n",
            "09/20 17:17:14 - mmengine - INFO - Saving checkpoint at 4 epochs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/mmdetection/mmdet/models/roi_heads/mask_heads/fcn_mask_head.py:339: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
            "  mask_preds = bboxes.new_tensor(mask_preds)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "09/20 17:21:30 - mmengine - INFO - Evaluating bbox...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.73s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=1.08s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.344\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.599\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.369\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.096\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.355\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.355\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.525\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.525\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.525\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.167\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.544\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.513\n",
            "09/20 17:21:33 - mmengine - INFO - bbox_mAP_copypaste: 0.344 0.599 0.369 0.096 0.355 0.355\n",
            "09/20 17:21:33 - mmengine - INFO - Evaluating segm...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.36s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=3.31s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=1.27s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.329\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.581\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.338\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.076\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.340\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.352\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.480\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.480\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.480\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.136\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.499\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.466\n",
            "09/20 17:21:39 - mmengine - INFO - segm_mAP_copypaste: 0.329 0.581 0.338 0.076 0.340 0.352\n",
            "09/20 17:21:39 - mmengine - INFO - Epoch(val) [4][336/336]    coco/bbox_mAP: 0.3440  coco/bbox_mAP_50: 0.5990  coco/bbox_mAP_75: 0.3690  coco/bbox_mAP_s: 0.0960  coco/bbox_mAP_m: 0.3550  coco/bbox_mAP_l: 0.3550  coco/segm_mAP: 0.3290  coco/segm_mAP_50: 0.5810  coco/segm_mAP_75: 0.3380  coco/segm_mAP_s: 0.0760  coco/segm_mAP_m: 0.3400  coco/segm_mAP_l: 0.3520  data_time: 0.0907  time: 0.6813\n",
            "09/20 17:39:49 - mmengine - INFO - Exp name: customconfig (2)_20230920_143907\n",
            "09/20 17:57:13 - mmengine - INFO - Exp name: customconfig (2)_20230920_143907\n",
            "09/20 17:57:13 - mmengine - INFO - Epoch(train)  [5][1774/1774]  lr: 5.0000e-03  eta: 2:57:31  time: 1.2031  data_time: 0.0196  memory: 5356  loss: 0.7995  loss_rpn_cls: 0.0113  loss_rpn_bbox: 0.0251  s0.loss_cls: 0.0858  s0.acc: 100.0000  s0.loss_bbox: 0.0656  s0.loss_mask: 0.2166  s1.loss_cls: 0.0381  s1.acc: 100.0000  s1.loss_bbox: 0.0957  s1.loss_mask: 0.1090  s2.loss_cls: 0.0220  s2.acc: 100.0000  s2.loss_bbox: 0.0769  s2.loss_mask: 0.0534\n",
            "09/20 17:57:13 - mmengine - INFO - Saving checkpoint at 5 epochs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/mmdetection/mmdet/models/roi_heads/mask_heads/fcn_mask_head.py:339: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
            "  mask_preds = bboxes.new_tensor(mask_preds)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "09/20 18:01:27 - mmengine - INFO - Evaluating bbox...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.84s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.78s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.320\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.579\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.318\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.093\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.328\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.338\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.491\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.491\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.491\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.142\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.492\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.511\n",
            "09/20 18:01:30 - mmengine - INFO - bbox_mAP_copypaste: 0.320 0.579 0.318 0.093 0.328 0.338\n",
            "09/20 18:01:30 - mmengine - INFO - Evaluating segm...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.27s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=3.10s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=1.39s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.306\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.566\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.307\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.060\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.320\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.317\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.455\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.455\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.455\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.096\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.467\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.447\n",
            "09/20 18:01:35 - mmengine - INFO - segm_mAP_copypaste: 0.306 0.566 0.307 0.060 0.320 0.317\n",
            "09/20 18:01:35 - mmengine - INFO - Epoch(val) [5][336/336]    coco/bbox_mAP: 0.3200  coco/bbox_mAP_50: 0.5790  coco/bbox_mAP_75: 0.3180  coco/bbox_mAP_s: 0.0930  coco/bbox_mAP_m: 0.3280  coco/bbox_mAP_l: 0.3380  coco/segm_mAP: 0.3060  coco/segm_mAP_50: 0.5660  coco/segm_mAP_75: 0.3070  coco/segm_mAP_s: 0.0600  coco/segm_mAP_m: 0.3200  coco/segm_mAP_l: 0.3170  data_time: 0.0847  time: 0.7222\n",
            "09/20 18:04:16 - mmengine - INFO - Exp name: customconfig (2)_20230920_143907\n",
            "09/20 18:24:15 - mmengine - INFO - Exp name: customconfig (2)_20230920_143907\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n",
            "Custom TB Handler failed, unregistering\n",
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n",
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n",
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-3-3aa8b8007f19>\", line 9, in <cell line: 9>\n",
            "    runner.train()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/runner/runner.py\", line 1745, in train\n",
            "    model = self.train_loop.run()  # type: ignore\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/runner/loops.py\", line 96, in run\n",
            "    self.run_epoch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/runner/loops.py\", line 111, in run_epoch\n",
            "    for idx, data_batch in enumerate(self.dataloader):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 633, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1325, in _next_data\n",
            "    return self._process_data(data)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1371, in _process_data\n",
            "    data.reraise()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_utils.py\", line 644, in reraise\n",
            "    raise exception\n",
            "FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 2.\n",
            "Original Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n",
            "    data = fetcher.fetch(index)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/dataset/base_dataset.py\", line 408, in __getitem__\n",
            "    data = self.prepare_data(idx)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/dataset/base_dataset.py\", line 790, in prepare_data\n",
            "    return self.pipeline(data_info)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/dataset/base_dataset.py\", line 58, in __call__\n",
            "    data = t(data)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmcv/transforms/base.py\", line 12, in __call__\n",
            "    return self.transform(results)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmcv/transforms/loading.py\", line 107, in transform\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmcv/transforms/loading.py\", line 99, in transform\n",
            "    img_bytes = fileio.get(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/fileio/io.py\", line 181, in get\n",
            "    return backend.get(filepath)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/fileio/backends/local_backend.py\", line 33, in get\n",
            "    with open(filepath, 'rb') as f:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/data/diagnosis/train/81-_JPG.rf.9e04b94fa16a10626a31b3046d852d98.jpg'\n",
            "\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n",
            "    module = getmodule(object, filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 861, in getmodule\n",
            "    file = getabsfile(object, _filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 845, in getabsfile\n",
            "    return os.path.normcase(os.path.abspath(_filename))\n",
            "  File \"/usr/lib/python3.10/posixpath.py\", line 384, in abspath\n",
            "    cwd = os.getcwd()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-3-3aa8b8007f19>\", line 9, in <cell line: 9>\n",
            "    runner.train()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/runner/runner.py\", line 1745, in train\n",
            "    model = self.train_loop.run()  # type: ignore\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/runner/loops.py\", line 96, in run\n",
            "    self.run_epoch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/runner/loops.py\", line 111, in run_epoch\n",
            "    for idx, data_batch in enumerate(self.dataloader):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 633, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1325, in _next_data\n",
            "    return self._process_data(data)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1371, in _process_data\n",
            "    data.reraise()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_utils.py\", line 644, in reraise\n",
            "    raise exception\n",
            "FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 2.\n",
            "Original Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n",
            "    data = fetcher.fetch(index)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/dataset/base_dataset.py\", line 408, in __getitem__\n",
            "    data = self.prepare_data(idx)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/dataset/base_dataset.py\", line 790, in prepare_data\n",
            "    return self.pipeline(data_info)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/dataset/base_dataset.py\", line 58, in __call__\n",
            "    data = t(data)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmcv/transforms/base.py\", line 12, in __call__\n",
            "    return self.transform(results)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmcv/transforms/loading.py\", line 107, in transform\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmcv/transforms/loading.py\", line 99, in transform\n",
            "    img_bytes = fileio.get(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/fileio/io.py\", line 181, in get\n",
            "    return backend.get(filepath)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/fileio/backends/local_backend.py\", line 33, in get\n",
            "    with open(filepath, 'rb') as f:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/data/diagnosis/train/81-_JPG.rf.9e04b94fa16a10626a31b3046d852d98.jpg'\n",
            "\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 1972, in wrapped\n",
            "    stb = handler(self,etype,value,tb,tb_offset=tb_offset)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/dask/base.py\", line 79, in _clean_ipython_traceback\n",
            "    stb = self.InteractiveTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n",
            "    return FormattedTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n",
            "    return VerboseTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1124, in structured_traceback\n",
            "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
            "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
            "    return len(records), 0\n",
            "TypeError: object of type 'NoneType' has no len()\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n",
            "    module = getmodule(object, filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 861, in getmodule\n",
            "    file = getabsfile(object, _filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 845, in getabsfile\n",
            "    return os.path.normcase(os.path.abspath(_filename))\n",
            "  File \"/usr/lib/python3.10/posixpath.py\", line 384, in abspath\n",
            "    cwd = os.getcwd()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-3-3aa8b8007f19>\", line 9, in <cell line: 9>\n",
            "    runner.train()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/runner/runner.py\", line 1745, in train\n",
            "    model = self.train_loop.run()  # type: ignore\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/runner/loops.py\", line 96, in run\n",
            "    self.run_epoch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/runner/loops.py\", line 111, in run_epoch\n",
            "    for idx, data_batch in enumerate(self.dataloader):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 633, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1325, in _next_data\n",
            "    return self._process_data(data)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1371, in _process_data\n",
            "    data.reraise()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_utils.py\", line 644, in reraise\n",
            "    raise exception\n",
            "FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 2.\n",
            "Original Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n",
            "    data = fetcher.fetch(index)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/dataset/base_dataset.py\", line 408, in __getitem__\n",
            "    data = self.prepare_data(idx)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/dataset/base_dataset.py\", line 790, in prepare_data\n",
            "    return self.pipeline(data_info)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/dataset/base_dataset.py\", line 58, in __call__\n",
            "    data = t(data)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmcv/transforms/base.py\", line 12, in __call__\n",
            "    return self.transform(results)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmcv/transforms/loading.py\", line 107, in transform\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmcv/transforms/loading.py\", line 99, in transform\n",
            "    img_bytes = fileio.get(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/fileio/io.py\", line 181, in get\n",
            "    return backend.get(filepath)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/fileio/backends/local_backend.py\", line 33, in get\n",
            "    with open(filepath, 'rb') as f:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/data/diagnosis/train/81-_JPG.rf.9e04b94fa16a10626a31b3046d852d98.jpg'\n",
            "\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 1972, in wrapped\n",
            "    stb = handler(self,etype,value,tb,tb_offset=tb_offset)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/dask/base.py\", line 79, in _clean_ipython_traceback\n",
            "    stb = self.InteractiveTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n",
            "    return FormattedTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n",
            "    return VerboseTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1124, in structured_traceback\n",
            "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
            "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
            "    return len(records), 0\n",
            "TypeError: object of type 'NoneType' has no len()\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n",
            "    if (await self.run_code(code, result,  async_=asy)):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3571, in run_code\n",
            "    self.CustomTB(etype, value, tb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 1979, in wrapped\n",
            "    stb = self.InteractiveTB.structured_traceback(*sys.exc_info())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n",
            "    return FormattedTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n",
            "    return VerboseTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1142, in structured_traceback\n",
            "    formatted_exceptions += self.format_exception_as_a_whole(etype, evalue, etb, lines_of_context,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
            "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
            "    return len(records), 0\n",
            "TypeError: object of type 'NoneType' has no len()\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n",
            "    module = getmodule(object, filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 861, in getmodule\n",
            "    file = getabsfile(object, _filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 845, in getabsfile\n",
            "    return os.path.normcase(os.path.abspath(_filename))\n",
            "  File \"/usr/lib/python3.10/posixpath.py\", line 384, in abspath\n",
            "    cwd = os.getcwd()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-3-3aa8b8007f19>\", line 9, in <cell line: 9>\n",
            "    runner.train()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/runner/runner.py\", line 1745, in train\n",
            "    model = self.train_loop.run()  # type: ignore\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/runner/loops.py\", line 96, in run\n",
            "    self.run_epoch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/runner/loops.py\", line 111, in run_epoch\n",
            "    for idx, data_batch in enumerate(self.dataloader):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 633, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1325, in _next_data\n",
            "    return self._process_data(data)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1371, in _process_data\n",
            "    data.reraise()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_utils.py\", line 644, in reraise\n",
            "    raise exception\n",
            "FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 2.\n",
            "Original Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n",
            "    data = fetcher.fetch(index)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/dataset/base_dataset.py\", line 408, in __getitem__\n",
            "    data = self.prepare_data(idx)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/dataset/base_dataset.py\", line 790, in prepare_data\n",
            "    return self.pipeline(data_info)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/dataset/base_dataset.py\", line 58, in __call__\n",
            "    data = t(data)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmcv/transforms/base.py\", line 12, in __call__\n",
            "    return self.transform(results)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmcv/transforms/loading.py\", line 107, in transform\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmcv/transforms/loading.py\", line 99, in transform\n",
            "    img_bytes = fileio.get(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/fileio/io.py\", line 181, in get\n",
            "    return backend.get(filepath)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/fileio/backends/local_backend.py\", line 33, in get\n",
            "    with open(filepath, 'rb') as f:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/data/diagnosis/train/81-_JPG.rf.9e04b94fa16a10626a31b3046d852d98.jpg'\n",
            "\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 1972, in wrapped\n",
            "    stb = handler(self,etype,value,tb,tb_offset=tb_offset)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/dask/base.py\", line 79, in _clean_ipython_traceback\n",
            "    stb = self.InteractiveTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n",
            "    return FormattedTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n",
            "    return VerboseTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1124, in structured_traceback\n",
            "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
            "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
            "    return len(records), 0\n",
            "TypeError: object of type 'NoneType' has no len()\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n",
            "    if (await self.run_code(code, result,  async_=asy)):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3571, in run_code\n",
            "    self.CustomTB(etype, value, tb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 1979, in wrapped\n",
            "    stb = self.InteractiveTB.structured_traceback(*sys.exc_info())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n",
            "    return FormattedTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n",
            "    return VerboseTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1142, in structured_traceback\n",
            "    formatted_exceptions += self.format_exception_as_a_whole(etype, evalue, etb, lines_of_context,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
            "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
            "    return len(records), 0\n",
            "TypeError: object of type 'NoneType' has no len()\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n",
            "    return runner(coro)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n",
            "    coro.send(None)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n",
            "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3492, in run_ast_nodes\n",
            "    self.showtraceback()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n",
            "    stb = self.InteractiveTB.structured_traceback(etype,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n",
            "    return FormattedTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n",
            "    return VerboseTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1142, in structured_traceback\n",
            "    formatted_exceptions += self.format_exception_as_a_whole(etype, evalue, etb, lines_of_context,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
            "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
            "    return len(records), 0\n",
            "TypeError: object of type 'NoneType' has no len()\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n",
            "    module = getmodule(object, filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 861, in getmodule\n",
            "    file = getabsfile(object, _filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 845, in getabsfile\n",
            "    return os.path.normcase(os.path.abspath(_filename))\n",
            "  File \"/usr/lib/python3.10/posixpath.py\", line 384, in abspath\n",
            "    cwd = os.getcwd()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n"
          ]
        }
      ],
      "source": [
        "from mmengine import Config\n",
        "\n",
        "cfg = Config.fromfile('/content/drive/MyDrive/models/customconfig (2).py')\n",
        "cfg['load_from']=r'/content/drive/MyDrive/models/epoch_5.pth'\n",
        "%cd /content/drive/MyDrive\n",
        "\n",
        "from mmengine.runner import Runner\n",
        "runner = Runner.from_cfg(cfg)\n",
        "runner.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "1J1o_WdqWkq4",
        "outputId": "7b299a88-3df1-4e8b-b705-827e474e2ac5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive\n",
            "09/21 15:29:15 - mmengine - INFO - \n",
            "------------------------------------------------------------\n",
            "System environment:\n",
            "    sys.platform: linux\n",
            "    Python: 3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0]\n",
            "    CUDA available: True\n",
            "    numpy_random_seed: 282443499\n",
            "    GPU 0: Tesla T4\n",
            "    CUDA_HOME: /usr/local/cuda\n",
            "    NVCC: Cuda compilation tools, release 11.8, V11.8.89\n",
            "    GCC: x86_64-linux-gnu-gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
            "    PyTorch: 2.0.1+cu118\n",
            "    PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 9.3\n",
            "  - C++ Version: 201703\n",
            "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 11.8\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
            "  - CuDNN 8.7\n",
            "  - Magma 2.6.1\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "    TorchVision: 0.15.2+cu118\n",
            "    OpenCV: 4.8.0\n",
            "    MMEngine: 0.8.4\n",
            "\n",
            "Runtime environment:\n",
            "    cudnn_benchmark: False\n",
            "    dist_cfg: {'backend': 'nccl'}\n",
            "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
            "    seed: 282443499\n",
            "    Distributed launcher: none\n",
            "    Distributed training: False\n",
            "    GPU number: 1\n",
            "------------------------------------------------------------\n",
            "\n",
            "09/21 15:29:16 - mmengine - INFO - Config:\n",
            "auto_scale_lr = dict(base_batch_size=16, enable=False)\n",
            "backend_args = None\n",
            "classes = (\n",
            "    'Bdr',\n",
            "    'Bone Loss',\n",
            "    'Bridge',\n",
            "    'Caries',\n",
            "    'Crown',\n",
            "    'Filling',\n",
            "    'Impaction',\n",
            "    'Implant',\n",
            "    'Periapical Abscess',\n",
            "    'Rct',\n",
            "    'Rct +Post',\n",
            "    'Retentive Pin',\n",
            "    'Shadow',\n",
            "    'Splinted Crowns',\n",
            "    'Unerupted',\n",
            ")\n",
            "data_root = 'data/diagnosis'\n",
            "dataset_type = 'DiagnosisDataset'\n",
            "default_hooks = dict(\n",
            "    checkpoint=dict(interval=1, type='CheckpointHook'),\n",
            "    logger=dict(interval=1774, type='LoggerHook'),\n",
            "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    timer=dict(type='IterTimerHook'),\n",
            "    visualization=dict(type='DetVisualizationHook'))\n",
            "default_scope = 'mmdet'\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=False,\n",
            "    dist_cfg=dict(backend='nccl'),\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
            "load_from = '/content/drive/MyDrive/models/temp.pth'\n",
            "log_level = 'INFO'\n",
            "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=1774)\n",
            "lr_config = dict(step=[\n",
            "    25,\n",
            "    30,\n",
            "])\n",
            "max_epochs = 20\n",
            "model = dict(\n",
            "    backbone=dict(\n",
            "        conv_cfg=dict(type='ConvAWS'),\n",
            "        depth=101,\n",
            "        frozen_stages=4,\n",
            "        init_cfg=dict(checkpoint='torchvision://resnet101', type='Pretrained'),\n",
            "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "        norm_eval=True,\n",
            "        num_stages=4,\n",
            "        out_indices=(\n",
            "            0,\n",
            "            1,\n",
            "            2,\n",
            "            3,\n",
            "        ),\n",
            "        output_img=True,\n",
            "        sac=dict(type='SAC', use_deform=True),\n",
            "        stage_with_sac=(\n",
            "            False,\n",
            "            True,\n",
            "            True,\n",
            "            True,\n",
            "        ),\n",
            "        style='pytorch',\n",
            "        type='DetectoRS_ResNet'),\n",
            "    data_preprocessor=dict(\n",
            "        bgr_to_rgb=True,\n",
            "        mean=[\n",
            "            123.675,\n",
            "            116.28,\n",
            "            103.53,\n",
            "        ],\n",
            "        pad_seg=True,\n",
            "        pad_size_divisor=32,\n",
            "        std=[\n",
            "            58.395,\n",
            "            57.12,\n",
            "            57.375,\n",
            "        ],\n",
            "        type='DetDataPreprocessor'),\n",
            "    neck=dict(\n",
            "        aspp_dilations=(\n",
            "            1,\n",
            "            3,\n",
            "            6,\n",
            "            1,\n",
            "        ),\n",
            "        aspp_out_channels=64,\n",
            "        in_channels=[\n",
            "            256,\n",
            "            512,\n",
            "            1024,\n",
            "            2048,\n",
            "        ],\n",
            "        num_outs=5,\n",
            "        out_channels=256,\n",
            "        rfp_backbone=dict(\n",
            "            conv_cfg=dict(type='ConvAWS'),\n",
            "            depth=101,\n",
            "            frozen_stages=1,\n",
            "            norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "            norm_eval=True,\n",
            "            num_stages=4,\n",
            "            out_indices=(\n",
            "                0,\n",
            "                1,\n",
            "                2,\n",
            "                3,\n",
            "            ),\n",
            "            pretrained='torchvision://resnet101',\n",
            "            rfp_inplanes=256,\n",
            "            sac=dict(type='SAC', use_deform=True),\n",
            "            stage_with_sac=(\n",
            "                False,\n",
            "                True,\n",
            "                True,\n",
            "                True,\n",
            "            ),\n",
            "            style='pytorch',\n",
            "            type='DetectoRS_ResNet'),\n",
            "        rfp_steps=2,\n",
            "        type='RFP'),\n",
            "    roi_head=dict(\n",
            "        bbox_head=[\n",
            "            dict(\n",
            "                bbox_coder=dict(\n",
            "                    target_means=[\n",
            "                        0.0,\n",
            "                        0.0,\n",
            "                        0.0,\n",
            "                        0.0,\n",
            "                    ],\n",
            "                    target_stds=[\n",
            "                        0.1,\n",
            "                        0.1,\n",
            "                        0.2,\n",
            "                        0.2,\n",
            "                    ],\n",
            "                    type='DeltaXYWHBBoxCoder'),\n",
            "                fc_out_channels=1024,\n",
            "                in_channels=256,\n",
            "                loss_bbox=dict(beta=1.0, loss_weight=1.0, type='SmoothL1Loss'),\n",
            "                loss_cls=dict(\n",
            "                    loss_weight=1.0,\n",
            "                    type='CrossEntropyLoss',\n",
            "                    use_sigmoid=False),\n",
            "                num_classes=15,\n",
            "                reg_class_agnostic=True,\n",
            "                roi_feat_size=7,\n",
            "                type='Shared2FCBBoxHead'),\n",
            "            dict(\n",
            "                bbox_coder=dict(\n",
            "                    target_means=[\n",
            "                        0.0,\n",
            "                        0.0,\n",
            "                        0.0,\n",
            "                        0.0,\n",
            "                    ],\n",
            "                    target_stds=[\n",
            "                        0.05,\n",
            "                        0.05,\n",
            "                        0.1,\n",
            "                        0.1,\n",
            "                    ],\n",
            "                    type='DeltaXYWHBBoxCoder'),\n",
            "                fc_out_channels=1024,\n",
            "                in_channels=256,\n",
            "                loss_bbox=dict(beta=1.0, loss_weight=1.0, type='SmoothL1Loss'),\n",
            "                loss_cls=dict(\n",
            "                    loss_weight=1.0,\n",
            "                    type='CrossEntropyLoss',\n",
            "                    use_sigmoid=False),\n",
            "                num_classes=15,\n",
            "                reg_class_agnostic=True,\n",
            "                roi_feat_size=7,\n",
            "                type='Shared2FCBBoxHead'),\n",
            "            dict(\n",
            "                bbox_coder=dict(\n",
            "                    target_means=[\n",
            "                        0.0,\n",
            "                        0.0,\n",
            "                        0.0,\n",
            "                        0.0,\n",
            "                    ],\n",
            "                    target_stds=[\n",
            "                        0.033,\n",
            "                        0.033,\n",
            "                        0.067,\n",
            "                        0.067,\n",
            "                    ],\n",
            "                    type='DeltaXYWHBBoxCoder'),\n",
            "                fc_out_channels=1024,\n",
            "                in_channels=256,\n",
            "                loss_bbox=dict(beta=1.0, loss_weight=1.0, type='SmoothL1Loss'),\n",
            "                loss_cls=dict(\n",
            "                    loss_weight=1.0,\n",
            "                    type='CrossEntropyLoss',\n",
            "                    use_sigmoid=False),\n",
            "                num_classes=15,\n",
            "                reg_class_agnostic=True,\n",
            "                roi_feat_size=7,\n",
            "                type='Shared2FCBBoxHead'),\n",
            "        ],\n",
            "        bbox_roi_extractor=dict(\n",
            "            featmap_strides=[\n",
            "                4,\n",
            "                8,\n",
            "                16,\n",
            "                32,\n",
            "            ],\n",
            "            out_channels=256,\n",
            "            roi_layer=dict(output_size=7, sampling_ratio=0, type='RoIAlign'),\n",
            "            type='SingleRoIExtractor'),\n",
            "        interleaved=True,\n",
            "        mask_head=[\n",
            "            dict(\n",
            "                conv_out_channels=256,\n",
            "                in_channels=256,\n",
            "                loss_mask=dict(\n",
            "                    loss_weight=1.0, type='CrossEntropyLoss', use_mask=True),\n",
            "                num_classes=80,\n",
            "                num_convs=4,\n",
            "                type='HTCMaskHead',\n",
            "                with_conv_res=False),\n",
            "            dict(\n",
            "                conv_out_channels=256,\n",
            "                in_channels=256,\n",
            "                loss_mask=dict(\n",
            "                    loss_weight=1.0, type='CrossEntropyLoss', use_mask=True),\n",
            "                num_classes=15,\n",
            "                num_convs=4,\n",
            "                type='HTCMaskHead'),\n",
            "            dict(\n",
            "                conv_out_channels=256,\n",
            "                in_channels=256,\n",
            "                loss_mask=dict(\n",
            "                    loss_weight=1.0, type='CrossEntropyLoss', use_mask=True),\n",
            "                num_classes=15,\n",
            "                num_convs=4,\n",
            "                type='HTCMaskHead'),\n",
            "        ],\n",
            "        mask_info_flow=True,\n",
            "        mask_roi_extractor=dict(\n",
            "            featmap_strides=[\n",
            "                4,\n",
            "                8,\n",
            "                16,\n",
            "                32,\n",
            "            ],\n",
            "            out_channels=256,\n",
            "            roi_layer=dict(output_size=14, sampling_ratio=0, type='RoIAlign'),\n",
            "            type='SingleRoIExtractor'),\n",
            "        num_stages=3,\n",
            "        stage_loss_weights=[\n",
            "            1,\n",
            "            0.5,\n",
            "            0.25,\n",
            "        ],\n",
            "        type='HybridTaskCascadeRoIHead'),\n",
            "    rpn_head=dict(\n",
            "        anchor_generator=dict(\n",
            "            ratios=[\n",
            "                0.5,\n",
            "                1.0,\n",
            "                2.0,\n",
            "            ],\n",
            "            scales=[\n",
            "                8,\n",
            "            ],\n",
            "            strides=[\n",
            "                4,\n",
            "                8,\n",
            "                16,\n",
            "                32,\n",
            "                64,\n",
            "            ],\n",
            "            type='AnchorGenerator'),\n",
            "        bbox_coder=dict(\n",
            "            target_means=[\n",
            "                0.0,\n",
            "                0.0,\n",
            "                0.0,\n",
            "                0.0,\n",
            "            ],\n",
            "            target_stds=[\n",
            "                1.0,\n",
            "                1.0,\n",
            "                1.0,\n",
            "                1.0,\n",
            "            ],\n",
            "            type='DeltaXYWHBBoxCoder'),\n",
            "        feat_channels=256,\n",
            "        in_channels=256,\n",
            "        loss_bbox=dict(\n",
            "            beta=0.1111111111111111, loss_weight=1.0, type='SmoothL1Loss'),\n",
            "        loss_cls=dict(\n",
            "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=True),\n",
            "        type='RPNHead'),\n",
            "    test_cfg=dict(\n",
            "        rcnn=dict(\n",
            "            mask_thr_binary=0.5,\n",
            "            max_per_img=100,\n",
            "            nms=dict(iou_threshold=0.5, type='nms'),\n",
            "            score_thr=0.001),\n",
            "        rpn=dict(\n",
            "            max_per_img=1000,\n",
            "            min_bbox_size=0,\n",
            "            nms=dict(iou_threshold=0.7, type='nms'),\n",
            "            nms_pre=1000)),\n",
            "    train_cfg=dict(\n",
            "        rcnn=[\n",
            "            dict(\n",
            "                assigner=dict(\n",
            "                    ignore_iof_thr=-1,\n",
            "                    min_pos_iou=0.5,\n",
            "                    neg_iou_thr=0.5,\n",
            "                    pos_iou_thr=0.5,\n",
            "                    type='MaxIoUAssigner'),\n",
            "                debug=False,\n",
            "                mask_size=28,\n",
            "                pos_weight=-1,\n",
            "                sampler=dict(\n",
            "                    add_gt_as_proposals=True,\n",
            "                    neg_pos_ub=-1,\n",
            "                    num=512,\n",
            "                    pos_fraction=0.25,\n",
            "                    type='RandomSampler')),\n",
            "            dict(\n",
            "                assigner=dict(\n",
            "                    ignore_iof_thr=-1,\n",
            "                    min_pos_iou=0.6,\n",
            "                    neg_iou_thr=0.6,\n",
            "                    pos_iou_thr=0.6,\n",
            "                    type='MaxIoUAssigner'),\n",
            "                debug=False,\n",
            "                mask_size=28,\n",
            "                pos_weight=-1,\n",
            "                sampler=dict(\n",
            "                    add_gt_as_proposals=True,\n",
            "                    neg_pos_ub=-1,\n",
            "                    num=512,\n",
            "                    pos_fraction=0.25,\n",
            "                    type='RandomSampler')),\n",
            "            dict(\n",
            "                assigner=dict(\n",
            "                    ignore_iof_thr=-1,\n",
            "                    min_pos_iou=0.7,\n",
            "                    neg_iou_thr=0.7,\n",
            "                    pos_iou_thr=0.7,\n",
            "                    type='MaxIoUAssigner'),\n",
            "                debug=False,\n",
            "                mask_size=28,\n",
            "                pos_weight=-1,\n",
            "                sampler=dict(\n",
            "                    add_gt_as_proposals=True,\n",
            "                    neg_pos_ub=-1,\n",
            "                    num=512,\n",
            "                    pos_fraction=0.25,\n",
            "                    type='RandomSampler')),\n",
            "        ],\n",
            "        rpn=dict(\n",
            "            allowed_border=0,\n",
            "            assigner=dict(\n",
            "                ignore_iof_thr=-1,\n",
            "                min_pos_iou=0.3,\n",
            "                neg_iou_thr=0.3,\n",
            "                pos_iou_thr=0.7,\n",
            "                type='MaxIoUAssigner'),\n",
            "            debug=False,\n",
            "            pos_weight=-1,\n",
            "            sampler=dict(\n",
            "                add_gt_as_proposals=False,\n",
            "                neg_pos_ub=-1,\n",
            "                num=256,\n",
            "                pos_fraction=0.5,\n",
            "                type='RandomSampler')),\n",
            "        rpn_proposal=dict(\n",
            "            max_per_img=2000,\n",
            "            min_bbox_size=0,\n",
            "            nms=dict(iou_threshold=0.7, type='nms'),\n",
            "            nms_pre=2000)),\n",
            "    type='HybridTaskCascade')\n",
            "optim_wrapper = dict(\n",
            "    optimizer=dict(lr=0.005, momentum=0.9, type='SGD', weight_decay=0.0001),\n",
            "    type='OptimWrapper')\n",
            "param_scheduler = [\n",
            "    dict(\n",
            "        begin=0, by_epoch=False, end=500, start_factor=0.001, type='LinearLR'),\n",
            "    dict(\n",
            "        begin=0,\n",
            "        by_epoch=True,\n",
            "        end=12,\n",
            "        gamma=0.1,\n",
            "        milestones=[\n",
            "            21,\n",
            "            22,\n",
            "        ],\n",
            "        type='MultiStepLR'),\n",
            "]\n",
            "resume = False\n",
            "test_cfg = dict(type='TestLoop')\n",
            "test_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='ann/val.json',\n",
            "        backend_args=None,\n",
            "        data_prefix=dict(img='valid/'),\n",
            "        data_root='data/diagnosis',\n",
            "        metainfo=dict(\n",
            "            classes=(\n",
            "                'Bdr',\n",
            "                'Bone Loss',\n",
            "                'Bridge',\n",
            "                'Caries',\n",
            "                'Crown',\n",
            "                'Filling',\n",
            "                'Impaction',\n",
            "                'Implant',\n",
            "                'Periapical Abscess',\n",
            "                'Rct',\n",
            "                'Rct +Post',\n",
            "                'Retentive Pin',\n",
            "                'Shadow',\n",
            "                'Splinted Crowns',\n",
            "                'Unerupted',\n",
            "            )),\n",
            "        pipeline=[\n",
            "            dict(backend_args=None, type='LoadImageFromFile'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                1333,\n",
            "                800,\n",
            "            ), type='Resize'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'img_id',\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'scale_factor',\n",
            "                ),\n",
            "                type='PackDetInputs'),\n",
            "        ],\n",
            "        test_mode=True,\n",
            "        type='DiagnosisDataset'),\n",
            "    drop_last=False,\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "test_evaluator = dict(\n",
            "    ann_file='/content/drive/MyDrive/data/diagnosis/ann/val.json',\n",
            "    backend_args=None,\n",
            "    format_only=False,\n",
            "    metric=[\n",
            "        'bbox',\n",
            "        'segm',\n",
            "    ],\n",
            "    type='CocoMetric')\n",
            "test_pipeline = [\n",
            "    dict(backend_args=None, type='LoadImageFromFile'),\n",
            "    dict(keep_ratio=True, scale=(\n",
            "        1333,\n",
            "        800,\n",
            "    ), type='Resize'),\n",
            "    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
            "    dict(\n",
            "        meta_keys=(\n",
            "            'img_id',\n",
            "            'img_path',\n",
            "            'ori_shape',\n",
            "            'img_shape',\n",
            "            'scale_factor',\n",
            "        ),\n",
            "        type='PackDetInputs'),\n",
            "]\n",
            "train_cfg = dict(max_epochs=10, type='EpochBasedTrainLoop', val_interval=1)\n",
            "train_dataloader = dict(\n",
            "    batch_sampler=dict(type='AspectRatioBatchSampler'),\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='ann/train.json',\n",
            "        backend_args=None,\n",
            "        data_prefix=dict(img='train/'),\n",
            "        data_root='/content/drive/MyDrive/data/diagnosis',\n",
            "        filter_cfg=dict(filter_empty_gt=False, min_size=16),\n",
            "        metainfo=dict(\n",
            "            classes=(\n",
            "                'Bdr',\n",
            "                'Bone Loss',\n",
            "                'Bridge',\n",
            "                'Caries',\n",
            "                'Crown',\n",
            "                'Filling',\n",
            "                'Impaction',\n",
            "                'Implant',\n",
            "                'Periapical Abscess',\n",
            "                'Rct',\n",
            "                'Rct +Post',\n",
            "                'Retentive Pin',\n",
            "                'Shadow',\n",
            "                'Splinted Crowns',\n",
            "                'Unerupted',\n",
            "            )),\n",
            "        pipeline=[\n",
            "            dict(backend_args=None, type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                1333,\n",
            "                800,\n",
            "            ), type='Resize'),\n",
            "            dict(prob=0.0, type='RandomFlip'),\n",
            "            dict(type='PackDetInputs'),\n",
            "        ],\n",
            "        type='DiagnosisDataset'),\n",
            "    num_workers=8,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
            "train_pipeline = [\n",
            "    dict(backend_args=None, type='LoadImageFromFile'),\n",
            "    dict(\n",
            "        type='LoadAnnotations', with_bbox=True, with_mask=True, with_seg=True),\n",
            "    dict(keep_ratio=True, scale=(\n",
            "        1333,\n",
            "        800,\n",
            "    ), type='Resize'),\n",
            "    dict(prob=0.5, type='RandomFlip'),\n",
            "    dict(type='PackDetInputs'),\n",
            "]\n",
            "val_cfg = dict(type='ValLoop')\n",
            "val_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='ann/val.json',\n",
            "        backend_args=None,\n",
            "        data_prefix=dict(img='valid/'),\n",
            "        data_root='data/diagnosis',\n",
            "        metainfo=dict(\n",
            "            classes=(\n",
            "                'Bdr',\n",
            "                'Bone Loss',\n",
            "                'Bridge',\n",
            "                'Caries',\n",
            "                'Crown',\n",
            "                'Filling',\n",
            "                'Impaction',\n",
            "                'Implant',\n",
            "                'Periapical Abscess',\n",
            "                'Rct',\n",
            "                'Rct +Post',\n",
            "                'Retentive Pin',\n",
            "                'Shadow',\n",
            "                'Splinted Crowns',\n",
            "                'Unerupted',\n",
            "            )),\n",
            "        pipeline=[\n",
            "            dict(backend_args=None, type='LoadImageFromFile'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                1333,\n",
            "                800,\n",
            "            ), type='Resize'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'img_id',\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'scale_factor',\n",
            "                ),\n",
            "                type='PackDetInputs'),\n",
            "        ],\n",
            "        test_mode=True,\n",
            "        type='DiagnosisDataset'),\n",
            "    drop_last=False,\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "val_evaluator = dict(\n",
            "    ann_file='/content/drive/MyDrive/data/diagnosis/ann/val.json',\n",
            "    backend_args=None,\n",
            "    format_only=False,\n",
            "    metric=[\n",
            "        'bbox',\n",
            "        'segm',\n",
            "    ],\n",
            "    type='CocoMetric')\n",
            "vis_backends = [\n",
            "    dict(type='LocalVisBackend'),\n",
            "]\n",
            "visualizer = dict(\n",
            "    name='visualizer',\n",
            "    type='DetLocalVisualizer',\n",
            "    vis_backends=[\n",
            "        dict(type='LocalVisBackend'),\n",
            "    ])\n",
            "work_dir = 'C:\\\\Users\\\\HP\\\\mmdetection\\\\demo\\\\work_dir'\n",
            "\n",
            "09/21 15:29:25 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
            "09/21 15:29:25 - mmengine - INFO - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "before_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DistSamplerSeedHook                \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DetVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_test_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DetVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_run:\n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "loading annotations into memory...\n",
            "Done (t=1.70s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.67s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "09/21 15:29:30 - mmengine - INFO - Loads checkpoint by torchvision backend from path: torchvision://resnet101\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet101-63fe2227.pth\" to /root/.cache/torch/hub/checkpoints/resnet101-63fe2227.pth\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "09/21 15:29:30 - mmengine - WARNING - The model and loaded state dict do not match exactly\n",
            "\n",
            "unexpected key in source state_dict: fc.weight, fc.bias\n",
            "\n",
            "missing keys in source state_dict: layer2.0.conv2.weight_diff, layer2.0.conv2.switch.weight, layer2.0.conv2.switch.bias, layer2.0.conv2.pre_context.weight, layer2.0.conv2.pre_context.bias, layer2.0.conv2.post_context.weight, layer2.0.conv2.post_context.bias, layer2.0.conv2.offset_s.weight, layer2.0.conv2.offset_s.bias, layer2.0.conv2.offset_l.weight, layer2.0.conv2.offset_l.bias, layer2.1.conv2.weight_diff, layer2.1.conv2.switch.weight, layer2.1.conv2.switch.bias, layer2.1.conv2.pre_context.weight, layer2.1.conv2.pre_context.bias, layer2.1.conv2.post_context.weight, layer2.1.conv2.post_context.bias, layer2.1.conv2.offset_s.weight, layer2.1.conv2.offset_s.bias, layer2.1.conv2.offset_l.weight, layer2.1.conv2.offset_l.bias, layer2.2.conv2.weight_diff, layer2.2.conv2.switch.weight, layer2.2.conv2.switch.bias, layer2.2.conv2.pre_context.weight, layer2.2.conv2.pre_context.bias, layer2.2.conv2.post_context.weight, layer2.2.conv2.post_context.bias, layer2.2.conv2.offset_s.weight, layer2.2.conv2.offset_s.bias, layer2.2.conv2.offset_l.weight, layer2.2.conv2.offset_l.bias, layer2.3.conv2.weight_diff, layer2.3.conv2.switch.weight, layer2.3.conv2.switch.bias, layer2.3.conv2.pre_context.weight, layer2.3.conv2.pre_context.bias, layer2.3.conv2.post_context.weight, layer2.3.conv2.post_context.bias, layer2.3.conv2.offset_s.weight, layer2.3.conv2.offset_s.bias, layer2.3.conv2.offset_l.weight, layer2.3.conv2.offset_l.bias, layer3.0.conv2.weight_diff, layer3.0.conv2.switch.weight, layer3.0.conv2.switch.bias, layer3.0.conv2.pre_context.weight, layer3.0.conv2.pre_context.bias, layer3.0.conv2.post_context.weight, layer3.0.conv2.post_context.bias, layer3.0.conv2.offset_s.weight, layer3.0.conv2.offset_s.bias, layer3.0.conv2.offset_l.weight, layer3.0.conv2.offset_l.bias, layer3.1.conv2.weight_diff, layer3.1.conv2.switch.weight, layer3.1.conv2.switch.bias, layer3.1.conv2.pre_context.weight, layer3.1.conv2.pre_context.bias, layer3.1.conv2.post_context.weight, layer3.1.conv2.post_context.bias, layer3.1.conv2.offset_s.weight, layer3.1.conv2.offset_s.bias, layer3.1.conv2.offset_l.weight, layer3.1.conv2.offset_l.bias, layer3.2.conv2.weight_diff, layer3.2.conv2.switch.weight, layer3.2.conv2.switch.bias, layer3.2.conv2.pre_context.weight, layer3.2.conv2.pre_context.bias, layer3.2.conv2.post_context.weight, layer3.2.conv2.post_context.bias, layer3.2.conv2.offset_s.weight, layer3.2.conv2.offset_s.bias, layer3.2.conv2.offset_l.weight, layer3.2.conv2.offset_l.bias, layer3.3.conv2.weight_diff, layer3.3.conv2.switch.weight, layer3.3.conv2.switch.bias, layer3.3.conv2.pre_context.weight, layer3.3.conv2.pre_context.bias, layer3.3.conv2.post_context.weight, layer3.3.conv2.post_context.bias, layer3.3.conv2.offset_s.weight, layer3.3.conv2.offset_s.bias, layer3.3.conv2.offset_l.weight, layer3.3.conv2.offset_l.bias, layer3.4.conv2.weight_diff, layer3.4.conv2.switch.weight, layer3.4.conv2.switch.bias, layer3.4.conv2.pre_context.weight, layer3.4.conv2.pre_context.bias, layer3.4.conv2.post_context.weight, layer3.4.conv2.post_context.bias, layer3.4.conv2.offset_s.weight, layer3.4.conv2.offset_s.bias, layer3.4.conv2.offset_l.weight, layer3.4.conv2.offset_l.bias, layer3.5.conv2.weight_diff, layer3.5.conv2.switch.weight, layer3.5.conv2.switch.bias, layer3.5.conv2.pre_context.weight, layer3.5.conv2.pre_context.bias, layer3.5.conv2.post_context.weight, layer3.5.conv2.post_context.bias, layer3.5.conv2.offset_s.weight, layer3.5.conv2.offset_s.bias, layer3.5.conv2.offset_l.weight, layer3.5.conv2.offset_l.bias, layer3.6.conv2.weight_diff, layer3.6.conv2.switch.weight, layer3.6.conv2.switch.bias, layer3.6.conv2.pre_context.weight, layer3.6.conv2.pre_context.bias, layer3.6.conv2.post_context.weight, layer3.6.conv2.post_context.bias, layer3.6.conv2.offset_s.weight, layer3.6.conv2.offset_s.bias, layer3.6.conv2.offset_l.weight, layer3.6.conv2.offset_l.bias, layer3.7.conv2.weight_diff, layer3.7.conv2.switch.weight, layer3.7.conv2.switch.bias, layer3.7.conv2.pre_context.weight, layer3.7.conv2.pre_context.bias, layer3.7.conv2.post_context.weight, layer3.7.conv2.post_context.bias, layer3.7.conv2.offset_s.weight, layer3.7.conv2.offset_s.bias, layer3.7.conv2.offset_l.weight, layer3.7.conv2.offset_l.bias, layer3.8.conv2.weight_diff, layer3.8.conv2.switch.weight, layer3.8.conv2.switch.bias, layer3.8.conv2.pre_context.weight, layer3.8.conv2.pre_context.bias, layer3.8.conv2.post_context.weight, layer3.8.conv2.post_context.bias, layer3.8.conv2.offset_s.weight, layer3.8.conv2.offset_s.bias, layer3.8.conv2.offset_l.weight, layer3.8.conv2.offset_l.bias, layer3.9.conv2.weight_diff, layer3.9.conv2.switch.weight, layer3.9.conv2.switch.bias, layer3.9.conv2.pre_context.weight, layer3.9.conv2.pre_context.bias, layer3.9.conv2.post_context.weight, layer3.9.conv2.post_context.bias, layer3.9.conv2.offset_s.weight, layer3.9.conv2.offset_s.bias, layer3.9.conv2.offset_l.weight, layer3.9.conv2.offset_l.bias, layer3.10.conv2.weight_diff, layer3.10.conv2.switch.weight, layer3.10.conv2.switch.bias, layer3.10.conv2.pre_context.weight, layer3.10.conv2.pre_context.bias, layer3.10.conv2.post_context.weight, layer3.10.conv2.post_context.bias, layer3.10.conv2.offset_s.weight, layer3.10.conv2.offset_s.bias, layer3.10.conv2.offset_l.weight, layer3.10.conv2.offset_l.bias, layer3.11.conv2.weight_diff, layer3.11.conv2.switch.weight, layer3.11.conv2.switch.bias, layer3.11.conv2.pre_context.weight, layer3.11.conv2.pre_context.bias, layer3.11.conv2.post_context.weight, layer3.11.conv2.post_context.bias, layer3.11.conv2.offset_s.weight, layer3.11.conv2.offset_s.bias, layer3.11.conv2.offset_l.weight, layer3.11.conv2.offset_l.bias, layer3.12.conv2.weight_diff, layer3.12.conv2.switch.weight, layer3.12.conv2.switch.bias, layer3.12.conv2.pre_context.weight, layer3.12.conv2.pre_context.bias, layer3.12.conv2.post_context.weight, layer3.12.conv2.post_context.bias, layer3.12.conv2.offset_s.weight, layer3.12.conv2.offset_s.bias, layer3.12.conv2.offset_l.weight, layer3.12.conv2.offset_l.bias, layer3.13.conv2.weight_diff, layer3.13.conv2.switch.weight, layer3.13.conv2.switch.bias, layer3.13.conv2.pre_context.weight, layer3.13.conv2.pre_context.bias, layer3.13.conv2.post_context.weight, layer3.13.conv2.post_context.bias, layer3.13.conv2.offset_s.weight, layer3.13.conv2.offset_s.bias, layer3.13.conv2.offset_l.weight, layer3.13.conv2.offset_l.bias, layer3.14.conv2.weight_diff, layer3.14.conv2.switch.weight, layer3.14.conv2.switch.bias, layer3.14.conv2.pre_context.weight, layer3.14.conv2.pre_context.bias, layer3.14.conv2.post_context.weight, layer3.14.conv2.post_context.bias, layer3.14.conv2.offset_s.weight, layer3.14.conv2.offset_s.bias, layer3.14.conv2.offset_l.weight, layer3.14.conv2.offset_l.bias, layer3.15.conv2.weight_diff, layer3.15.conv2.switch.weight, layer3.15.conv2.switch.bias, layer3.15.conv2.pre_context.weight, layer3.15.conv2.pre_context.bias, layer3.15.conv2.post_context.weight, layer3.15.conv2.post_context.bias, layer3.15.conv2.offset_s.weight, layer3.15.conv2.offset_s.bias, layer3.15.conv2.offset_l.weight, layer3.15.conv2.offset_l.bias, layer3.16.conv2.weight_diff, layer3.16.conv2.switch.weight, layer3.16.conv2.switch.bias, layer3.16.conv2.pre_context.weight, layer3.16.conv2.pre_context.bias, layer3.16.conv2.post_context.weight, layer3.16.conv2.post_context.bias, layer3.16.conv2.offset_s.weight, layer3.16.conv2.offset_s.bias, layer3.16.conv2.offset_l.weight, layer3.16.conv2.offset_l.bias, layer3.17.conv2.weight_diff, layer3.17.conv2.switch.weight, layer3.17.conv2.switch.bias, layer3.17.conv2.pre_context.weight, layer3.17.conv2.pre_context.bias, layer3.17.conv2.post_context.weight, layer3.17.conv2.post_context.bias, layer3.17.conv2.offset_s.weight, layer3.17.conv2.offset_s.bias, layer3.17.conv2.offset_l.weight, layer3.17.conv2.offset_l.bias, layer3.18.conv2.weight_diff, layer3.18.conv2.switch.weight, layer3.18.conv2.switch.bias, layer3.18.conv2.pre_context.weight, layer3.18.conv2.pre_context.bias, layer3.18.conv2.post_context.weight, layer3.18.conv2.post_context.bias, layer3.18.conv2.offset_s.weight, layer3.18.conv2.offset_s.bias, layer3.18.conv2.offset_l.weight, layer3.18.conv2.offset_l.bias, layer3.19.conv2.weight_diff, layer3.19.conv2.switch.weight, layer3.19.conv2.switch.bias, layer3.19.conv2.pre_context.weight, layer3.19.conv2.pre_context.bias, layer3.19.conv2.post_context.weight, layer3.19.conv2.post_context.bias, layer3.19.conv2.offset_s.weight, layer3.19.conv2.offset_s.bias, layer3.19.conv2.offset_l.weight, layer3.19.conv2.offset_l.bias, layer3.20.conv2.weight_diff, layer3.20.conv2.switch.weight, layer3.20.conv2.switch.bias, layer3.20.conv2.pre_context.weight, layer3.20.conv2.pre_context.bias, layer3.20.conv2.post_context.weight, layer3.20.conv2.post_context.bias, layer3.20.conv2.offset_s.weight, layer3.20.conv2.offset_s.bias, layer3.20.conv2.offset_l.weight, layer3.20.conv2.offset_l.bias, layer3.21.conv2.weight_diff, layer3.21.conv2.switch.weight, layer3.21.conv2.switch.bias, layer3.21.conv2.pre_context.weight, layer3.21.conv2.pre_context.bias, layer3.21.conv2.post_context.weight, layer3.21.conv2.post_context.bias, layer3.21.conv2.offset_s.weight, layer3.21.conv2.offset_s.bias, layer3.21.conv2.offset_l.weight, layer3.21.conv2.offset_l.bias, layer3.22.conv2.weight_diff, layer3.22.conv2.switch.weight, layer3.22.conv2.switch.bias, layer3.22.conv2.pre_context.weight, layer3.22.conv2.pre_context.bias, layer3.22.conv2.post_context.weight, layer3.22.conv2.post_context.bias, layer3.22.conv2.offset_s.weight, layer3.22.conv2.offset_s.bias, layer3.22.conv2.offset_l.weight, layer3.22.conv2.offset_l.bias, layer4.0.conv2.weight_diff, layer4.0.conv2.switch.weight, layer4.0.conv2.switch.bias, layer4.0.conv2.pre_context.weight, layer4.0.conv2.pre_context.bias, layer4.0.conv2.post_context.weight, layer4.0.conv2.post_context.bias, layer4.0.conv2.offset_s.weight, layer4.0.conv2.offset_s.bias, layer4.0.conv2.offset_l.weight, layer4.0.conv2.offset_l.bias, layer4.1.conv2.weight_diff, layer4.1.conv2.switch.weight, layer4.1.conv2.switch.bias, layer4.1.conv2.pre_context.weight, layer4.1.conv2.pre_context.bias, layer4.1.conv2.post_context.weight, layer4.1.conv2.post_context.bias, layer4.1.conv2.offset_s.weight, layer4.1.conv2.offset_s.bias, layer4.1.conv2.offset_l.weight, layer4.1.conv2.offset_l.bias, layer4.2.conv2.weight_diff, layer4.2.conv2.switch.weight, layer4.2.conv2.switch.bias, layer4.2.conv2.pre_context.weight, layer4.2.conv2.pre_context.bias, layer4.2.conv2.post_context.weight, layer4.2.conv2.post_context.bias, layer4.2.conv2.offset_s.weight, layer4.2.conv2.offset_s.bias, layer4.2.conv2.offset_l.weight, layer4.2.conv2.offset_l.bias\n",
            "\n",
            "09/21 15:29:30 - mmengine - INFO - Loads checkpoint by torchvision backend from path: torchvision://resnet101\n",
            "09/21 15:29:31 - mmengine - WARNING - The model and loaded state dict do not match exactly\n",
            "\n",
            "unexpected key in source state_dict: fc.weight, fc.bias\n",
            "\n",
            "missing keys in source state_dict: layer2.0.conv2.weight_diff, layer2.0.conv2.switch.weight, layer2.0.conv2.switch.bias, layer2.0.conv2.pre_context.weight, layer2.0.conv2.pre_context.bias, layer2.0.conv2.post_context.weight, layer2.0.conv2.post_context.bias, layer2.0.conv2.offset_s.weight, layer2.0.conv2.offset_s.bias, layer2.0.conv2.offset_l.weight, layer2.0.conv2.offset_l.bias, layer2.0.rfp_conv.weight, layer2.0.rfp_conv.bias, layer2.1.conv2.weight_diff, layer2.1.conv2.switch.weight, layer2.1.conv2.switch.bias, layer2.1.conv2.pre_context.weight, layer2.1.conv2.pre_context.bias, layer2.1.conv2.post_context.weight, layer2.1.conv2.post_context.bias, layer2.1.conv2.offset_s.weight, layer2.1.conv2.offset_s.bias, layer2.1.conv2.offset_l.weight, layer2.1.conv2.offset_l.bias, layer2.2.conv2.weight_diff, layer2.2.conv2.switch.weight, layer2.2.conv2.switch.bias, layer2.2.conv2.pre_context.weight, layer2.2.conv2.pre_context.bias, layer2.2.conv2.post_context.weight, layer2.2.conv2.post_context.bias, layer2.2.conv2.offset_s.weight, layer2.2.conv2.offset_s.bias, layer2.2.conv2.offset_l.weight, layer2.2.conv2.offset_l.bias, layer2.3.conv2.weight_diff, layer2.3.conv2.switch.weight, layer2.3.conv2.switch.bias, layer2.3.conv2.pre_context.weight, layer2.3.conv2.pre_context.bias, layer2.3.conv2.post_context.weight, layer2.3.conv2.post_context.bias, layer2.3.conv2.offset_s.weight, layer2.3.conv2.offset_s.bias, layer2.3.conv2.offset_l.weight, layer2.3.conv2.offset_l.bias, layer3.0.conv2.weight_diff, layer3.0.conv2.switch.weight, layer3.0.conv2.switch.bias, layer3.0.conv2.pre_context.weight, layer3.0.conv2.pre_context.bias, layer3.0.conv2.post_context.weight, layer3.0.conv2.post_context.bias, layer3.0.conv2.offset_s.weight, layer3.0.conv2.offset_s.bias, layer3.0.conv2.offset_l.weight, layer3.0.conv2.offset_l.bias, layer3.0.rfp_conv.weight, layer3.0.rfp_conv.bias, layer3.1.conv2.weight_diff, layer3.1.conv2.switch.weight, layer3.1.conv2.switch.bias, layer3.1.conv2.pre_context.weight, layer3.1.conv2.pre_context.bias, layer3.1.conv2.post_context.weight, layer3.1.conv2.post_context.bias, layer3.1.conv2.offset_s.weight, layer3.1.conv2.offset_s.bias, layer3.1.conv2.offset_l.weight, layer3.1.conv2.offset_l.bias, layer3.2.conv2.weight_diff, layer3.2.conv2.switch.weight, layer3.2.conv2.switch.bias, layer3.2.conv2.pre_context.weight, layer3.2.conv2.pre_context.bias, layer3.2.conv2.post_context.weight, layer3.2.conv2.post_context.bias, layer3.2.conv2.offset_s.weight, layer3.2.conv2.offset_s.bias, layer3.2.conv2.offset_l.weight, layer3.2.conv2.offset_l.bias, layer3.3.conv2.weight_diff, layer3.3.conv2.switch.weight, layer3.3.conv2.switch.bias, layer3.3.conv2.pre_context.weight, layer3.3.conv2.pre_context.bias, layer3.3.conv2.post_context.weight, layer3.3.conv2.post_context.bias, layer3.3.conv2.offset_s.weight, layer3.3.conv2.offset_s.bias, layer3.3.conv2.offset_l.weight, layer3.3.conv2.offset_l.bias, layer3.4.conv2.weight_diff, layer3.4.conv2.switch.weight, layer3.4.conv2.switch.bias, layer3.4.conv2.pre_context.weight, layer3.4.conv2.pre_context.bias, layer3.4.conv2.post_context.weight, layer3.4.conv2.post_context.bias, layer3.4.conv2.offset_s.weight, layer3.4.conv2.offset_s.bias, layer3.4.conv2.offset_l.weight, layer3.4.conv2.offset_l.bias, layer3.5.conv2.weight_diff, layer3.5.conv2.switch.weight, layer3.5.conv2.switch.bias, layer3.5.conv2.pre_context.weight, layer3.5.conv2.pre_context.bias, layer3.5.conv2.post_context.weight, layer3.5.conv2.post_context.bias, layer3.5.conv2.offset_s.weight, layer3.5.conv2.offset_s.bias, layer3.5.conv2.offset_l.weight, layer3.5.conv2.offset_l.bias, layer3.6.conv2.weight_diff, layer3.6.conv2.switch.weight, layer3.6.conv2.switch.bias, layer3.6.conv2.pre_context.weight, layer3.6.conv2.pre_context.bias, layer3.6.conv2.post_context.weight, layer3.6.conv2.post_context.bias, layer3.6.conv2.offset_s.weight, layer3.6.conv2.offset_s.bias, layer3.6.conv2.offset_l.weight, layer3.6.conv2.offset_l.bias, layer3.7.conv2.weight_diff, layer3.7.conv2.switch.weight, layer3.7.conv2.switch.bias, layer3.7.conv2.pre_context.weight, layer3.7.conv2.pre_context.bias, layer3.7.conv2.post_context.weight, layer3.7.conv2.post_context.bias, layer3.7.conv2.offset_s.weight, layer3.7.conv2.offset_s.bias, layer3.7.conv2.offset_l.weight, layer3.7.conv2.offset_l.bias, layer3.8.conv2.weight_diff, layer3.8.conv2.switch.weight, layer3.8.conv2.switch.bias, layer3.8.conv2.pre_context.weight, layer3.8.conv2.pre_context.bias, layer3.8.conv2.post_context.weight, layer3.8.conv2.post_context.bias, layer3.8.conv2.offset_s.weight, layer3.8.conv2.offset_s.bias, layer3.8.conv2.offset_l.weight, layer3.8.conv2.offset_l.bias, layer3.9.conv2.weight_diff, layer3.9.conv2.switch.weight, layer3.9.conv2.switch.bias, layer3.9.conv2.pre_context.weight, layer3.9.conv2.pre_context.bias, layer3.9.conv2.post_context.weight, layer3.9.conv2.post_context.bias, layer3.9.conv2.offset_s.weight, layer3.9.conv2.offset_s.bias, layer3.9.conv2.offset_l.weight, layer3.9.conv2.offset_l.bias, layer3.10.conv2.weight_diff, layer3.10.conv2.switch.weight, layer3.10.conv2.switch.bias, layer3.10.conv2.pre_context.weight, layer3.10.conv2.pre_context.bias, layer3.10.conv2.post_context.weight, layer3.10.conv2.post_context.bias, layer3.10.conv2.offset_s.weight, layer3.10.conv2.offset_s.bias, layer3.10.conv2.offset_l.weight, layer3.10.conv2.offset_l.bias, layer3.11.conv2.weight_diff, layer3.11.conv2.switch.weight, layer3.11.conv2.switch.bias, layer3.11.conv2.pre_context.weight, layer3.11.conv2.pre_context.bias, layer3.11.conv2.post_context.weight, layer3.11.conv2.post_context.bias, layer3.11.conv2.offset_s.weight, layer3.11.conv2.offset_s.bias, layer3.11.conv2.offset_l.weight, layer3.11.conv2.offset_l.bias, layer3.12.conv2.weight_diff, layer3.12.conv2.switch.weight, layer3.12.conv2.switch.bias, layer3.12.conv2.pre_context.weight, layer3.12.conv2.pre_context.bias, layer3.12.conv2.post_context.weight, layer3.12.conv2.post_context.bias, layer3.12.conv2.offset_s.weight, layer3.12.conv2.offset_s.bias, layer3.12.conv2.offset_l.weight, layer3.12.conv2.offset_l.bias, layer3.13.conv2.weight_diff, layer3.13.conv2.switch.weight, layer3.13.conv2.switch.bias, layer3.13.conv2.pre_context.weight, layer3.13.conv2.pre_context.bias, layer3.13.conv2.post_context.weight, layer3.13.conv2.post_context.bias, layer3.13.conv2.offset_s.weight, layer3.13.conv2.offset_s.bias, layer3.13.conv2.offset_l.weight, layer3.13.conv2.offset_l.bias, layer3.14.conv2.weight_diff, layer3.14.conv2.switch.weight, layer3.14.conv2.switch.bias, layer3.14.conv2.pre_context.weight, layer3.14.conv2.pre_context.bias, layer3.14.conv2.post_context.weight, layer3.14.conv2.post_context.bias, layer3.14.conv2.offset_s.weight, layer3.14.conv2.offset_s.bias, layer3.14.conv2.offset_l.weight, layer3.14.conv2.offset_l.bias, layer3.15.conv2.weight_diff, layer3.15.conv2.switch.weight, layer3.15.conv2.switch.bias, layer3.15.conv2.pre_context.weight, layer3.15.conv2.pre_context.bias, layer3.15.conv2.post_context.weight, layer3.15.conv2.post_context.bias, layer3.15.conv2.offset_s.weight, layer3.15.conv2.offset_s.bias, layer3.15.conv2.offset_l.weight, layer3.15.conv2.offset_l.bias, layer3.16.conv2.weight_diff, layer3.16.conv2.switch.weight, layer3.16.conv2.switch.bias, layer3.16.conv2.pre_context.weight, layer3.16.conv2.pre_context.bias, layer3.16.conv2.post_context.weight, layer3.16.conv2.post_context.bias, layer3.16.conv2.offset_s.weight, layer3.16.conv2.offset_s.bias, layer3.16.conv2.offset_l.weight, layer3.16.conv2.offset_l.bias, layer3.17.conv2.weight_diff, layer3.17.conv2.switch.weight, layer3.17.conv2.switch.bias, layer3.17.conv2.pre_context.weight, layer3.17.conv2.pre_context.bias, layer3.17.conv2.post_context.weight, layer3.17.conv2.post_context.bias, layer3.17.conv2.offset_s.weight, layer3.17.conv2.offset_s.bias, layer3.17.conv2.offset_l.weight, layer3.17.conv2.offset_l.bias, layer3.18.conv2.weight_diff, layer3.18.conv2.switch.weight, layer3.18.conv2.switch.bias, layer3.18.conv2.pre_context.weight, layer3.18.conv2.pre_context.bias, layer3.18.conv2.post_context.weight, layer3.18.conv2.post_context.bias, layer3.18.conv2.offset_s.weight, layer3.18.conv2.offset_s.bias, layer3.18.conv2.offset_l.weight, layer3.18.conv2.offset_l.bias, layer3.19.conv2.weight_diff, layer3.19.conv2.switch.weight, layer3.19.conv2.switch.bias, layer3.19.conv2.pre_context.weight, layer3.19.conv2.pre_context.bias, layer3.19.conv2.post_context.weight, layer3.19.conv2.post_context.bias, layer3.19.conv2.offset_s.weight, layer3.19.conv2.offset_s.bias, layer3.19.conv2.offset_l.weight, layer3.19.conv2.offset_l.bias, layer3.20.conv2.weight_diff, layer3.20.conv2.switch.weight, layer3.20.conv2.switch.bias, layer3.20.conv2.pre_context.weight, layer3.20.conv2.pre_context.bias, layer3.20.conv2.post_context.weight, layer3.20.conv2.post_context.bias, layer3.20.conv2.offset_s.weight, layer3.20.conv2.offset_s.bias, layer3.20.conv2.offset_l.weight, layer3.20.conv2.offset_l.bias, layer3.21.conv2.weight_diff, layer3.21.conv2.switch.weight, layer3.21.conv2.switch.bias, layer3.21.conv2.pre_context.weight, layer3.21.conv2.pre_context.bias, layer3.21.conv2.post_context.weight, layer3.21.conv2.post_context.bias, layer3.21.conv2.offset_s.weight, layer3.21.conv2.offset_s.bias, layer3.21.conv2.offset_l.weight, layer3.21.conv2.offset_l.bias, layer3.22.conv2.weight_diff, layer3.22.conv2.switch.weight, layer3.22.conv2.switch.bias, layer3.22.conv2.pre_context.weight, layer3.22.conv2.pre_context.bias, layer3.22.conv2.post_context.weight, layer3.22.conv2.post_context.bias, layer3.22.conv2.offset_s.weight, layer3.22.conv2.offset_s.bias, layer3.22.conv2.offset_l.weight, layer3.22.conv2.offset_l.bias, layer4.0.conv2.weight_diff, layer4.0.conv2.switch.weight, layer4.0.conv2.switch.bias, layer4.0.conv2.pre_context.weight, layer4.0.conv2.pre_context.bias, layer4.0.conv2.post_context.weight, layer4.0.conv2.post_context.bias, layer4.0.conv2.offset_s.weight, layer4.0.conv2.offset_s.bias, layer4.0.conv2.offset_l.weight, layer4.0.conv2.offset_l.bias, layer4.0.rfp_conv.weight, layer4.0.rfp_conv.bias, layer4.1.conv2.weight_diff, layer4.1.conv2.switch.weight, layer4.1.conv2.switch.bias, layer4.1.conv2.pre_context.weight, layer4.1.conv2.pre_context.bias, layer4.1.conv2.post_context.weight, layer4.1.conv2.post_context.bias, layer4.1.conv2.offset_s.weight, layer4.1.conv2.offset_s.bias, layer4.1.conv2.offset_l.weight, layer4.1.conv2.offset_l.bias, layer4.2.conv2.weight_diff, layer4.2.conv2.switch.weight, layer4.2.conv2.switch.bias, layer4.2.conv2.pre_context.weight, layer4.2.conv2.pre_context.bias, layer4.2.conv2.post_context.weight, layer4.2.conv2.post_context.bias, layer4.2.conv2.offset_s.weight, layer4.2.conv2.offset_s.bias, layer4.2.conv2.offset_l.weight, layer4.2.conv2.offset_l.bias\n",
            "\n",
            "Loads checkpoint by local backend from path: /content/drive/MyDrive/models/temp.pth\n",
            "09/21 15:30:13 - mmengine - INFO - Load checkpoint from /content/drive/MyDrive/models/temp.pth\n",
            "09/21 15:30:13 - mmengine - WARNING - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
            "09/21 15:30:13 - mmengine - WARNING - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
            "09/21 15:30:13 - mmengine - INFO - Checkpoints will be saved to /content/drive/MyDrive/C:\\Users\\HP\\mmdetection\\demo\\work_dir.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "09/21 15:50:03 - mmengine - INFO - Exp name: customconfig (2)_20230921_152913\n",
            "09/21 16:05:15 - mmengine - INFO - Exp name: customconfig (2)_20230921_152913\n",
            "09/21 16:05:15 - mmengine - INFO - Epoch(train)  [1][1774/1774]  lr: 5.0000e-03  eta: 5:15:14  time: 1.1847  data_time: 0.0186  memory: 5362  loss: 0.7353  loss_rpn_cls: 0.0094  loss_rpn_bbox: 0.0223  s0.loss_cls: 0.0762  s0.acc: 90.4297  s0.loss_bbox: 0.0565  s0.loss_mask: 0.2071  s1.loss_cls: 0.0323  s1.acc: 91.0417  s1.loss_bbox: 0.0851  s1.loss_mask: 0.1047  s2.loss_cls: 0.0188  s2.acc: 89.2784  s2.loss_bbox: 0.0711  s2.loss_mask: 0.0517\n",
            "09/21 16:05:15 - mmengine - INFO - Saving checkpoint at 1 epochs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/mmdetection/mmdet/models/roi_heads/mask_heads/fcn_mask_head.py:339: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
            "  mask_preds = bboxes.new_tensor(mask_preds)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "09/21 16:09:14 - mmengine - INFO - Evaluating bbox...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.30s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=2.02s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.93s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.337\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.586\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.349\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.138\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.325\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.376\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.491\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.491\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.491\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.198\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.496\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.494\n",
            "09/21 16:09:17 - mmengine - INFO - bbox_mAP_copypaste: 0.337 0.586 0.349 0.138 0.325 0.376\n",
            "09/21 16:09:17 - mmengine - INFO - Evaluating segm...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.25s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=1.71s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.52s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.321\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.575\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.336\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.089\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.316\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.351\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.459\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.459\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.459\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.175\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.473\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.428\n",
            "09/21 16:09:20 - mmengine - INFO - segm_mAP_copypaste: 0.321 0.575 0.336 0.089 0.316 0.351\n",
            "09/21 16:09:20 - mmengine - INFO - Epoch(val) [1][336/336]    coco/bbox_mAP: 0.3370  coco/bbox_mAP_50: 0.5860  coco/bbox_mAP_75: 0.3490  coco/bbox_mAP_s: 0.1380  coco/bbox_mAP_m: 0.3250  coco/bbox_mAP_l: 0.3760  coco/segm_mAP: 0.3210  coco/segm_mAP_50: 0.5750  coco/segm_mAP_75: 0.3360  coco/segm_mAP_s: 0.0890  coco/segm_mAP_m: 0.3160  coco/segm_mAP_l: 0.3510  data_time: 0.0936  time: 0.6588\n",
            "09/21 16:13:45 - mmengine - INFO - Exp name: customconfig (2)_20230921_152913\n",
            "09/21 16:33:38 - mmengine - INFO - Exp name: customconfig (2)_20230921_152913\n",
            "09/21 16:44:28 - mmengine - INFO - Exp name: customconfig (2)_20230921_152913\n",
            "09/21 16:44:28 - mmengine - INFO - Epoch(train)  [2][1774/1774]  lr: 5.0000e-03  eta: 4:40:39  time: 1.1884  data_time: 0.0179  memory: 5361  loss: 0.6970  loss_rpn_cls: 0.0080  loss_rpn_bbox: 0.0219  s0.loss_cls: 0.0684  s0.acc: 94.5312  s0.loss_bbox: 0.0522  s0.loss_mask: 0.2007  s1.loss_cls: 0.0286  s1.acc: 95.0884  s1.loss_bbox: 0.0794  s1.loss_mask: 0.1019  s2.loss_cls: 0.0167  s2.acc: 94.0476  s2.loss_bbox: 0.0687  s2.loss_mask: 0.0505\n",
            "09/21 16:44:28 - mmengine - INFO - Saving checkpoint at 2 epochs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/mmdetection/mmdet/models/roi_heads/mask_heads/fcn_mask_head.py:339: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
            "  mask_preds = bboxes.new_tensor(mask_preds)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "09/21 16:48:30 - mmengine - INFO - Evaluating bbox...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.76s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.77s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.364\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.614\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.379\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.151\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.358\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.387\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.536\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.536\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.536\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.208\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.539\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.556\n",
            "09/21 16:48:32 - mmengine - INFO - bbox_mAP_copypaste: 0.364 0.614 0.379 0.151 0.358 0.387\n",
            "09/21 16:48:32 - mmengine - INFO - Evaluating segm...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.23s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=2.15s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.75s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.342\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.602\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.377\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.094\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.351\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.366\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.497\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.497\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.497\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.190\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.511\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.492\n",
            "09/21 16:48:36 - mmengine - INFO - segm_mAP_copypaste: 0.342 0.602 0.377 0.094 0.351 0.366\n",
            "09/21 16:48:36 - mmengine - INFO - Epoch(val) [2][336/336]    coco/bbox_mAP: 0.3640  coco/bbox_mAP_50: 0.6140  coco/bbox_mAP_75: 0.3790  coco/bbox_mAP_s: 0.1510  coco/bbox_mAP_m: 0.3580  coco/bbox_mAP_l: 0.3870  coco/segm_mAP: 0.3420  coco/segm_mAP_50: 0.6020  coco/segm_mAP_75: 0.3770  coco/segm_mAP_s: 0.0940  coco/segm_mAP_m: 0.3510  coco/segm_mAP_l: 0.3660  data_time: 0.0752  time: 0.6762\n",
            "09/21 16:57:29 - mmengine - INFO - Exp name: customconfig (2)_20230921_152913\n",
            "09/21 17:17:26 - mmengine - INFO - Exp name: customconfig (2)_20230921_152913\n",
            "09/21 17:23:51 - mmengine - INFO - Exp name: customconfig (2)_20230921_152913\n",
            "09/21 17:23:51 - mmengine - INFO - Epoch(train)  [3][1774/1774]  lr: 5.0000e-03  eta: 4:05:57  time: 1.1921  data_time: 0.0184  memory: 5361  loss: 0.6632  loss_rpn_cls: 0.0067  loss_rpn_bbox: 0.0207  s0.loss_cls: 0.0641  s0.acc: 96.8750  s0.loss_bbox: 0.0488  s0.loss_mask: 0.1936  s1.loss_cls: 0.0258  s1.acc: 98.2759  s1.loss_bbox: 0.0748  s1.loss_mask: 0.0983  s2.loss_cls: 0.0153  s2.acc: 97.3742  s2.loss_bbox: 0.0662  s2.loss_mask: 0.0488\n",
            "09/21 17:23:51 - mmengine - INFO - Saving checkpoint at 3 epochs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/mmdetection/mmdet/models/roi_heads/mask_heads/fcn_mask_head.py:339: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
            "  mask_preds = bboxes.new_tensor(mask_preds)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "09/21 17:27:33 - mmengine - INFO - Evaluating bbox...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.30s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.66s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.363\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.625\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.383\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.119\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.368\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.370\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.521\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.521\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.521\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.158\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.519\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.512\n",
            "09/21 17:27:35 - mmengine - INFO - bbox_mAP_copypaste: 0.363 0.625 0.383 0.119 0.368 0.370\n",
            "09/21 17:27:35 - mmengine - INFO - Evaluating segm...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.33s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=2.91s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=1.17s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.350\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.622\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.374\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.080\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.364\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.360\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.493\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.493\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.493\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.152\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.501\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.464\n",
            "09/21 17:27:40 - mmengine - INFO - segm_mAP_copypaste: 0.350 0.622 0.374 0.080 0.364 0.360\n",
            "09/21 17:27:41 - mmengine - INFO - Epoch(val) [3][336/336]    coco/bbox_mAP: 0.3630  coco/bbox_mAP_50: 0.6250  coco/bbox_mAP_75: 0.3830  coco/bbox_mAP_s: 0.1190  coco/bbox_mAP_m: 0.3680  coco/bbox_mAP_l: 0.3700  coco/segm_mAP: 0.3500  coco/segm_mAP_50: 0.6220  coco/segm_mAP_75: 0.3740  coco/segm_mAP_s: 0.0800  coco/segm_mAP_m: 0.3640  coco/segm_mAP_l: 0.3600  data_time: 0.0730  time: 0.6361\n",
            "09/21 17:41:07 - mmengine - INFO - Exp name: customconfig (2)_20230921_152913\n",
            "09/21 18:00:56 - mmengine - INFO - Exp name: customconfig (2)_20230921_152913\n",
            "09/21 18:02:50 - mmengine - INFO - Exp name: customconfig (2)_20230921_152913\n",
            "09/21 18:02:50 - mmengine - INFO - Epoch(train)  [4][1774/1774]  lr: 5.0000e-03  eta: 3:30:50  time: 1.1891  data_time: 0.0174  memory: 5362  loss: 0.6297  loss_rpn_cls: 0.0059  loss_rpn_bbox: 0.0197  s0.loss_cls: 0.0580  s0.acc: 97.4609  s0.loss_bbox: 0.0445  s0.loss_mask: 0.1885  s1.loss_cls: 0.0230  s1.acc: 98.2721  s1.loss_bbox: 0.0697  s1.loss_mask: 0.0961  s2.loss_cls: 0.0135  s2.acc: 99.0909  s2.loss_bbox: 0.0628  s2.loss_mask: 0.0480\n",
            "09/21 18:02:50 - mmengine - INFO - Saving checkpoint at 4 epochs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/mmdetection/mmdet/models/roi_heads/mask_heads/fcn_mask_head.py:339: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
            "  mask_preds = bboxes.new_tensor(mask_preds)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "09/21 18:06:25 - mmengine - INFO - Evaluating bbox...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.25s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.58s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.367\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.620\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.391\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.135\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.358\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.413\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.523\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.523\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.523\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.184\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.516\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.593\n",
            "09/21 18:06:26 - mmengine - INFO - bbox_mAP_copypaste: 0.367 0.620 0.391 0.135 0.358 0.413\n",
            "09/21 18:06:26 - mmengine - INFO - Evaluating segm...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.16s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=1.51s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.58s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.338\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.611\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.364\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.095\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.333\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.383\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.484\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.484\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.484\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.179\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.484\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.513\n",
            "09/21 18:06:29 - mmengine - INFO - segm_mAP_copypaste: 0.338 0.611 0.364 0.095 0.333 0.383\n",
            "09/21 18:06:29 - mmengine - INFO - Epoch(val) [4][336/336]    coco/bbox_mAP: 0.3670  coco/bbox_mAP_50: 0.6200  coco/bbox_mAP_75: 0.3910  coco/bbox_mAP_s: 0.1350  coco/bbox_mAP_m: 0.3580  coco/bbox_mAP_l: 0.4130  coco/segm_mAP: 0.3380  coco/segm_mAP_50: 0.6110  coco/segm_mAP_75: 0.3640  coco/segm_mAP_s: 0.0950  coco/segm_mAP_m: 0.3330  coco/segm_mAP_l: 0.3830  data_time: 0.0750  time: 0.6119\n",
            "09/21 18:24:19 - mmengine - INFO - Exp name: customconfig (2)_20230921_152913\n",
            "09/21 18:41:38 - mmengine - INFO - Exp name: customconfig (2)_20230921_152913\n",
            "09/21 18:41:38 - mmengine - INFO - Epoch(train)  [5][1774/1774]  lr: 5.0000e-03  eta: 2:55:42  time: 1.1887  data_time: 0.0171  memory: 5361  loss: 0.5871  loss_rpn_cls: 0.0050  loss_rpn_bbox: 0.0183  s0.loss_cls: 0.0527  s0.acc: 97.2656  s0.loss_bbox: 0.0395  s0.loss_mask: 0.1802  s1.loss_cls: 0.0200  s1.acc: 98.2906  s1.loss_bbox: 0.0631  s1.loss_mask: 0.0921  s2.loss_cls: 0.0118  s2.acc: 97.5556  s2.loss_bbox: 0.0582  s2.loss_mask: 0.0461\n",
            "09/21 18:41:38 - mmengine - INFO - Saving checkpoint at 5 epochs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/mmdetection/mmdet/models/roi_heads/mask_heads/fcn_mask_head.py:339: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
            "  mask_preds = bboxes.new_tensor(mask_preds)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "09/21 18:45:13 - mmengine - INFO - Evaluating bbox...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=2.19s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.84s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.355\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.601\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.357\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.105\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.347\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.380\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.495\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.495\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.495\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.143\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.503\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.483\n",
            "09/21 18:45:16 - mmengine - INFO - bbox_mAP_copypaste: 0.355 0.601 0.357 0.105 0.347 0.380\n",
            "09/21 18:45:16 - mmengine - INFO - Evaluating segm...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.20s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=2.09s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.47s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.340\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.597\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.349\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.099\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.337\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.359\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.466\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.466\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.466\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.140\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.480\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.436\n",
            "09/21 18:45:19 - mmengine - INFO - segm_mAP_copypaste: 0.340 0.597 0.349 0.099 0.337 0.359\n",
            "09/21 18:45:19 - mmengine - INFO - Epoch(val) [5][336/336]    coco/bbox_mAP: 0.3550  coco/bbox_mAP_50: 0.6010  coco/bbox_mAP_75: 0.3570  coco/bbox_mAP_s: 0.1050  coco/bbox_mAP_m: 0.3470  coco/bbox_mAP_l: 0.3800  coco/segm_mAP: 0.3400  coco/segm_mAP_50: 0.5970  coco/segm_mAP_75: 0.3490  coco/segm_mAP_s: 0.0990  coco/segm_mAP_m: 0.3370  coco/segm_mAP_l: 0.3590  data_time: 0.0742  time: 0.5611\n",
            "09/21 18:47:52 - mmengine - INFO - Exp name: customconfig (2)_20230921_152913\n",
            "09/21 19:07:41 - mmengine - INFO - Exp name: customconfig (2)_20230921_152913\n",
            "09/21 19:20:31 - mmengine - INFO - Exp name: customconfig (2)_20230921_152913\n",
            "09/21 19:20:31 - mmengine - INFO - Epoch(train)  [6][1774/1774]  lr: 5.0000e-03  eta: 2:20:36  time: 1.1904  data_time: 0.0173  memory: 5361  loss: 0.5502  loss_rpn_cls: 0.0047  loss_rpn_bbox: 0.0172  s0.loss_cls: 0.0480  s0.acc: 95.8984  s0.loss_bbox: 0.0355  s0.loss_mask: 0.1737  s1.loss_cls: 0.0174  s1.acc: 98.6364  s1.loss_bbox: 0.0567  s1.loss_mask: 0.0888  s2.loss_cls: 0.0102  s2.acc: 97.6077  s2.loss_bbox: 0.0532  s2.loss_mask: 0.0446\n",
            "09/21 19:20:31 - mmengine - INFO - Saving checkpoint at 6 epochs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/mmdetection/mmdet/models/roi_heads/mask_heads/fcn_mask_head.py:339: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
            "  mask_preds = bboxes.new_tensor(mask_preds)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "09/21 19:24:03 - mmengine - INFO - Evaluating bbox...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.87s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.48s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.371\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.619\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.389\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.130\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.358\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.413\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.497\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.497\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.497\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.157\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.498\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.511\n",
            "09/21 19:24:06 - mmengine - INFO - bbox_mAP_copypaste: 0.371 0.619 0.389 0.130 0.358 0.413\n",
            "09/21 19:24:06 - mmengine - INFO - Evaluating segm...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.12s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=1.28s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.69s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.347\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.609\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.368\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.082\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.337\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.374\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.459\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.459\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.459\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.146\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.470\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.442\n",
            "09/21 19:24:08 - mmengine - INFO - segm_mAP_copypaste: 0.347 0.609 0.368 0.082 0.337 0.374\n",
            "09/21 19:24:08 - mmengine - INFO - Epoch(val) [6][336/336]    coco/bbox_mAP: 0.3710  coco/bbox_mAP_50: 0.6190  coco/bbox_mAP_75: 0.3890  coco/bbox_mAP_s: 0.1300  coco/bbox_mAP_m: 0.3580  coco/bbox_mAP_l: 0.4130  coco/segm_mAP: 0.3470  coco/segm_mAP_50: 0.6090  coco/segm_mAP_75: 0.3680  coco/segm_mAP_s: 0.0820  coco/segm_mAP_m: 0.3370  coco/segm_mAP_l: 0.3740  data_time: 0.0746  time: 0.5666\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n",
            "Custom TB Handler failed, unregistering\n",
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n",
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n",
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-1-2bedb0d976c8>\", line 9, in <cell line: 9>\n",
            "    runner.train()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/runner/runner.py\", line 1745, in train\n",
            "    model = self.train_loop.run()  # type: ignore\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/runner/loops.py\", line 96, in run\n",
            "    self.run_epoch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/runner/loops.py\", line 111, in run_epoch\n",
            "    for idx, data_batch in enumerate(self.dataloader):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 633, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1325, in _next_data\n",
            "    return self._process_data(data)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1371, in _process_data\n",
            "    data.reraise()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_utils.py\", line 644, in reraise\n",
            "    raise exception\n",
            "FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 2.\n",
            "Original Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n",
            "    data = fetcher.fetch(index)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/dataset/base_dataset.py\", line 408, in __getitem__\n",
            "    data = self.prepare_data(idx)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/dataset/base_dataset.py\", line 790, in prepare_data\n",
            "    return self.pipeline(data_info)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/dataset/base_dataset.py\", line 58, in __call__\n",
            "    data = t(data)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmcv/transforms/base.py\", line 12, in __call__\n",
            "    return self.transform(results)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmcv/transforms/loading.py\", line 107, in transform\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmcv/transforms/loading.py\", line 99, in transform\n",
            "    img_bytes = fileio.get(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/fileio/io.py\", line 181, in get\n",
            "    return backend.get(filepath)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/fileio/backends/local_backend.py\", line 33, in get\n",
            "    with open(filepath, 'rb') as f:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/data/diagnosis/train/576w_jpg.rf.5eeab3d4c6b9bb82a265e3eef9de6d73.jpg'\n",
            "\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n",
            "    module = getmodule(object, filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 861, in getmodule\n",
            "    file = getabsfile(object, _filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 845, in getabsfile\n",
            "    return os.path.normcase(os.path.abspath(_filename))\n",
            "  File \"/usr/lib/python3.10/posixpath.py\", line 384, in abspath\n",
            "    cwd = os.getcwd()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-1-2bedb0d976c8>\", line 9, in <cell line: 9>\n",
            "    runner.train()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/runner/runner.py\", line 1745, in train\n",
            "    model = self.train_loop.run()  # type: ignore\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/runner/loops.py\", line 96, in run\n",
            "    self.run_epoch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/runner/loops.py\", line 111, in run_epoch\n",
            "    for idx, data_batch in enumerate(self.dataloader):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 633, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1325, in _next_data\n",
            "    return self._process_data(data)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1371, in _process_data\n",
            "    data.reraise()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_utils.py\", line 644, in reraise\n",
            "    raise exception\n",
            "FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 2.\n",
            "Original Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n",
            "    data = fetcher.fetch(index)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/dataset/base_dataset.py\", line 408, in __getitem__\n",
            "    data = self.prepare_data(idx)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/dataset/base_dataset.py\", line 790, in prepare_data\n",
            "    return self.pipeline(data_info)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/dataset/base_dataset.py\", line 58, in __call__\n",
            "    data = t(data)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmcv/transforms/base.py\", line 12, in __call__\n",
            "    return self.transform(results)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmcv/transforms/loading.py\", line 107, in transform\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmcv/transforms/loading.py\", line 99, in transform\n",
            "    img_bytes = fileio.get(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/fileio/io.py\", line 181, in get\n",
            "    return backend.get(filepath)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/fileio/backends/local_backend.py\", line 33, in get\n",
            "    with open(filepath, 'rb') as f:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/data/diagnosis/train/576w_jpg.rf.5eeab3d4c6b9bb82a265e3eef9de6d73.jpg'\n",
            "\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 1972, in wrapped\n",
            "    stb = handler(self,etype,value,tb,tb_offset=tb_offset)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/dask/base.py\", line 79, in _clean_ipython_traceback\n",
            "    stb = self.InteractiveTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n",
            "    return FormattedTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n",
            "    return VerboseTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1124, in structured_traceback\n",
            "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
            "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
            "    return len(records), 0\n",
            "TypeError: object of type 'NoneType' has no len()\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n",
            "    module = getmodule(object, filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 861, in getmodule\n",
            "    file = getabsfile(object, _filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 845, in getabsfile\n",
            "    return os.path.normcase(os.path.abspath(_filename))\n",
            "  File \"/usr/lib/python3.10/posixpath.py\", line 384, in abspath\n",
            "    cwd = os.getcwd()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-1-2bedb0d976c8>\", line 9, in <cell line: 9>\n",
            "    runner.train()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/runner/runner.py\", line 1745, in train\n",
            "    model = self.train_loop.run()  # type: ignore\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/runner/loops.py\", line 96, in run\n",
            "    self.run_epoch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/runner/loops.py\", line 111, in run_epoch\n",
            "    for idx, data_batch in enumerate(self.dataloader):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 633, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1325, in _next_data\n",
            "    return self._process_data(data)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1371, in _process_data\n",
            "    data.reraise()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_utils.py\", line 644, in reraise\n",
            "    raise exception\n",
            "FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 2.\n",
            "Original Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n",
            "    data = fetcher.fetch(index)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/dataset/base_dataset.py\", line 408, in __getitem__\n",
            "    data = self.prepare_data(idx)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/dataset/base_dataset.py\", line 790, in prepare_data\n",
            "    return self.pipeline(data_info)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/dataset/base_dataset.py\", line 58, in __call__\n",
            "    data = t(data)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmcv/transforms/base.py\", line 12, in __call__\n",
            "    return self.transform(results)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmcv/transforms/loading.py\", line 107, in transform\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmcv/transforms/loading.py\", line 99, in transform\n",
            "    img_bytes = fileio.get(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/fileio/io.py\", line 181, in get\n",
            "    return backend.get(filepath)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/fileio/backends/local_backend.py\", line 33, in get\n",
            "    with open(filepath, 'rb') as f:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/data/diagnosis/train/576w_jpg.rf.5eeab3d4c6b9bb82a265e3eef9de6d73.jpg'\n",
            "\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 1972, in wrapped\n",
            "    stb = handler(self,etype,value,tb,tb_offset=tb_offset)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/dask/base.py\", line 79, in _clean_ipython_traceback\n",
            "    stb = self.InteractiveTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n",
            "    return FormattedTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n",
            "    return VerboseTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1124, in structured_traceback\n",
            "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
            "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
            "    return len(records), 0\n",
            "TypeError: object of type 'NoneType' has no len()\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n",
            "    if (await self.run_code(code, result,  async_=asy)):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3571, in run_code\n",
            "    self.CustomTB(etype, value, tb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 1979, in wrapped\n",
            "    stb = self.InteractiveTB.structured_traceback(*sys.exc_info())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n",
            "    return FormattedTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n",
            "    return VerboseTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1142, in structured_traceback\n",
            "    formatted_exceptions += self.format_exception_as_a_whole(etype, evalue, etb, lines_of_context,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
            "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
            "    return len(records), 0\n",
            "TypeError: object of type 'NoneType' has no len()\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n",
            "    module = getmodule(object, filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 861, in getmodule\n",
            "    file = getabsfile(object, _filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 845, in getabsfile\n",
            "    return os.path.normcase(os.path.abspath(_filename))\n",
            "  File \"/usr/lib/python3.10/posixpath.py\", line 384, in abspath\n",
            "    cwd = os.getcwd()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-1-2bedb0d976c8>\", line 9, in <cell line: 9>\n",
            "    runner.train()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/runner/runner.py\", line 1745, in train\n",
            "    model = self.train_loop.run()  # type: ignore\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/runner/loops.py\", line 96, in run\n",
            "    self.run_epoch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/runner/loops.py\", line 111, in run_epoch\n",
            "    for idx, data_batch in enumerate(self.dataloader):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 633, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1325, in _next_data\n",
            "    return self._process_data(data)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1371, in _process_data\n",
            "    data.reraise()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_utils.py\", line 644, in reraise\n",
            "    raise exception\n",
            "FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 2.\n",
            "Original Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n",
            "    data = fetcher.fetch(index)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/dataset/base_dataset.py\", line 408, in __getitem__\n",
            "    data = self.prepare_data(idx)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/dataset/base_dataset.py\", line 790, in prepare_data\n",
            "    return self.pipeline(data_info)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/dataset/base_dataset.py\", line 58, in __call__\n",
            "    data = t(data)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmcv/transforms/base.py\", line 12, in __call__\n",
            "    return self.transform(results)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmcv/transforms/loading.py\", line 107, in transform\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmcv/transforms/loading.py\", line 99, in transform\n",
            "    img_bytes = fileio.get(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/fileio/io.py\", line 181, in get\n",
            "    return backend.get(filepath)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/fileio/backends/local_backend.py\", line 33, in get\n",
            "    with open(filepath, 'rb') as f:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/data/diagnosis/train/576w_jpg.rf.5eeab3d4c6b9bb82a265e3eef9de6d73.jpg'\n",
            "\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 1972, in wrapped\n",
            "    stb = handler(self,etype,value,tb,tb_offset=tb_offset)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/dask/base.py\", line 79, in _clean_ipython_traceback\n",
            "    stb = self.InteractiveTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n",
            "    return FormattedTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n",
            "    return VerboseTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1124, in structured_traceback\n",
            "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
            "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
            "    return len(records), 0\n",
            "TypeError: object of type 'NoneType' has no len()\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n",
            "    if (await self.run_code(code, result,  async_=asy)):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3571, in run_code\n",
            "    self.CustomTB(etype, value, tb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 1979, in wrapped\n",
            "    stb = self.InteractiveTB.structured_traceback(*sys.exc_info())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n",
            "    return FormattedTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n",
            "    return VerboseTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1142, in structured_traceback\n",
            "    formatted_exceptions += self.format_exception_as_a_whole(etype, evalue, etb, lines_of_context,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
            "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
            "    return len(records), 0\n",
            "TypeError: object of type 'NoneType' has no len()\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n",
            "    return runner(coro)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n",
            "    coro.send(None)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n",
            "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3492, in run_ast_nodes\n",
            "    self.showtraceback()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n",
            "    stb = self.InteractiveTB.structured_traceback(etype,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n",
            "    return FormattedTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n",
            "    return VerboseTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1142, in structured_traceback\n",
            "    formatted_exceptions += self.format_exception_as_a_whole(etype, evalue, etb, lines_of_context,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
            "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
            "    return len(records), 0\n",
            "TypeError: object of type 'NoneType' has no len()\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n",
            "    module = getmodule(object, filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 861, in getmodule\n",
            "    file = getabsfile(object, _filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 845, in getabsfile\n",
            "    return os.path.normcase(os.path.abspath(_filename))\n",
            "  File \"/usr/lib/python3.10/posixpath.py\", line 384, in abspath\n",
            "    cwd = os.getcwd()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n"
          ]
        }
      ],
      "source": [
        "from mmengine import Config\n",
        "\n",
        "cfg = Config.fromfile('/content/drive/MyDrive/models/customconfig (2).py')\n",
        "cfg['load_from']=r'/content/drive/MyDrive/models/temp.pth'\n",
        "%cd /content/drive/MyDrive\n",
        "\n",
        "from mmengine.runner import Runner\n",
        "runner = Runner.from_cfg(cfg)\n",
        "runner.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hBlRhelhzxuJ",
        "outputId": "7b84b9ae-ef6e-4d7a-dc7c-09457b83412e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive\n",
            "09/25 14:48:43 - mmengine - INFO - \n",
            "------------------------------------------------------------\n",
            "System environment:\n",
            "    sys.platform: linux\n",
            "    Python: 3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0]\n",
            "    CUDA available: True\n",
            "    numpy_random_seed: 695506343\n",
            "    GPU 0: Tesla T4\n",
            "    CUDA_HOME: /usr/local/cuda\n",
            "    NVCC: Cuda compilation tools, release 11.8, V11.8.89\n",
            "    GCC: x86_64-linux-gnu-gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
            "    PyTorch: 2.0.1+cu118\n",
            "    PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 9.3\n",
            "  - C++ Version: 201703\n",
            "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 11.8\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
            "  - CuDNN 8.7\n",
            "  - Magma 2.6.1\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "    TorchVision: 0.15.2+cu118\n",
            "    OpenCV: 4.8.0\n",
            "    MMEngine: 0.8.5\n",
            "\n",
            "Runtime environment:\n",
            "    cudnn_benchmark: False\n",
            "    dist_cfg: {'backend': 'nccl'}\n",
            "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
            "    seed: 695506343\n",
            "    Distributed launcher: none\n",
            "    Distributed training: False\n",
            "    GPU number: 1\n",
            "------------------------------------------------------------\n",
            "\n",
            "09/25 14:48:44 - mmengine - INFO - Config:\n",
            "auto_scale_lr = dict(base_batch_size=16, enable=False)\n",
            "backend_args = None\n",
            "classes = (\n",
            "    'Bdr',\n",
            "    'Bone Loss',\n",
            "    'Bridge',\n",
            "    'Caries',\n",
            "    'Crown',\n",
            "    'Filling',\n",
            "    'Impaction',\n",
            "    'Implant',\n",
            "    'Periapical Abscess',\n",
            "    'Rct',\n",
            "    'Rct +Post',\n",
            "    'Retentive Pin',\n",
            "    'Shadow',\n",
            "    'Splinted Crowns',\n",
            "    'Unerupted',\n",
            ")\n",
            "data_root = 'data/diagnosis'\n",
            "dataset_type = 'DiagnosisDataset'\n",
            "default_hooks = dict(\n",
            "    checkpoint=dict(interval=1, type='CheckpointHook'),\n",
            "    logger=dict(interval=1774, type='LoggerHook'),\n",
            "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    timer=dict(type='IterTimerHook'),\n",
            "    visualization=dict(type='DetVisualizationHook'))\n",
            "default_scope = 'mmdet'\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=False,\n",
            "    dist_cfg=dict(backend='nccl'),\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
            "load_from = '/content/drive/MyDrive/C:\\\\Users\\\\HP\\\\mmdetection\\\\demo\\\\work_dir/temp.pth'\n",
            "log_level = 'INFO'\n",
            "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=1774)\n",
            "lr_config = dict(step=[\n",
            "    25,\n",
            "    30,\n",
            "])\n",
            "max_epochs = 20\n",
            "model = dict(\n",
            "    backbone=dict(\n",
            "        conv_cfg=dict(type='ConvAWS'),\n",
            "        depth=101,\n",
            "        frozen_stages=4,\n",
            "        init_cfg=dict(checkpoint='torchvision://resnet101', type='Pretrained'),\n",
            "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "        norm_eval=True,\n",
            "        num_stages=4,\n",
            "        out_indices=(\n",
            "            0,\n",
            "            1,\n",
            "            2,\n",
            "            3,\n",
            "        ),\n",
            "        output_img=True,\n",
            "        sac=dict(type='SAC', use_deform=True),\n",
            "        stage_with_sac=(\n",
            "            False,\n",
            "            True,\n",
            "            True,\n",
            "            True,\n",
            "        ),\n",
            "        style='pytorch',\n",
            "        type='DetectoRS_ResNet'),\n",
            "    data_preprocessor=dict(\n",
            "        bgr_to_rgb=True,\n",
            "        mean=[\n",
            "            123.675,\n",
            "            116.28,\n",
            "            103.53,\n",
            "        ],\n",
            "        pad_seg=True,\n",
            "        pad_size_divisor=32,\n",
            "        std=[\n",
            "            58.395,\n",
            "            57.12,\n",
            "            57.375,\n",
            "        ],\n",
            "        type='DetDataPreprocessor'),\n",
            "    neck=dict(\n",
            "        aspp_dilations=(\n",
            "            1,\n",
            "            3,\n",
            "            6,\n",
            "            1,\n",
            "        ),\n",
            "        aspp_out_channels=64,\n",
            "        in_channels=[\n",
            "            256,\n",
            "            512,\n",
            "            1024,\n",
            "            2048,\n",
            "        ],\n",
            "        num_outs=5,\n",
            "        out_channels=256,\n",
            "        rfp_backbone=dict(\n",
            "            conv_cfg=dict(type='ConvAWS'),\n",
            "            depth=101,\n",
            "            frozen_stages=1,\n",
            "            norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "            norm_eval=True,\n",
            "            num_stages=4,\n",
            "            out_indices=(\n",
            "                0,\n",
            "                1,\n",
            "                2,\n",
            "                3,\n",
            "            ),\n",
            "            pretrained='torchvision://resnet101',\n",
            "            rfp_inplanes=256,\n",
            "            sac=dict(type='SAC', use_deform=True),\n",
            "            stage_with_sac=(\n",
            "                False,\n",
            "                True,\n",
            "                True,\n",
            "                True,\n",
            "            ),\n",
            "            style='pytorch',\n",
            "            type='DetectoRS_ResNet'),\n",
            "        rfp_steps=2,\n",
            "        type='RFP'),\n",
            "    roi_head=dict(\n",
            "        bbox_head=[\n",
            "            dict(\n",
            "                bbox_coder=dict(\n",
            "                    target_means=[\n",
            "                        0.0,\n",
            "                        0.0,\n",
            "                        0.0,\n",
            "                        0.0,\n",
            "                    ],\n",
            "                    target_stds=[\n",
            "                        0.1,\n",
            "                        0.1,\n",
            "                        0.2,\n",
            "                        0.2,\n",
            "                    ],\n",
            "                    type='DeltaXYWHBBoxCoder'),\n",
            "                fc_out_channels=1024,\n",
            "                in_channels=256,\n",
            "                loss_bbox=dict(beta=1.0, loss_weight=1.0, type='SmoothL1Loss'),\n",
            "                loss_cls=dict(\n",
            "                    loss_weight=1.0,\n",
            "                    type='CrossEntropyLoss',\n",
            "                    use_sigmoid=False),\n",
            "                num_classes=15,\n",
            "                reg_class_agnostic=True,\n",
            "                roi_feat_size=7,\n",
            "                type='Shared2FCBBoxHead'),\n",
            "            dict(\n",
            "                bbox_coder=dict(\n",
            "                    target_means=[\n",
            "                        0.0,\n",
            "                        0.0,\n",
            "                        0.0,\n",
            "                        0.0,\n",
            "                    ],\n",
            "                    target_stds=[\n",
            "                        0.05,\n",
            "                        0.05,\n",
            "                        0.1,\n",
            "                        0.1,\n",
            "                    ],\n",
            "                    type='DeltaXYWHBBoxCoder'),\n",
            "                fc_out_channels=1024,\n",
            "                in_channels=256,\n",
            "                loss_bbox=dict(beta=1.0, loss_weight=1.0, type='SmoothL1Loss'),\n",
            "                loss_cls=dict(\n",
            "                    loss_weight=1.0,\n",
            "                    type='CrossEntropyLoss',\n",
            "                    use_sigmoid=False),\n",
            "                num_classes=15,\n",
            "                reg_class_agnostic=True,\n",
            "                roi_feat_size=7,\n",
            "                type='Shared2FCBBoxHead'),\n",
            "            dict(\n",
            "                bbox_coder=dict(\n",
            "                    target_means=[\n",
            "                        0.0,\n",
            "                        0.0,\n",
            "                        0.0,\n",
            "                        0.0,\n",
            "                    ],\n",
            "                    target_stds=[\n",
            "                        0.033,\n",
            "                        0.033,\n",
            "                        0.067,\n",
            "                        0.067,\n",
            "                    ],\n",
            "                    type='DeltaXYWHBBoxCoder'),\n",
            "                fc_out_channels=1024,\n",
            "                in_channels=256,\n",
            "                loss_bbox=dict(beta=1.0, loss_weight=1.0, type='SmoothL1Loss'),\n",
            "                loss_cls=dict(\n",
            "                    loss_weight=1.0,\n",
            "                    type='CrossEntropyLoss',\n",
            "                    use_sigmoid=False),\n",
            "                num_classes=15,\n",
            "                reg_class_agnostic=True,\n",
            "                roi_feat_size=7,\n",
            "                type='Shared2FCBBoxHead'),\n",
            "        ],\n",
            "        bbox_roi_extractor=dict(\n",
            "            featmap_strides=[\n",
            "                4,\n",
            "                8,\n",
            "                16,\n",
            "                32,\n",
            "            ],\n",
            "            out_channels=256,\n",
            "            roi_layer=dict(output_size=7, sampling_ratio=0, type='RoIAlign'),\n",
            "            type='SingleRoIExtractor'),\n",
            "        interleaved=True,\n",
            "        mask_head=[\n",
            "            dict(\n",
            "                conv_out_channels=256,\n",
            "                in_channels=256,\n",
            "                loss_mask=dict(\n",
            "                    loss_weight=1.0, type='CrossEntropyLoss', use_mask=True),\n",
            "                num_classes=80,\n",
            "                num_convs=4,\n",
            "                type='HTCMaskHead',\n",
            "                with_conv_res=False),\n",
            "            dict(\n",
            "                conv_out_channels=256,\n",
            "                in_channels=256,\n",
            "                loss_mask=dict(\n",
            "                    loss_weight=1.0, type='CrossEntropyLoss', use_mask=True),\n",
            "                num_classes=15,\n",
            "                num_convs=4,\n",
            "                type='HTCMaskHead'),\n",
            "            dict(\n",
            "                conv_out_channels=256,\n",
            "                in_channels=256,\n",
            "                loss_mask=dict(\n",
            "                    loss_weight=1.0, type='CrossEntropyLoss', use_mask=True),\n",
            "                num_classes=15,\n",
            "                num_convs=4,\n",
            "                type='HTCMaskHead'),\n",
            "        ],\n",
            "        mask_info_flow=True,\n",
            "        mask_roi_extractor=dict(\n",
            "            featmap_strides=[\n",
            "                4,\n",
            "                8,\n",
            "                16,\n",
            "                32,\n",
            "            ],\n",
            "            out_channels=256,\n",
            "            roi_layer=dict(output_size=14, sampling_ratio=0, type='RoIAlign'),\n",
            "            type='SingleRoIExtractor'),\n",
            "        num_stages=3,\n",
            "        stage_loss_weights=[\n",
            "            1,\n",
            "            0.5,\n",
            "            0.25,\n",
            "        ],\n",
            "        type='HybridTaskCascadeRoIHead'),\n",
            "    rpn_head=dict(\n",
            "        anchor_generator=dict(\n",
            "            ratios=[\n",
            "                0.5,\n",
            "                1.0,\n",
            "                2.0,\n",
            "            ],\n",
            "            scales=[\n",
            "                8,\n",
            "            ],\n",
            "            strides=[\n",
            "                4,\n",
            "                8,\n",
            "                16,\n",
            "                32,\n",
            "                64,\n",
            "            ],\n",
            "            type='AnchorGenerator'),\n",
            "        bbox_coder=dict(\n",
            "            target_means=[\n",
            "                0.0,\n",
            "                0.0,\n",
            "                0.0,\n",
            "                0.0,\n",
            "            ],\n",
            "            target_stds=[\n",
            "                1.0,\n",
            "                1.0,\n",
            "                1.0,\n",
            "                1.0,\n",
            "            ],\n",
            "            type='DeltaXYWHBBoxCoder'),\n",
            "        feat_channels=256,\n",
            "        in_channels=256,\n",
            "        loss_bbox=dict(\n",
            "            beta=0.1111111111111111, loss_weight=1.0, type='SmoothL1Loss'),\n",
            "        loss_cls=dict(\n",
            "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=True),\n",
            "        type='RPNHead'),\n",
            "    test_cfg=dict(\n",
            "        rcnn=dict(\n",
            "            mask_thr_binary=0.5,\n",
            "            max_per_img=100,\n",
            "            nms=dict(iou_threshold=0.5, type='nms'),\n",
            "            score_thr=0.001),\n",
            "        rpn=dict(\n",
            "            max_per_img=1000,\n",
            "            min_bbox_size=0,\n",
            "            nms=dict(iou_threshold=0.7, type='nms'),\n",
            "            nms_pre=1000)),\n",
            "    train_cfg=dict(\n",
            "        rcnn=[\n",
            "            dict(\n",
            "                assigner=dict(\n",
            "                    ignore_iof_thr=-1,\n",
            "                    min_pos_iou=0.5,\n",
            "                    neg_iou_thr=0.5,\n",
            "                    pos_iou_thr=0.5,\n",
            "                    type='MaxIoUAssigner'),\n",
            "                debug=False,\n",
            "                mask_size=28,\n",
            "                pos_weight=-1,\n",
            "                sampler=dict(\n",
            "                    add_gt_as_proposals=True,\n",
            "                    neg_pos_ub=-1,\n",
            "                    num=512,\n",
            "                    pos_fraction=0.25,\n",
            "                    type='RandomSampler')),\n",
            "            dict(\n",
            "                assigner=dict(\n",
            "                    ignore_iof_thr=-1,\n",
            "                    min_pos_iou=0.6,\n",
            "                    neg_iou_thr=0.6,\n",
            "                    pos_iou_thr=0.6,\n",
            "                    type='MaxIoUAssigner'),\n",
            "                debug=False,\n",
            "                mask_size=28,\n",
            "                pos_weight=-1,\n",
            "                sampler=dict(\n",
            "                    add_gt_as_proposals=True,\n",
            "                    neg_pos_ub=-1,\n",
            "                    num=512,\n",
            "                    pos_fraction=0.25,\n",
            "                    type='RandomSampler')),\n",
            "            dict(\n",
            "                assigner=dict(\n",
            "                    ignore_iof_thr=-1,\n",
            "                    min_pos_iou=0.7,\n",
            "                    neg_iou_thr=0.7,\n",
            "                    pos_iou_thr=0.7,\n",
            "                    type='MaxIoUAssigner'),\n",
            "                debug=False,\n",
            "                mask_size=28,\n",
            "                pos_weight=-1,\n",
            "                sampler=dict(\n",
            "                    add_gt_as_proposals=True,\n",
            "                    neg_pos_ub=-1,\n",
            "                    num=512,\n",
            "                    pos_fraction=0.25,\n",
            "                    type='RandomSampler')),\n",
            "        ],\n",
            "        rpn=dict(\n",
            "            allowed_border=0,\n",
            "            assigner=dict(\n",
            "                ignore_iof_thr=-1,\n",
            "                min_pos_iou=0.3,\n",
            "                neg_iou_thr=0.3,\n",
            "                pos_iou_thr=0.7,\n",
            "                type='MaxIoUAssigner'),\n",
            "            debug=False,\n",
            "            pos_weight=-1,\n",
            "            sampler=dict(\n",
            "                add_gt_as_proposals=False,\n",
            "                neg_pos_ub=-1,\n",
            "                num=256,\n",
            "                pos_fraction=0.5,\n",
            "                type='RandomSampler')),\n",
            "        rpn_proposal=dict(\n",
            "            max_per_img=2000,\n",
            "            min_bbox_size=0,\n",
            "            nms=dict(iou_threshold=0.7, type='nms'),\n",
            "            nms_pre=2000)),\n",
            "    type='HybridTaskCascade')\n",
            "optim_wrapper = dict(\n",
            "    optimizer=dict(lr=0.005, momentum=0.9, type='SGD', weight_decay=0.0001),\n",
            "    type='OptimWrapper')\n",
            "param_scheduler = [\n",
            "    dict(\n",
            "        begin=0, by_epoch=False, end=500, start_factor=0.001, type='LinearLR'),\n",
            "    dict(\n",
            "        begin=0,\n",
            "        by_epoch=True,\n",
            "        end=12,\n",
            "        gamma=0.1,\n",
            "        milestones=[\n",
            "            21,\n",
            "            22,\n",
            "        ],\n",
            "        type='MultiStepLR'),\n",
            "]\n",
            "resume = False\n",
            "test_cfg = dict(type='TestLoop')\n",
            "test_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='ann/val.json',\n",
            "        backend_args=None,\n",
            "        data_prefix=dict(img='valid/'),\n",
            "        data_root='data/diagnosis',\n",
            "        metainfo=dict(\n",
            "            classes=(\n",
            "                'Bdr',\n",
            "                'Bone Loss',\n",
            "                'Bridge',\n",
            "                'Caries',\n",
            "                'Crown',\n",
            "                'Filling',\n",
            "                'Impaction',\n",
            "                'Implant',\n",
            "                'Periapical Abscess',\n",
            "                'Rct',\n",
            "                'Rct +Post',\n",
            "                'Retentive Pin',\n",
            "                'Shadow',\n",
            "                'Splinted Crowns',\n",
            "                'Unerupted',\n",
            "            )),\n",
            "        pipeline=[\n",
            "            dict(backend_args=None, type='LoadImageFromFile'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                1333,\n",
            "                800,\n",
            "            ), type='Resize'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'img_id',\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'scale_factor',\n",
            "                ),\n",
            "                type='PackDetInputs'),\n",
            "        ],\n",
            "        test_mode=True,\n",
            "        type='DiagnosisDataset'),\n",
            "    drop_last=False,\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "test_evaluator = dict(\n",
            "    ann_file='/content/drive/MyDrive/data/diagnosis/ann/val.json',\n",
            "    backend_args=None,\n",
            "    format_only=False,\n",
            "    metric=[\n",
            "        'bbox',\n",
            "        'segm',\n",
            "    ],\n",
            "    type='CocoMetric')\n",
            "test_pipeline = [\n",
            "    dict(backend_args=None, type='LoadImageFromFile'),\n",
            "    dict(keep_ratio=True, scale=(\n",
            "        1333,\n",
            "        800,\n",
            "    ), type='Resize'),\n",
            "    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
            "    dict(\n",
            "        meta_keys=(\n",
            "            'img_id',\n",
            "            'img_path',\n",
            "            'ori_shape',\n",
            "            'img_shape',\n",
            "            'scale_factor',\n",
            "        ),\n",
            "        type='PackDetInputs'),\n",
            "]\n",
            "train_cfg = dict(max_epochs=10, type='EpochBasedTrainLoop', val_interval=1)\n",
            "train_dataloader = dict(\n",
            "    batch_sampler=dict(type='AspectRatioBatchSampler'),\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='ann/train.json',\n",
            "        backend_args=None,\n",
            "        data_prefix=dict(img='train/'),\n",
            "        data_root='/content/drive/MyDrive/data/diagnosis',\n",
            "        filter_cfg=dict(filter_empty_gt=False, min_size=16),\n",
            "        metainfo=dict(\n",
            "            classes=(\n",
            "                'Bdr',\n",
            "                'Bone Loss',\n",
            "                'Bridge',\n",
            "                'Caries',\n",
            "                'Crown',\n",
            "                'Filling',\n",
            "                'Impaction',\n",
            "                'Implant',\n",
            "                'Periapical Abscess',\n",
            "                'Rct',\n",
            "                'Rct +Post',\n",
            "                'Retentive Pin',\n",
            "                'Shadow',\n",
            "                'Splinted Crowns',\n",
            "                'Unerupted',\n",
            "            )),\n",
            "        pipeline=[\n",
            "            dict(backend_args=None, type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                1333,\n",
            "                800,\n",
            "            ), type='Resize'),\n",
            "            dict(prob=0.0, type='RandomFlip'),\n",
            "            dict(type='PackDetInputs'),\n",
            "        ],\n",
            "        type='DiagnosisDataset'),\n",
            "    num_workers=8,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
            "train_pipeline = [\n",
            "    dict(backend_args=None, type='LoadImageFromFile'),\n",
            "    dict(\n",
            "        type='LoadAnnotations', with_bbox=True, with_mask=True, with_seg=True),\n",
            "    dict(keep_ratio=True, scale=(\n",
            "        1333,\n",
            "        800,\n",
            "    ), type='Resize'),\n",
            "    dict(prob=0.5, type='RandomFlip'),\n",
            "    dict(type='PackDetInputs'),\n",
            "]\n",
            "val_cfg = dict(type='ValLoop')\n",
            "val_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='ann/val.json',\n",
            "        backend_args=None,\n",
            "        data_prefix=dict(img='valid/'),\n",
            "        data_root='data/diagnosis',\n",
            "        metainfo=dict(\n",
            "            classes=(\n",
            "                'Bdr',\n",
            "                'Bone Loss',\n",
            "                'Bridge',\n",
            "                'Caries',\n",
            "                'Crown',\n",
            "                'Filling',\n",
            "                'Impaction',\n",
            "                'Implant',\n",
            "                'Periapical Abscess',\n",
            "                'Rct',\n",
            "                'Rct +Post',\n",
            "                'Retentive Pin',\n",
            "                'Shadow',\n",
            "                'Splinted Crowns',\n",
            "                'Unerupted',\n",
            "            )),\n",
            "        pipeline=[\n",
            "            dict(backend_args=None, type='LoadImageFromFile'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                1333,\n",
            "                800,\n",
            "            ), type='Resize'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'img_id',\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'scale_factor',\n",
            "                ),\n",
            "                type='PackDetInputs'),\n",
            "        ],\n",
            "        test_mode=True,\n",
            "        type='DiagnosisDataset'),\n",
            "    drop_last=False,\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "val_evaluator = dict(\n",
            "    ann_file='/content/drive/MyDrive/data/diagnosis/ann/val.json',\n",
            "    backend_args=None,\n",
            "    format_only=False,\n",
            "    metric=[\n",
            "        'bbox',\n",
            "        'segm',\n",
            "    ],\n",
            "    type='CocoMetric')\n",
            "vis_backends = [\n",
            "    dict(type='LocalVisBackend'),\n",
            "]\n",
            "visualizer = dict(\n",
            "    name='visualizer',\n",
            "    type='DetLocalVisualizer',\n",
            "    vis_backends=[\n",
            "        dict(type='LocalVisBackend'),\n",
            "    ])\n",
            "work_dir = 'C:\\\\Users\\\\HP\\\\mmdetection\\\\demo\\\\work_dir'\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/mmengine/utils/manager.py:113: UserWarning: <class 'mmdet.visualization.local_visualizer.DetLocalVisualizer'> instance named of visualizer has been created, the method `get_instance` should not accept any other arguments\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "09/25 14:48:47 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
            "09/25 14:48:47 - mmengine - INFO - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "before_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DistSamplerSeedHook                \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DetVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_test_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DetVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_run:\n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "loading annotations into memory...\n",
            "Done (t=0.27s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "09/25 14:48:49 - mmengine - INFO - Loads checkpoint by torchvision backend from path: torchvision://resnet101\n",
            "09/25 14:48:50 - mmengine - WARNING - The model and loaded state dict do not match exactly\n",
            "\n",
            "unexpected key in source state_dict: fc.weight, fc.bias\n",
            "\n",
            "missing keys in source state_dict: layer2.0.conv2.weight_diff, layer2.0.conv2.switch.weight, layer2.0.conv2.switch.bias, layer2.0.conv2.pre_context.weight, layer2.0.conv2.pre_context.bias, layer2.0.conv2.post_context.weight, layer2.0.conv2.post_context.bias, layer2.0.conv2.offset_s.weight, layer2.0.conv2.offset_s.bias, layer2.0.conv2.offset_l.weight, layer2.0.conv2.offset_l.bias, layer2.1.conv2.weight_diff, layer2.1.conv2.switch.weight, layer2.1.conv2.switch.bias, layer2.1.conv2.pre_context.weight, layer2.1.conv2.pre_context.bias, layer2.1.conv2.post_context.weight, layer2.1.conv2.post_context.bias, layer2.1.conv2.offset_s.weight, layer2.1.conv2.offset_s.bias, layer2.1.conv2.offset_l.weight, layer2.1.conv2.offset_l.bias, layer2.2.conv2.weight_diff, layer2.2.conv2.switch.weight, layer2.2.conv2.switch.bias, layer2.2.conv2.pre_context.weight, layer2.2.conv2.pre_context.bias, layer2.2.conv2.post_context.weight, layer2.2.conv2.post_context.bias, layer2.2.conv2.offset_s.weight, layer2.2.conv2.offset_s.bias, layer2.2.conv2.offset_l.weight, layer2.2.conv2.offset_l.bias, layer2.3.conv2.weight_diff, layer2.3.conv2.switch.weight, layer2.3.conv2.switch.bias, layer2.3.conv2.pre_context.weight, layer2.3.conv2.pre_context.bias, layer2.3.conv2.post_context.weight, layer2.3.conv2.post_context.bias, layer2.3.conv2.offset_s.weight, layer2.3.conv2.offset_s.bias, layer2.3.conv2.offset_l.weight, layer2.3.conv2.offset_l.bias, layer3.0.conv2.weight_diff, layer3.0.conv2.switch.weight, layer3.0.conv2.switch.bias, layer3.0.conv2.pre_context.weight, layer3.0.conv2.pre_context.bias, layer3.0.conv2.post_context.weight, layer3.0.conv2.post_context.bias, layer3.0.conv2.offset_s.weight, layer3.0.conv2.offset_s.bias, layer3.0.conv2.offset_l.weight, layer3.0.conv2.offset_l.bias, layer3.1.conv2.weight_diff, layer3.1.conv2.switch.weight, layer3.1.conv2.switch.bias, layer3.1.conv2.pre_context.weight, layer3.1.conv2.pre_context.bias, layer3.1.conv2.post_context.weight, layer3.1.conv2.post_context.bias, layer3.1.conv2.offset_s.weight, layer3.1.conv2.offset_s.bias, layer3.1.conv2.offset_l.weight, layer3.1.conv2.offset_l.bias, layer3.2.conv2.weight_diff, layer3.2.conv2.switch.weight, layer3.2.conv2.switch.bias, layer3.2.conv2.pre_context.weight, layer3.2.conv2.pre_context.bias, layer3.2.conv2.post_context.weight, layer3.2.conv2.post_context.bias, layer3.2.conv2.offset_s.weight, layer3.2.conv2.offset_s.bias, layer3.2.conv2.offset_l.weight, layer3.2.conv2.offset_l.bias, layer3.3.conv2.weight_diff, layer3.3.conv2.switch.weight, layer3.3.conv2.switch.bias, layer3.3.conv2.pre_context.weight, layer3.3.conv2.pre_context.bias, layer3.3.conv2.post_context.weight, layer3.3.conv2.post_context.bias, layer3.3.conv2.offset_s.weight, layer3.3.conv2.offset_s.bias, layer3.3.conv2.offset_l.weight, layer3.3.conv2.offset_l.bias, layer3.4.conv2.weight_diff, layer3.4.conv2.switch.weight, layer3.4.conv2.switch.bias, layer3.4.conv2.pre_context.weight, layer3.4.conv2.pre_context.bias, layer3.4.conv2.post_context.weight, layer3.4.conv2.post_context.bias, layer3.4.conv2.offset_s.weight, layer3.4.conv2.offset_s.bias, layer3.4.conv2.offset_l.weight, layer3.4.conv2.offset_l.bias, layer3.5.conv2.weight_diff, layer3.5.conv2.switch.weight, layer3.5.conv2.switch.bias, layer3.5.conv2.pre_context.weight, layer3.5.conv2.pre_context.bias, layer3.5.conv2.post_context.weight, layer3.5.conv2.post_context.bias, layer3.5.conv2.offset_s.weight, layer3.5.conv2.offset_s.bias, layer3.5.conv2.offset_l.weight, layer3.5.conv2.offset_l.bias, layer3.6.conv2.weight_diff, layer3.6.conv2.switch.weight, layer3.6.conv2.switch.bias, layer3.6.conv2.pre_context.weight, layer3.6.conv2.pre_context.bias, layer3.6.conv2.post_context.weight, layer3.6.conv2.post_context.bias, layer3.6.conv2.offset_s.weight, layer3.6.conv2.offset_s.bias, layer3.6.conv2.offset_l.weight, layer3.6.conv2.offset_l.bias, layer3.7.conv2.weight_diff, layer3.7.conv2.switch.weight, layer3.7.conv2.switch.bias, layer3.7.conv2.pre_context.weight, layer3.7.conv2.pre_context.bias, layer3.7.conv2.post_context.weight, layer3.7.conv2.post_context.bias, layer3.7.conv2.offset_s.weight, layer3.7.conv2.offset_s.bias, layer3.7.conv2.offset_l.weight, layer3.7.conv2.offset_l.bias, layer3.8.conv2.weight_diff, layer3.8.conv2.switch.weight, layer3.8.conv2.switch.bias, layer3.8.conv2.pre_context.weight, layer3.8.conv2.pre_context.bias, layer3.8.conv2.post_context.weight, layer3.8.conv2.post_context.bias, layer3.8.conv2.offset_s.weight, layer3.8.conv2.offset_s.bias, layer3.8.conv2.offset_l.weight, layer3.8.conv2.offset_l.bias, layer3.9.conv2.weight_diff, layer3.9.conv2.switch.weight, layer3.9.conv2.switch.bias, layer3.9.conv2.pre_context.weight, layer3.9.conv2.pre_context.bias, layer3.9.conv2.post_context.weight, layer3.9.conv2.post_context.bias, layer3.9.conv2.offset_s.weight, layer3.9.conv2.offset_s.bias, layer3.9.conv2.offset_l.weight, layer3.9.conv2.offset_l.bias, layer3.10.conv2.weight_diff, layer3.10.conv2.switch.weight, layer3.10.conv2.switch.bias, layer3.10.conv2.pre_context.weight, layer3.10.conv2.pre_context.bias, layer3.10.conv2.post_context.weight, layer3.10.conv2.post_context.bias, layer3.10.conv2.offset_s.weight, layer3.10.conv2.offset_s.bias, layer3.10.conv2.offset_l.weight, layer3.10.conv2.offset_l.bias, layer3.11.conv2.weight_diff, layer3.11.conv2.switch.weight, layer3.11.conv2.switch.bias, layer3.11.conv2.pre_context.weight, layer3.11.conv2.pre_context.bias, layer3.11.conv2.post_context.weight, layer3.11.conv2.post_context.bias, layer3.11.conv2.offset_s.weight, layer3.11.conv2.offset_s.bias, layer3.11.conv2.offset_l.weight, layer3.11.conv2.offset_l.bias, layer3.12.conv2.weight_diff, layer3.12.conv2.switch.weight, layer3.12.conv2.switch.bias, layer3.12.conv2.pre_context.weight, layer3.12.conv2.pre_context.bias, layer3.12.conv2.post_context.weight, layer3.12.conv2.post_context.bias, layer3.12.conv2.offset_s.weight, layer3.12.conv2.offset_s.bias, layer3.12.conv2.offset_l.weight, layer3.12.conv2.offset_l.bias, layer3.13.conv2.weight_diff, layer3.13.conv2.switch.weight, layer3.13.conv2.switch.bias, layer3.13.conv2.pre_context.weight, layer3.13.conv2.pre_context.bias, layer3.13.conv2.post_context.weight, layer3.13.conv2.post_context.bias, layer3.13.conv2.offset_s.weight, layer3.13.conv2.offset_s.bias, layer3.13.conv2.offset_l.weight, layer3.13.conv2.offset_l.bias, layer3.14.conv2.weight_diff, layer3.14.conv2.switch.weight, layer3.14.conv2.switch.bias, layer3.14.conv2.pre_context.weight, layer3.14.conv2.pre_context.bias, layer3.14.conv2.post_context.weight, layer3.14.conv2.post_context.bias, layer3.14.conv2.offset_s.weight, layer3.14.conv2.offset_s.bias, layer3.14.conv2.offset_l.weight, layer3.14.conv2.offset_l.bias, layer3.15.conv2.weight_diff, layer3.15.conv2.switch.weight, layer3.15.conv2.switch.bias, layer3.15.conv2.pre_context.weight, layer3.15.conv2.pre_context.bias, layer3.15.conv2.post_context.weight, layer3.15.conv2.post_context.bias, layer3.15.conv2.offset_s.weight, layer3.15.conv2.offset_s.bias, layer3.15.conv2.offset_l.weight, layer3.15.conv2.offset_l.bias, layer3.16.conv2.weight_diff, layer3.16.conv2.switch.weight, layer3.16.conv2.switch.bias, layer3.16.conv2.pre_context.weight, layer3.16.conv2.pre_context.bias, layer3.16.conv2.post_context.weight, layer3.16.conv2.post_context.bias, layer3.16.conv2.offset_s.weight, layer3.16.conv2.offset_s.bias, layer3.16.conv2.offset_l.weight, layer3.16.conv2.offset_l.bias, layer3.17.conv2.weight_diff, layer3.17.conv2.switch.weight, layer3.17.conv2.switch.bias, layer3.17.conv2.pre_context.weight, layer3.17.conv2.pre_context.bias, layer3.17.conv2.post_context.weight, layer3.17.conv2.post_context.bias, layer3.17.conv2.offset_s.weight, layer3.17.conv2.offset_s.bias, layer3.17.conv2.offset_l.weight, layer3.17.conv2.offset_l.bias, layer3.18.conv2.weight_diff, layer3.18.conv2.switch.weight, layer3.18.conv2.switch.bias, layer3.18.conv2.pre_context.weight, layer3.18.conv2.pre_context.bias, layer3.18.conv2.post_context.weight, layer3.18.conv2.post_context.bias, layer3.18.conv2.offset_s.weight, layer3.18.conv2.offset_s.bias, layer3.18.conv2.offset_l.weight, layer3.18.conv2.offset_l.bias, layer3.19.conv2.weight_diff, layer3.19.conv2.switch.weight, layer3.19.conv2.switch.bias, layer3.19.conv2.pre_context.weight, layer3.19.conv2.pre_context.bias, layer3.19.conv2.post_context.weight, layer3.19.conv2.post_context.bias, layer3.19.conv2.offset_s.weight, layer3.19.conv2.offset_s.bias, layer3.19.conv2.offset_l.weight, layer3.19.conv2.offset_l.bias, layer3.20.conv2.weight_diff, layer3.20.conv2.switch.weight, layer3.20.conv2.switch.bias, layer3.20.conv2.pre_context.weight, layer3.20.conv2.pre_context.bias, layer3.20.conv2.post_context.weight, layer3.20.conv2.post_context.bias, layer3.20.conv2.offset_s.weight, layer3.20.conv2.offset_s.bias, layer3.20.conv2.offset_l.weight, layer3.20.conv2.offset_l.bias, layer3.21.conv2.weight_diff, layer3.21.conv2.switch.weight, layer3.21.conv2.switch.bias, layer3.21.conv2.pre_context.weight, layer3.21.conv2.pre_context.bias, layer3.21.conv2.post_context.weight, layer3.21.conv2.post_context.bias, layer3.21.conv2.offset_s.weight, layer3.21.conv2.offset_s.bias, layer3.21.conv2.offset_l.weight, layer3.21.conv2.offset_l.bias, layer3.22.conv2.weight_diff, layer3.22.conv2.switch.weight, layer3.22.conv2.switch.bias, layer3.22.conv2.pre_context.weight, layer3.22.conv2.pre_context.bias, layer3.22.conv2.post_context.weight, layer3.22.conv2.post_context.bias, layer3.22.conv2.offset_s.weight, layer3.22.conv2.offset_s.bias, layer3.22.conv2.offset_l.weight, layer3.22.conv2.offset_l.bias, layer4.0.conv2.weight_diff, layer4.0.conv2.switch.weight, layer4.0.conv2.switch.bias, layer4.0.conv2.pre_context.weight, layer4.0.conv2.pre_context.bias, layer4.0.conv2.post_context.weight, layer4.0.conv2.post_context.bias, layer4.0.conv2.offset_s.weight, layer4.0.conv2.offset_s.bias, layer4.0.conv2.offset_l.weight, layer4.0.conv2.offset_l.bias, layer4.1.conv2.weight_diff, layer4.1.conv2.switch.weight, layer4.1.conv2.switch.bias, layer4.1.conv2.pre_context.weight, layer4.1.conv2.pre_context.bias, layer4.1.conv2.post_context.weight, layer4.1.conv2.post_context.bias, layer4.1.conv2.offset_s.weight, layer4.1.conv2.offset_s.bias, layer4.1.conv2.offset_l.weight, layer4.1.conv2.offset_l.bias, layer4.2.conv2.weight_diff, layer4.2.conv2.switch.weight, layer4.2.conv2.switch.bias, layer4.2.conv2.pre_context.weight, layer4.2.conv2.pre_context.bias, layer4.2.conv2.post_context.weight, layer4.2.conv2.post_context.bias, layer4.2.conv2.offset_s.weight, layer4.2.conv2.offset_s.bias, layer4.2.conv2.offset_l.weight, layer4.2.conv2.offset_l.bias\n",
            "\n",
            "09/25 14:48:50 - mmengine - INFO - Loads checkpoint by torchvision backend from path: torchvision://resnet101\n",
            "09/25 14:48:50 - mmengine - WARNING - The model and loaded state dict do not match exactly\n",
            "\n",
            "unexpected key in source state_dict: fc.weight, fc.bias\n",
            "\n",
            "missing keys in source state_dict: layer2.0.conv2.weight_diff, layer2.0.conv2.switch.weight, layer2.0.conv2.switch.bias, layer2.0.conv2.pre_context.weight, layer2.0.conv2.pre_context.bias, layer2.0.conv2.post_context.weight, layer2.0.conv2.post_context.bias, layer2.0.conv2.offset_s.weight, layer2.0.conv2.offset_s.bias, layer2.0.conv2.offset_l.weight, layer2.0.conv2.offset_l.bias, layer2.0.rfp_conv.weight, layer2.0.rfp_conv.bias, layer2.1.conv2.weight_diff, layer2.1.conv2.switch.weight, layer2.1.conv2.switch.bias, layer2.1.conv2.pre_context.weight, layer2.1.conv2.pre_context.bias, layer2.1.conv2.post_context.weight, layer2.1.conv2.post_context.bias, layer2.1.conv2.offset_s.weight, layer2.1.conv2.offset_s.bias, layer2.1.conv2.offset_l.weight, layer2.1.conv2.offset_l.bias, layer2.2.conv2.weight_diff, layer2.2.conv2.switch.weight, layer2.2.conv2.switch.bias, layer2.2.conv2.pre_context.weight, layer2.2.conv2.pre_context.bias, layer2.2.conv2.post_context.weight, layer2.2.conv2.post_context.bias, layer2.2.conv2.offset_s.weight, layer2.2.conv2.offset_s.bias, layer2.2.conv2.offset_l.weight, layer2.2.conv2.offset_l.bias, layer2.3.conv2.weight_diff, layer2.3.conv2.switch.weight, layer2.3.conv2.switch.bias, layer2.3.conv2.pre_context.weight, layer2.3.conv2.pre_context.bias, layer2.3.conv2.post_context.weight, layer2.3.conv2.post_context.bias, layer2.3.conv2.offset_s.weight, layer2.3.conv2.offset_s.bias, layer2.3.conv2.offset_l.weight, layer2.3.conv2.offset_l.bias, layer3.0.conv2.weight_diff, layer3.0.conv2.switch.weight, layer3.0.conv2.switch.bias, layer3.0.conv2.pre_context.weight, layer3.0.conv2.pre_context.bias, layer3.0.conv2.post_context.weight, layer3.0.conv2.post_context.bias, layer3.0.conv2.offset_s.weight, layer3.0.conv2.offset_s.bias, layer3.0.conv2.offset_l.weight, layer3.0.conv2.offset_l.bias, layer3.0.rfp_conv.weight, layer3.0.rfp_conv.bias, layer3.1.conv2.weight_diff, layer3.1.conv2.switch.weight, layer3.1.conv2.switch.bias, layer3.1.conv2.pre_context.weight, layer3.1.conv2.pre_context.bias, layer3.1.conv2.post_context.weight, layer3.1.conv2.post_context.bias, layer3.1.conv2.offset_s.weight, layer3.1.conv2.offset_s.bias, layer3.1.conv2.offset_l.weight, layer3.1.conv2.offset_l.bias, layer3.2.conv2.weight_diff, layer3.2.conv2.switch.weight, layer3.2.conv2.switch.bias, layer3.2.conv2.pre_context.weight, layer3.2.conv2.pre_context.bias, layer3.2.conv2.post_context.weight, layer3.2.conv2.post_context.bias, layer3.2.conv2.offset_s.weight, layer3.2.conv2.offset_s.bias, layer3.2.conv2.offset_l.weight, layer3.2.conv2.offset_l.bias, layer3.3.conv2.weight_diff, layer3.3.conv2.switch.weight, layer3.3.conv2.switch.bias, layer3.3.conv2.pre_context.weight, layer3.3.conv2.pre_context.bias, layer3.3.conv2.post_context.weight, layer3.3.conv2.post_context.bias, layer3.3.conv2.offset_s.weight, layer3.3.conv2.offset_s.bias, layer3.3.conv2.offset_l.weight, layer3.3.conv2.offset_l.bias, layer3.4.conv2.weight_diff, layer3.4.conv2.switch.weight, layer3.4.conv2.switch.bias, layer3.4.conv2.pre_context.weight, layer3.4.conv2.pre_context.bias, layer3.4.conv2.post_context.weight, layer3.4.conv2.post_context.bias, layer3.4.conv2.offset_s.weight, layer3.4.conv2.offset_s.bias, layer3.4.conv2.offset_l.weight, layer3.4.conv2.offset_l.bias, layer3.5.conv2.weight_diff, layer3.5.conv2.switch.weight, layer3.5.conv2.switch.bias, layer3.5.conv2.pre_context.weight, layer3.5.conv2.pre_context.bias, layer3.5.conv2.post_context.weight, layer3.5.conv2.post_context.bias, layer3.5.conv2.offset_s.weight, layer3.5.conv2.offset_s.bias, layer3.5.conv2.offset_l.weight, layer3.5.conv2.offset_l.bias, layer3.6.conv2.weight_diff, layer3.6.conv2.switch.weight, layer3.6.conv2.switch.bias, layer3.6.conv2.pre_context.weight, layer3.6.conv2.pre_context.bias, layer3.6.conv2.post_context.weight, layer3.6.conv2.post_context.bias, layer3.6.conv2.offset_s.weight, layer3.6.conv2.offset_s.bias, layer3.6.conv2.offset_l.weight, layer3.6.conv2.offset_l.bias, layer3.7.conv2.weight_diff, layer3.7.conv2.switch.weight, layer3.7.conv2.switch.bias, layer3.7.conv2.pre_context.weight, layer3.7.conv2.pre_context.bias, layer3.7.conv2.post_context.weight, layer3.7.conv2.post_context.bias, layer3.7.conv2.offset_s.weight, layer3.7.conv2.offset_s.bias, layer3.7.conv2.offset_l.weight, layer3.7.conv2.offset_l.bias, layer3.8.conv2.weight_diff, layer3.8.conv2.switch.weight, layer3.8.conv2.switch.bias, layer3.8.conv2.pre_context.weight, layer3.8.conv2.pre_context.bias, layer3.8.conv2.post_context.weight, layer3.8.conv2.post_context.bias, layer3.8.conv2.offset_s.weight, layer3.8.conv2.offset_s.bias, layer3.8.conv2.offset_l.weight, layer3.8.conv2.offset_l.bias, layer3.9.conv2.weight_diff, layer3.9.conv2.switch.weight, layer3.9.conv2.switch.bias, layer3.9.conv2.pre_context.weight, layer3.9.conv2.pre_context.bias, layer3.9.conv2.post_context.weight, layer3.9.conv2.post_context.bias, layer3.9.conv2.offset_s.weight, layer3.9.conv2.offset_s.bias, layer3.9.conv2.offset_l.weight, layer3.9.conv2.offset_l.bias, layer3.10.conv2.weight_diff, layer3.10.conv2.switch.weight, layer3.10.conv2.switch.bias, layer3.10.conv2.pre_context.weight, layer3.10.conv2.pre_context.bias, layer3.10.conv2.post_context.weight, layer3.10.conv2.post_context.bias, layer3.10.conv2.offset_s.weight, layer3.10.conv2.offset_s.bias, layer3.10.conv2.offset_l.weight, layer3.10.conv2.offset_l.bias, layer3.11.conv2.weight_diff, layer3.11.conv2.switch.weight, layer3.11.conv2.switch.bias, layer3.11.conv2.pre_context.weight, layer3.11.conv2.pre_context.bias, layer3.11.conv2.post_context.weight, layer3.11.conv2.post_context.bias, layer3.11.conv2.offset_s.weight, layer3.11.conv2.offset_s.bias, layer3.11.conv2.offset_l.weight, layer3.11.conv2.offset_l.bias, layer3.12.conv2.weight_diff, layer3.12.conv2.switch.weight, layer3.12.conv2.switch.bias, layer3.12.conv2.pre_context.weight, layer3.12.conv2.pre_context.bias, layer3.12.conv2.post_context.weight, layer3.12.conv2.post_context.bias, layer3.12.conv2.offset_s.weight, layer3.12.conv2.offset_s.bias, layer3.12.conv2.offset_l.weight, layer3.12.conv2.offset_l.bias, layer3.13.conv2.weight_diff, layer3.13.conv2.switch.weight, layer3.13.conv2.switch.bias, layer3.13.conv2.pre_context.weight, layer3.13.conv2.pre_context.bias, layer3.13.conv2.post_context.weight, layer3.13.conv2.post_context.bias, layer3.13.conv2.offset_s.weight, layer3.13.conv2.offset_s.bias, layer3.13.conv2.offset_l.weight, layer3.13.conv2.offset_l.bias, layer3.14.conv2.weight_diff, layer3.14.conv2.switch.weight, layer3.14.conv2.switch.bias, layer3.14.conv2.pre_context.weight, layer3.14.conv2.pre_context.bias, layer3.14.conv2.post_context.weight, layer3.14.conv2.post_context.bias, layer3.14.conv2.offset_s.weight, layer3.14.conv2.offset_s.bias, layer3.14.conv2.offset_l.weight, layer3.14.conv2.offset_l.bias, layer3.15.conv2.weight_diff, layer3.15.conv2.switch.weight, layer3.15.conv2.switch.bias, layer3.15.conv2.pre_context.weight, layer3.15.conv2.pre_context.bias, layer3.15.conv2.post_context.weight, layer3.15.conv2.post_context.bias, layer3.15.conv2.offset_s.weight, layer3.15.conv2.offset_s.bias, layer3.15.conv2.offset_l.weight, layer3.15.conv2.offset_l.bias, layer3.16.conv2.weight_diff, layer3.16.conv2.switch.weight, layer3.16.conv2.switch.bias, layer3.16.conv2.pre_context.weight, layer3.16.conv2.pre_context.bias, layer3.16.conv2.post_context.weight, layer3.16.conv2.post_context.bias, layer3.16.conv2.offset_s.weight, layer3.16.conv2.offset_s.bias, layer3.16.conv2.offset_l.weight, layer3.16.conv2.offset_l.bias, layer3.17.conv2.weight_diff, layer3.17.conv2.switch.weight, layer3.17.conv2.switch.bias, layer3.17.conv2.pre_context.weight, layer3.17.conv2.pre_context.bias, layer3.17.conv2.post_context.weight, layer3.17.conv2.post_context.bias, layer3.17.conv2.offset_s.weight, layer3.17.conv2.offset_s.bias, layer3.17.conv2.offset_l.weight, layer3.17.conv2.offset_l.bias, layer3.18.conv2.weight_diff, layer3.18.conv2.switch.weight, layer3.18.conv2.switch.bias, layer3.18.conv2.pre_context.weight, layer3.18.conv2.pre_context.bias, layer3.18.conv2.post_context.weight, layer3.18.conv2.post_context.bias, layer3.18.conv2.offset_s.weight, layer3.18.conv2.offset_s.bias, layer3.18.conv2.offset_l.weight, layer3.18.conv2.offset_l.bias, layer3.19.conv2.weight_diff, layer3.19.conv2.switch.weight, layer3.19.conv2.switch.bias, layer3.19.conv2.pre_context.weight, layer3.19.conv2.pre_context.bias, layer3.19.conv2.post_context.weight, layer3.19.conv2.post_context.bias, layer3.19.conv2.offset_s.weight, layer3.19.conv2.offset_s.bias, layer3.19.conv2.offset_l.weight, layer3.19.conv2.offset_l.bias, layer3.20.conv2.weight_diff, layer3.20.conv2.switch.weight, layer3.20.conv2.switch.bias, layer3.20.conv2.pre_context.weight, layer3.20.conv2.pre_context.bias, layer3.20.conv2.post_context.weight, layer3.20.conv2.post_context.bias, layer3.20.conv2.offset_s.weight, layer3.20.conv2.offset_s.bias, layer3.20.conv2.offset_l.weight, layer3.20.conv2.offset_l.bias, layer3.21.conv2.weight_diff, layer3.21.conv2.switch.weight, layer3.21.conv2.switch.bias, layer3.21.conv2.pre_context.weight, layer3.21.conv2.pre_context.bias, layer3.21.conv2.post_context.weight, layer3.21.conv2.post_context.bias, layer3.21.conv2.offset_s.weight, layer3.21.conv2.offset_s.bias, layer3.21.conv2.offset_l.weight, layer3.21.conv2.offset_l.bias, layer3.22.conv2.weight_diff, layer3.22.conv2.switch.weight, layer3.22.conv2.switch.bias, layer3.22.conv2.pre_context.weight, layer3.22.conv2.pre_context.bias, layer3.22.conv2.post_context.weight, layer3.22.conv2.post_context.bias, layer3.22.conv2.offset_s.weight, layer3.22.conv2.offset_s.bias, layer3.22.conv2.offset_l.weight, layer3.22.conv2.offset_l.bias, layer4.0.conv2.weight_diff, layer4.0.conv2.switch.weight, layer4.0.conv2.switch.bias, layer4.0.conv2.pre_context.weight, layer4.0.conv2.pre_context.bias, layer4.0.conv2.post_context.weight, layer4.0.conv2.post_context.bias, layer4.0.conv2.offset_s.weight, layer4.0.conv2.offset_s.bias, layer4.0.conv2.offset_l.weight, layer4.0.conv2.offset_l.bias, layer4.0.rfp_conv.weight, layer4.0.rfp_conv.bias, layer4.1.conv2.weight_diff, layer4.1.conv2.switch.weight, layer4.1.conv2.switch.bias, layer4.1.conv2.pre_context.weight, layer4.1.conv2.pre_context.bias, layer4.1.conv2.post_context.weight, layer4.1.conv2.post_context.bias, layer4.1.conv2.offset_s.weight, layer4.1.conv2.offset_s.bias, layer4.1.conv2.offset_l.weight, layer4.1.conv2.offset_l.bias, layer4.2.conv2.weight_diff, layer4.2.conv2.switch.weight, layer4.2.conv2.switch.bias, layer4.2.conv2.pre_context.weight, layer4.2.conv2.pre_context.bias, layer4.2.conv2.post_context.weight, layer4.2.conv2.post_context.bias, layer4.2.conv2.offset_s.weight, layer4.2.conv2.offset_s.bias, layer4.2.conv2.offset_l.weight, layer4.2.conv2.offset_l.bias\n",
            "\n",
            "Loads checkpoint by local backend from path: /content/drive/MyDrive/C:\\Users\\HP\\mmdetection\\demo\\work_dir/temp.pth\n",
            "09/25 14:49:04 - mmengine - INFO - Load checkpoint from /content/drive/MyDrive/C:\\Users\\HP\\mmdetection\\demo\\work_dir/temp.pth\n",
            "09/25 14:49:04 - mmengine - WARNING - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
            "09/25 14:49:04 - mmengine - WARNING - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
            "09/25 14:49:04 - mmengine - INFO - Checkpoints will be saved to /content/drive/MyDrive/C:\\Users\\HP\\mmdetection\\demo\\work_dir.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "09/25 15:09:21 - mmengine - INFO - Exp name: customconfig (2)_20230925_144843\n",
            "09/25 15:25:03 - mmengine - INFO - Exp name: customconfig (2)_20230925_144843\n",
            "09/25 15:25:03 - mmengine - INFO - Epoch(train)  [1][1774/1774]  lr: 5.0000e-03  eta: 5:23:51  time: 1.2170  data_time: 0.0179  memory: 6125  loss: 0.5019  loss_rpn_cls: 0.0032  loss_rpn_bbox: 0.0150  s0.loss_cls: 0.0426  s0.acc: 100.0000  s0.loss_bbox: 0.0304  s0.loss_mask: 0.1646  s1.loss_cls: 0.0147  s1.acc: 100.0000  s1.loss_bbox: 0.0492  s1.loss_mask: 0.0841  s2.loss_cls: 0.0083  s2.acc: 100.0000  s2.loss_bbox: 0.0476  s2.loss_mask: 0.0423\n",
            "09/25 15:25:03 - mmengine - INFO - Saving checkpoint at 1 epochs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/mmdetection/mmdet/models/roi_heads/mask_heads/fcn_mask_head.py:339: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
            "  mask_preds = bboxes.new_tensor(mask_preds)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "09/25 15:28:33 - mmengine - INFO - Evaluating bbox...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=2.05s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.72s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.348\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.588\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.360\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.121\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.343\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.384\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.475\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.475\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.475\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.158\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.478\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.480\n",
            "09/25 15:28:36 - mmengine - INFO - bbox_mAP_copypaste: 0.348 0.588 0.360 0.121 0.343 0.384\n",
            "09/25 15:28:36 - mmengine - INFO - Evaluating segm...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.10s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=1.26s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.35s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.338\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.586\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.356\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.103\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.340\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.353\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.454\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.454\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.454\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.171\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.466\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.424\n",
            "09/25 15:28:38 - mmengine - INFO - segm_mAP_copypaste: 0.338 0.586 0.356 0.103 0.340 0.353\n",
            "09/25 15:28:38 - mmengine - INFO - Epoch(val) [1][336/336]    coco/bbox_mAP: 0.3480  coco/bbox_mAP_50: 0.5880  coco/bbox_mAP_75: 0.3600  coco/bbox_mAP_s: 0.1210  coco/bbox_mAP_m: 0.3430  coco/bbox_mAP_l: 0.3840  coco/segm_mAP: 0.3380  coco/segm_mAP_50: 0.5860  coco/segm_mAP_75: 0.3560  coco/segm_mAP_s: 0.1030  coco/segm_mAP_m: 0.3400  coco/segm_mAP_l: 0.3530  data_time: 0.0950  time: 0.5804\n",
            "09/25 15:33:08 - mmengine - INFO - Exp name: customconfig (2)_20230925_144843\n",
            "09/25 15:53:23 - mmengine - INFO - Exp name: customconfig (2)_20230925_144843\n",
            "09/25 16:04:24 - mmengine - INFO - Exp name: customconfig (2)_20230925_144843\n",
            "09/25 16:04:24 - mmengine - INFO - Epoch(train)  [2][1774/1774]  lr: 5.0000e-03  eta: 4:47:02  time: 1.2100  data_time: 0.0172  memory: 6125  loss: 0.4734  loss_rpn_cls: 0.0032  loss_rpn_bbox: 0.0145  s0.loss_cls: 0.0400  s0.acc: 99.2188  s0.loss_bbox: 0.0281  s0.loss_mask: 0.1570  s1.loss_cls: 0.0133  s1.acc: 99.4141  s1.loss_bbox: 0.0450  s1.loss_mask: 0.0803  s2.loss_cls: 0.0073  s2.acc: 99.2188  s2.loss_bbox: 0.0441  s2.loss_mask: 0.0405\n",
            "09/25 16:04:24 - mmengine - INFO - Saving checkpoint at 2 epochs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/mmdetection/mmdet/models/roi_heads/mask_heads/fcn_mask_head.py:339: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
            "  mask_preds = bboxes.new_tensor(mask_preds)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "09/25 16:07:53 - mmengine - INFO - Evaluating bbox...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.29s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.45s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.367\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.611\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.387\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.125\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.377\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.400\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.504\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.504\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.504\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.193\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.506\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.497\n",
            "09/25 16:07:55 - mmengine - INFO - bbox_mAP_copypaste: 0.367 0.611 0.387 0.125 0.377 0.400\n",
            "09/25 16:07:55 - mmengine - INFO - Evaluating segm...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.13s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=1.97s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.77s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.341\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.597\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.360\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.100\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.353\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.360\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.466\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.466\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.466\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.169\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.473\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.438\n",
            "09/25 16:07:58 - mmengine - INFO - segm_mAP_copypaste: 0.341 0.597 0.360 0.100 0.353 0.360\n",
            "09/25 16:07:58 - mmengine - INFO - Epoch(val) [2][336/336]    coco/bbox_mAP: 0.3670  coco/bbox_mAP_50: 0.6110  coco/bbox_mAP_75: 0.3870  coco/bbox_mAP_s: 0.1250  coco/bbox_mAP_m: 0.3770  coco/bbox_mAP_l: 0.4000  coco/segm_mAP: 0.3410  coco/segm_mAP_50: 0.5970  coco/segm_mAP_75: 0.3600  coco/segm_mAP_s: 0.1000  coco/segm_mAP_m: 0.3530  coco/segm_mAP_l: 0.3600  data_time: 0.0841  time: 0.5941\n",
            "09/25 16:17:05 - mmengine - INFO - Exp name: customconfig (2)_20230925_144843\n",
            "09/25 16:37:12 - mmengine - INFO - Exp name: customconfig (2)_20230925_144843\n",
            "09/25 16:43:39 - mmengine - INFO - Exp name: customconfig (2)_20230925_144843\n",
            "09/25 16:43:39 - mmengine - INFO - Epoch(train)  [3][1774/1774]  lr: 5.0000e-03  eta: 4:10:42  time: 1.2069  data_time: 0.0175  memory: 6125  loss: 0.4592  loss_rpn_cls: 0.0032  loss_rpn_bbox: 0.0142  s0.loss_cls: 0.0386  s0.acc: 100.0000  s0.loss_bbox: 0.0265  s0.loss_mask: 0.1546  s1.loss_cls: 0.0125  s1.acc: 100.0000  s1.loss_bbox: 0.0426  s1.loss_mask: 0.0787  s2.loss_cls: 0.0067  s2.acc: 100.0000  s2.loss_bbox: 0.0418  s2.loss_mask: 0.0398\n",
            "09/25 16:43:39 - mmengine - INFO - Saving checkpoint at 3 epochs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/mmdetection/mmdet/models/roi_heads/mask_heads/fcn_mask_head.py:339: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
            "  mask_preds = bboxes.new_tensor(mask_preds)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "09/25 16:47:36 - mmengine - INFO - Evaluating bbox...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=2.09s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.81s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.360\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.597\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.388\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.124\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.375\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.380\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.504\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.504\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.504\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.178\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.513\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.496\n",
            "09/25 16:47:39 - mmengine - INFO - bbox_mAP_copypaste: 0.360 0.597 0.388 0.124 0.375 0.380\n",
            "09/25 16:47:39 - mmengine - INFO - Evaluating segm...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.23s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=2.08s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.72s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.342\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.591\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.370\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.091\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.358\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.359\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.463\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.463\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.463\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.157\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.475\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.452\n",
            "09/25 16:47:42 - mmengine - INFO - segm_mAP_copypaste: 0.342 0.591 0.370 0.091 0.358 0.359\n",
            "09/25 16:47:42 - mmengine - INFO - Epoch(val) [3][336/336]    coco/bbox_mAP: 0.3600  coco/bbox_mAP_50: 0.5970  coco/bbox_mAP_75: 0.3880  coco/bbox_mAP_s: 0.1240  coco/bbox_mAP_m: 0.3750  coco/bbox_mAP_l: 0.3800  coco/segm_mAP: 0.3420  coco/segm_mAP_50: 0.5910  coco/segm_mAP_75: 0.3700  coco/segm_mAP_s: 0.0910  coco/segm_mAP_m: 0.3580  coco/segm_mAP_l: 0.3590  data_time: 0.0838  time: 0.5981\n",
            "09/25 17:01:24 - mmengine - INFO - Exp name: customconfig (2)_20230925_144843\n",
            "09/25 17:21:38 - mmengine - INFO - Exp name: customconfig (2)_20230925_144843\n",
            "09/25 17:23:30 - mmengine - INFO - Exp name: customconfig (2)_20230925_144843\n",
            "09/25 17:23:30 - mmengine - INFO - Epoch(train)  [4][1774/1774]  lr: 5.0000e-03  eta: 3:34:50  time: 1.2104  data_time: 0.0178  memory: 6125  loss: 0.4403  loss_rpn_cls: 0.0028  loss_rpn_bbox: 0.0140  s0.loss_cls: 0.0375  s0.acc: 99.0234  s0.loss_bbox: 0.0250  s0.loss_mask: 0.1496  s1.loss_cls: 0.0120  s1.acc: 99.3631  s1.loss_bbox: 0.0394  s1.loss_mask: 0.0763  s2.loss_cls: 0.0064  s2.acc: 99.7793  s2.loss_bbox: 0.0388  s2.loss_mask: 0.0386\n",
            "09/25 17:23:30 - mmengine - INFO - Saving checkpoint at 4 epochs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/mmdetection/mmdet/models/roi_heads/mask_heads/fcn_mask_head.py:339: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
            "  mask_preds = bboxes.new_tensor(mask_preds)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "09/25 17:26:51 - mmengine - INFO - Evaluating bbox...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.99s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.42s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.348\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.580\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.377\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.123\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.342\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.372\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.493\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.493\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.493\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.148\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.503\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.470\n",
            "09/25 17:26:53 - mmengine - INFO - bbox_mAP_copypaste: 0.348 0.580 0.377 0.123 0.342 0.372\n",
            "09/25 17:26:53 - mmengine - INFO - Evaluating segm...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.10s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=1.17s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.40s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.331\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.575\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.358\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.077\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.333\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.339\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.452\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.452\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.452\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.127\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.463\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.421\n",
            "09/25 17:26:55 - mmengine - INFO - segm_mAP_copypaste: 0.331 0.575 0.358 0.077 0.333 0.339\n",
            "09/25 17:26:55 - mmengine - INFO - Epoch(val) [4][336/336]    coco/bbox_mAP: 0.3480  coco/bbox_mAP_50: 0.5800  coco/bbox_mAP_75: 0.3770  coco/bbox_mAP_s: 0.1230  coco/bbox_mAP_m: 0.3420  coco/bbox_mAP_l: 0.3720  coco/segm_mAP: 0.3310  coco/segm_mAP_50: 0.5750  coco/segm_mAP_75: 0.3580  coco/segm_mAP_s: 0.0770  coco/segm_mAP_m: 0.3330  coco/segm_mAP_l: 0.3390  data_time: 0.0870  time: 0.5718\n",
            "09/25 17:45:08 - mmengine - INFO - Exp name: customconfig (2)_20230925_144843\n",
            "09/25 18:02:45 - mmengine - INFO - Exp name: customconfig (2)_20230925_144843\n",
            "09/25 18:02:45 - mmengine - INFO - Epoch(train)  [5][1774/1774]  lr: 5.0000e-03  eta: 2:59:04  time: 1.2122  data_time: 0.0172  memory: 6125  loss: 0.4211  loss_rpn_cls: 0.0027  loss_rpn_bbox: 0.0132  s0.loss_cls: 0.0353  s0.acc: 97.6562  s0.loss_bbox: 0.0230  s0.loss_mask: 0.1442  s1.loss_cls: 0.0109  s1.acc: 97.8261  s1.loss_bbox: 0.0372  s1.loss_mask: 0.0739  s2.loss_cls: 0.0058  s2.acc: 95.9184  s2.loss_bbox: 0.0374  s2.loss_mask: 0.0375\n",
            "09/25 18:02:45 - mmengine - INFO - Saving checkpoint at 5 epochs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/mmdetection/mmdet/models/roi_heads/mask_heads/fcn_mask_head.py:339: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
            "  mask_preds = bboxes.new_tensor(mask_preds)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "09/25 18:06:57 - mmengine - INFO - Evaluating bbox...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.20s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.41s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.355\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.594\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.376\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.104\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.356\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.388\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.477\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.477\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.477\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.142\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.482\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.485\n",
            "09/25 18:06:59 - mmengine - INFO - bbox_mAP_copypaste: 0.355 0.594 0.376 0.104 0.356 0.388\n",
            "09/25 18:06:59 - mmengine - INFO - Evaluating segm...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.10s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=1.14s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.38s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.328\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.582\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.347\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.094\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.331\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.336\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.436\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.436\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.436\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.136\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.451\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.403\n",
            "09/25 18:07:01 - mmengine - INFO - segm_mAP_copypaste: 0.328 0.582 0.347 0.094 0.331 0.336\n",
            "09/25 18:07:01 - mmengine - INFO - Epoch(val) [5][336/336]    coco/bbox_mAP: 0.3550  coco/bbox_mAP_50: 0.5940  coco/bbox_mAP_75: 0.3760  coco/bbox_mAP_s: 0.1040  coco/bbox_mAP_m: 0.3560  coco/bbox_mAP_l: 0.3880  coco/segm_mAP: 0.3280  coco/segm_mAP_50: 0.5820  coco/segm_mAP_75: 0.3470  coco/segm_mAP_s: 0.0940  coco/segm_mAP_m: 0.3310  coco/segm_mAP_l: 0.3360  data_time: 0.0827  time: 0.5553\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-0cc5ff0944fe>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmmengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunner\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRunner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mrunner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_cfg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mmengine/runner/runner.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1743\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train_step'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1744\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1745\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1746\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_run'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1747\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mmengine/runner/loops.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_epoch\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_max_epochs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decide_current_val_interval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mmengine/runner/loops.py\u001b[0m in \u001b[0;36mrun_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_train_epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mmengine/runner/loops.py\u001b[0m in \u001b[0;36mrun_iter\u001b[0;34m(self, idx, data_batch)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;31m# synchronization during gradient accumulation process.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;31m# outputs should be a dict of loss.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         outputs = self.runner.model.train_step(\n\u001b[0m\u001b[1;32m    129\u001b[0m             data_batch, optim_wrapper=self.runner.optim_wrapper)\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mmengine/model/base_model/base_model.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, data, optim_wrapper)\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mparsed_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_losses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0moptim_wrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlog_vars\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mmengine/optim/optimizer/optimizer_wrapper.py\u001b[0m in \u001b[0;36mupdate_params\u001b[0;34m(self, loss, step_kwargs, zero_kwargs)\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0mzero_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0;31m# Update parameters only if `self._inner_count` is divisible by\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;31m# `self._accumulative_counts` or `self._inner_count` equals to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mmengine/optim/optimizer/optimizer_wrapper.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mKeyword\u001b[0m \u001b[0marguments\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mto\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mmeth\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \"\"\"\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inner_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from mmengine import Config\n",
        "\n",
        "cfg = Config.fromfile('/content/drive/MyDrive/models/customconfig (2).py')\n",
        "cfg['load_from']=r'/content/drive/MyDrive/C:\\Users\\HP\\mmdetection\\demo\\work_dir/temp.pth'\n",
        "%cd /content/drive/MyDrive\n",
        "\n",
        "from mmengine.runner import Runner\n",
        "runner = Runner.from_cfg(cfg)\n",
        "runner.train()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}